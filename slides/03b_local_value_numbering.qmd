---
title: "_ local value numbering"

format:
    revealjs:
        slide-number: true
        show-slide-number: print
        chalkboard: true

---

### Local Value Numbering

Value numbering is a very powerful technique that removes ***redunancies***,  An instruction  x + y is redundant inside a block if it has already been computed
in the block, and no intervening operation redefines x or y. If the compiler
finds a redundant expression, it can save that value at the first computation
and replace any subsequent evaluations with references to the saved value.

The idea is simple - The algorithm executes the block, Each time it sees a new variable it gives it a value (reprented as a number)
Each time it sees an instruction it forms a hash of the op code and t he value numbers of its operands and gives tha a new value number.

Two instructions are redundant if they have same op code and operands, which means the same value number

e_i and e_j have the
same value number if and only if e_i and e_j are provably equal for all possible
operands of the expressions.

local value numbering covers lot of optimizations

```
dead code elimination

main {
    a: int = const 100;
    a: int = const 42;
    print a;

}

copy propagation

main{
    x: int = const 4;
    copy1: int = id x;
    copy2: int = id copy1;
    print copy2;
}

common sub-expression elimination cse 

main {
    a: int = const 4;
    b: int = const 2;
    sum1: int = add a b;
    sum2: int = add a b;
    prod: int = mul sum1 sum2;
    print prod;
}
```


We want to stop thinking about varaibles and think about values.
Two instructions are redundant if they compute the same value.

### this is a very deep idea that comes up multiple times.  

for example in a JIT compiler we want computation to be fast so we can get rid of all the variables
```
b: int const 1;
c: int cont 2;
a:  int b c;  
```
becomes:
```
[  int const 1
   int const 2 
   int 0 1
]
```
less storage, args are just pointers, instructions are smaller.
faster because any use points to the corresponding def without any searching.


Pseudo code (similar to an interpreter)

hash table 
constants and expressions of value numbers to value numbers and a variable holding the value 

reverse map from variable to value numbers 


```
  main {
    a: int = const 4;
    b: int = const 2;
    sum1: int = add a b;
    sum2: int = add a b;
    prod: int = mult sum1 sum2;
    print prod

  }
```

table 

|key | value  |canonical name|
|---| ------| ------|
|const 4 | 1 | a |
|const 2 | 2 | b |
|add 1 2 | 3 | sum1|
|mul 3 3 | 4 | prod| 

revese map

| name | value|
|---| ---|
| a    | 1|
| b    | 2 |
| sum1 | 3|
| sum2 | 3| 
| prod | 4 


as we lookup each instruction - replace each arg with the canonical home

if the value is already in the table replace with an id from canonical home

extensions 

1) a: int id b 

a gets the value number of b. No copy required

2) : int add a b; for add sort value numbers so add a b; and add b a; get the same value number 

3) 

```
constant folding 
   a: int const 1;
   b: int const 2;
   c: add a b;
```
if both value numbers are pointing to constants- actually do the add


### pseudo code

 ```
    table = mapping from value tuples to canonical variables,
      with each row numbered
    var2num = mapping from variable names to their current
      value numbers (i.e., rows in table)

    for instr in block:
        value = (instr.op, var2num[instr.args[0]], ...)

        if value in table:
            # The value has been computed before; reuse it.
            num, var = table[value]
            replace instr with copy of var

        else:
            # A newly computed value.
            num = fresh value number

            dest = instr.dest
            if instr.dest  will be overwritten later:
                 dest = fresh variable name
                 instr.dest = dest
            else:
                 dest = instr.dest

            table[value] = num, dest

            for a in instr.args:
                replace a with table[var2num[a]].var

        var2num[instr.dest] = num
```

problem:   canonical variables being overwritten

``` x = a+b  
    x = 
      = a+b 

```

* Local value numbering.
 



You can see my implementation in `lvn.py` in [the examples directory] in the Bril repository. But seriously, don't be tempted! You want to write your implementation without looking at mine!

[examples](https://github.com/normrubin/bril/tree/main/examples)
### Testing Your Optimizations

As part of your tasks for this lesson, you will implement your first two optimizations.
The two main things you want your optimizations to do are:

1. Not break programs.
2. Make programs faster, most of the time.

As with every task in this class, part of the work is checking that you have done what you set out to do---in this case, that your optimizations do those two things.
Think carefully about how to make a convincing case for each of those criteria.

One tempting methodology might be to handwrite a few small test-case Bril programs (or, worse, borrow the woefully inadequate ones sitting around in the Bril git repository), run them through your optimizations, and look at them to check whether they look right.
This does not amount to convincing evidence (maybe you can think of a few specific reasons why).

While there are many ways to be convincing, a pretty good way might be to run your optimization on *every single available [Bril benchmark][bench]*,
systematically check that it still produces the right output for at least one input,
and collect aggregate statistics about some metric you're interested in.
This is a nice way to check for unexpected behavior in programs that you didn't carefully write yourself to test the cases you're thinking of.

If this is the route you choose, you can do it however you like, I have made a simple tool that you can consider using, called [Brench][].
Brench is not very fancy; it does three things:

1. It makes it easy to run a long list of inputs through several different commands. (For example, you can run a long list of Bril benchmarks through an "interpret" command and an "optimize-and-then-interpret" command.)
2. It checks that all the commands agree on their output. (So, in our use case, it checks that optimizing the benchmark doesn't change its output when interpreted.)
3. It can collect a statistic from each command for comparison. (Like the number of dynamic instructions the interpreter executed, which is a pretty good metric for standard optimizations.)

Those three things are probably what you want to do to make a convincing case for an optimization's correctness and effectiveness, whether or not you use Brench. It's there if you want it, but feel free to go your own way!

[bench]: https://capra.cs.cornell.edu/bril/tools/bench.html


