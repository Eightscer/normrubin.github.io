[
  {
    "objectID": "Class_Overview/about.html",
    "href": "Class_Overview/about.html",
    "title": "About",
    "section": "",
    "text": "This is the web site for eece 7398\n\n\n\n\n\n\nWarning\n\n\n\nfill in the about page\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Class Overview",
      "About"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html",
    "href": "Class_Overview/What_to_do.html",
    "title": "How to do assignments",
    "section": "",
    "text": "#How to How to do assignments",
    "crumbs": [
      "EECS 7398",
      "Class Overview",
      "How to do assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "href": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "title": "How to do assignments",
    "section": "Mechanics of writing a blog",
    "text": "Mechanics of writing a blog\nAssignments get submitted as blog postings. In setting up the class web site I used quarto which lets you write a blog post in markdown (no messy html required). I recommend you use it as well.",
    "crumbs": [
      "EECS 7398",
      "Class Overview",
      "How to do assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "href": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "title": "How to do assignments",
    "section": "submitting via pull requests",
    "text": "submitting via pull requests\nTo add a blog post (which you must do for discussion leading and project reports), use a pull request.\nYou’ll want to create a text file in the blog directory with your new post. Use a filename like YYYY-MM-DD-title.md, where the date is the discussion day or the project deadline and the title is up to you.\nList all the authors of your post. Include a link to your homepage if you have one, but it’s optional. Also write a short bio for yourselves (using Markdown), which will appear at the bottom of the post. Then, the rest of the text file is the Markdown text of your blog post.\nIf you want to use math in your blog post, you can use \\(\\pi\\) for inline math and [ e^{i} + 1 = 0 ] for display math.\nTo include images or other resources in your post, make your post into a directory. That is, make a new directory called YYYY-MM-DD-title inside blog. Then, put your text in a file called index.md inside that. Put your images in the same directory and refer to them with relative paths. See the QUARTO docs on for more details.\nYou can preview your writing with any Markdown renderer. To see what it will look like when published, install quarto and type quarto render to preview the entire site.\n\nHomeworks\nTo reinforce the specific compiler techniques we cover in class, you will implement them on your own. In lessons, we will discuss the high-level ideas and provide pseudo-code; your task is to translate these into working code and collect empirical evidence to demonstrate their effectiveness. Completing these implementations will reveal practical challenges that are not apparent from a high-level overview.\nTesting your implementation is crucial. Your goal is to provide convincing evidence that your implementation performs as intended. For instance, an optimization should generally make programs faster without causing any errors. While formal proofs of these properties are likely out of scope, you will need to find alternative ways to gather evidence. Avoid relying solely on existing test cases in the Bril repository, as they are typically insufficient. instead, consider using all the benchmarks available in the repo.\nYou may work individually or in groups of 2–3 students. Upon completing an implementation, follow these steps:\n\nConsider putting all your code online in an open-source repository, such as GitHub (optional but recommended). Create a fork of the class repository if desired.\nSubmit the assignment on Canvas by providing a text file with a URL to your open-source implementation. If you prefer not to open-source your code, you can upload the code itself.\nWrite a brief post in the lesson’s associated GitHub Discussions thread, covering the following topics (one paragraph each is sufficient):\n\nSummarize what you did.\nExplain how you tested your implementation. What test inputs did you use? Do you have any quantitative results?\nDescribe the hardest part of the task and how you addressed this challenge.\n\n\nEnsure all implementation tasks are your own work or done with your group. Although sample implementations for many tasks are available in the GitHub repository, you are not allowed to use this code. Similarly, you may not use implementations open-sourced by past 6120 students. I recommend not looking at these implementations while working on your tasks to ensure you genuinely learn the material. However, if you absolutely need to refer to them, you are responsible for managing your own learning process.\n\n\nPaper Reading & Discussion\nI’m not sure yet if the discussions will be on Canvas or GitHub Discussions.\nAnother part of this course involves reading and discussing research papers. For each paper (see the schedule), everyone will participate in the discussion in two ways: asynchronously on GitHub Discussions threads before class, and synchronously in class. For every paper, there will be a Discussions topic; post at least one message with your thoughts on the paper before the class discussion. Your comment doesn’t need to be long—just a couple of sentences is fine. You can also respond to others’ thoughts on the thread.\nFor some papers, you will be the discussion leader. Leaders have three extra responsibilities: monitoring and replying to the asynchronous discussion, moderating and guiding the in-class discussion, and synthesizing ideas into a blog post afterward.\nLeader Responsibilities\nAt least a week before the discussion day:\n1) Create a GitHub Discussions thread in the Reading category for your topic.\nDuring the lead-up to the discussion day:\n1) Monitor the GitHub Discussions thread for your topic. Answer questions and offer additional insights as needed.\n1) Collect a list of questions for the in-class discussion. You can create your own or select the best from the online discussion.\nOn the discussion day:\nModerate the discussion. Provide enough background to get to the discussion questions and facilitate the conversation.\nDue one week after the discussion day:\n\nWrite a post about the paper for our course blog. The post should include:\n\nBackground information necessary to understand the paper.\nA detailed summary of the main contributions.\nCritical analysis of the merits and shortcomings of the work.\nDiscussion of the paper’s role in history and its connections to the current computing landscape.\n\n\nIncorporate the best ideas from the online and in-class discussions. You can present your own opinions, the class consensus, or both.\n\n\nWriting the Blog Post\nWhile summarizing the paper, avoid letting direct summary dominate your post. Keep the technical explanation to about a quarter of the length. Prioritize breadth over depth in your summary, and highlight specific contributions instead of covering the entire paper.\nFocus most of your writing on your own commentary: context, criticism, and discussion. Choose a title for your blog post that reflects the main point you want to make about the paper, rather than just the paper’s title.\nFor inspiration, check out last cs6120 blog posts. However, avoid reading posts about your paper, if they exist.\nPublishing\nPublish the post to the course GitHub repository by opening a pull request. Once your PR is open, announce it on the appropriate Discussions thread to let others know.\nProposal The first deadline is the project proposal. Open a GitHub issue answering these three questions, which are a sort of abbreviated form of the Heilmeier catechism:\nWhat will you do? How will you do it? How will you empirically measure success? You should also list the GitHub usernames of everyone in the group. After you send the PR, submit its URL to the “Project Proposal” assignment on CMS.\nThe instructor will have feedback on how to approach your project.\nImplementation The main phase, of course, is implementing the thing you said you would implement. I recommend you keep a “lab notebook” to log your thoughts, attempts, and frustrations—this will come in handy for the report you’ll write about the project.\nI strongly recommend that you develop your code as an open-source project. Use a publicly-visible version control repository on a host like GitHub, and include an open source license. When you create your repository, comment on your proposal GitHub issue with a link. (If you have a specific objection to open-sourcing your code, that’s OK—include a description of how you’ll share your code privately with me.)\nEvaluation A major part of your project is an empirical evaluation. To design your evaluation strategy, you will need to consider at least these things:\nWhere will you get the input code you’ll use in your evaluation? How will you check the correctness of your implementation? If you’ve implemented an optimization, for example, “correctness” means that the transformed programs behave the same way as the original programs. How will you measure the benefit (in performance, energy, complexity, etc.) of your implementation? How will you present the data you collect from your empirical evaluation? Other questions may be relevant depending on the project you choose. Consider the SIGPLAN empirical evaluation guidelines when you design your methodology.\nExperience Report For the main project deadline, you will write up the project’s outcomes in the form of a post on the course blog. Your writeup should answer these questions in excruciating, exhaustive detail:\nWhat was the goal? What did you do? (Include both the design and the implementation.) What were the hardest parts to get right? Were you successful? (Report rigorously on your empirical evaluation.) As with paper discussions, you can optionally include a video to go along with your blog post.\nTo submit your report, open a pull request in the course’s GitHub repository to add your post to the blog. In your PR description, please include “closes #N” where N is the issue number for your proposal. The repository README has instructions.",
    "crumbs": [
      "EECS 7398",
      "Class Overview",
      "How to do assignments"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html",
    "href": "lectures/06_ssa.html",
    "title": "6 Static single Assignment",
    "section": "",
    "text": "A variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program\nin SSA we change our IR so that every variable has exactly one definition in the program (each variable is assigned only once). The name SSA is statically there is only a single assignment per variable.\n\n\nIn addition to a language form, SSA is also a philosophy! It can fundamentally change the way you think about programs. In the SSA philosophy:\n\ndefinitions == variables\ninstructions == values\narguments == data flow graph edges\n\nIn LLVM, for example, instructions do not refer to argument variables by name—an argument is a pointer to defining instruction.\nStatic means in the text, not in the execution.\n\n\n\n\n\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n\nvariable i has two static assignments 1 and 4, so this program is not in SSA\nVariable s has two static assignments, x has one static assignment but x has lots of dynamic assignments (when the program executes)\nWe call a program without branches a piece of *** straightline code***.\n    @main {\n      a: int = const 4;\n      b: int = const 2;\n      a: int = add a b;\n      b: int = add a b;\n      print b;\n    }\nIts easy to see how to convert straight line code into ssa\n    @main {\n      a.1: int = const 4;\n      b.1: int = const 2;\n      a.2: int = add a.1 b.1;\n      b.2: int = add a.2 b.1;\n      print b.2;\n    }\nfor each variable a: \n    Count[a] = 0 \n    Stack[a] = [0]\n\nrename_basic_block(B): \n    for each instruction S in block B: \n        for each use of a variable x in S: \n            i = top(Stack[x]) \n            replace the use of x with xi for each variable a that S defines count[a] = Count[a] + 1 \n            i = Count[a]             \n            push i onto Stack[a]             \n            replace definition of a with ai \nWe don’t need the stack here but we will need it later.\nOf course, things will get a little more complicated when there is control flow. And because real machines are not SSA, using separate variables (i.e., memory locations and registers) for everything is bound to be inefficient.\nThe idea in SSA is to convert general programs into SSA form, do all our optimization there, and then convert back to a standard mutating form before we generate backend code.\n\n\n\nJust renaming assignments willy-nilly will quickly run into problems. Consider this program:\n\n\n\n\n\ngraph TB\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\nIf we start renaming all the occurrences of a, everything goes fine until we try to write that last print a. Which “version” of a should it use?\nTo match the expressiveness of unrestricted programs, SSA adds a new kind of instruction: a ϕ-node. ϕ-nodes are flow-sensitive copy instructions: they get a value from one of several variables, depending on which incoming CFG edge was most recently taken to get to them.\nIn Bril, a ϕ-node appears as a phi instruction:\na.4: int = phi .left a.2 .right a.3;\nThe phi instruction chooses between any number of variables, and it picks between them based on labels. If the program most recently executed a basic block with the given label, then the phi instruction takes its value from the corresponding variable.\nYou can write the above program in SSA like this:\n    @main(cond: bool) {\n    .entry:\n        a.1: int = const 47;\n        br cond .left .right;\n    .left:\n        a.2: int = add a.1 a.1;\n        jmp .exit;\n    .right:\n        a.3: int = mul a.1 a.1;\n        jmp .exit;\n    .exit:\n        a.4: int = phi .left a.2 .right a.3;\n        print a.4;\n    }\n\n\n\nBril has an SSA extension It adds support for a phi instruction. Beyond that, SSA form is just a restriction on the normal expressiveness of Bril—if you solemnly promise never to assign statically to the same variable twice, you are writing “SSA Bril.”\nThe reference interpreter has built-in support for phi, so you can execute your SSA-form Bril programs without fuss.\n\n\n\nCompilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies.\n\n\n\n\n\ngraph TD;\nsubgraph a;\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    A0 --&gt; A2\n    A1--&gt; A2\n end\nsubgraph b;\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\nend\n\n\n\n\n\n\n\n\n\n\n\n\ngraph TB\nA0[\"L1\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1--&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\nwhere do we put the copy b2 = b0?\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors.\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge.\n\n\nVery simple scheme\n\n\n\n\n\ngraph TB\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX--&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nThere should be a phi-function for variable b at node z of the flow graph exactly when all of the following are true:\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other.\n\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work\nTo convert to SSA, we want to insert ϕ-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need ϕ-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition? The dominance frontier!\nThis is going to be almost linear\nWe do it in two steps. 1) insert ϕ-nodes: 1) rename variables:\n\n\n\n\n\ngraph TB\n\na--&gt;b\na--&gt; e\na--&gt; i\n\nb--&gt;c\nc--- c\nc--&gt; d\ne--&gt; f[\"f\n  x = \"]\ne--&gt; g\ng--&gt; h\nf--&gt; h\nh--&gt;l\nf--&gt; d\nh--&gt; e\ni--&gt; k\ni--&gt; j\nj--&gt; k\nk--&gt; l\nd--&gt; l\n\n\n\n\n\n\n\nWe need phi functions for x in d and h, where else?\nwe need to iterate and keep adding phi nodes\nfor each node in the cfg \n   for each variable with a def in node\n     add node to Defs[v]   # Blocks where v is assigned.\n\nfor each v in vars:\n    W = Defs[v]\n    while W is not empty\n      remove a node n from w\n         for block in DF[d]:  # Dominance frontier.\n           Add a ϕ-node to block,\n             unless we have done so already.\n           Add block to W (because it now writes to v!),\n             unless it's already in there.\nSince we keep adding nodes to W how do we know this terminates?\nThen, rename variables:\nrename(n):\n  rename_basic_block(n)  # from before \n  for each successor Y of n, where n is the jth pred of Y\n    for each phi-function f in Y where the operand of f is 'a'\n      i = top(stack[a])\n      replace jth operand wit a_i\n  for each child of X of n (in the dominator tree)\n    rename(X)\n    for each instruction S in n\n       pop stack(S.dest)\n\n   \nThe arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\n\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\n\ni is only live in blocks l2 and l4 so no need to add phi-node at l1, this gives us pruned ssa form\n\n\n\n\nOur previous analyses always used a (variable, program point), but in ssa these are the same\n\n\n\nwhile there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]\n\n\n\nwe define a partial order on consts, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is &gt; \n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn\nWhat order do we process nodes? because the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments\nB0: x  = input \n    a = 1 \n    c = a +10\n    if a &lt; c go to b1\n\nB1: b = x * a\n    print b \n    a = a +1 \n    go to b1\n\nin ssa form \n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a1,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nwalking the dominator tree b0 -&gt; b1\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 = 1 (only one input of phi is defined)\nb0 = any\na2 = 2\n\nupdate the uses of a2 - which is the phi a1 -&gt; any\nupdate the uses of a1 which is the increment no change \n\n\n\n## liveness \n\n![](images/StaticSingleAssignment_Part69.jpg)\n\n![](images/StaticSingleAssignment_Part70.jpg)\n\n![](images/StaticSingleAssignment_Part71.jpg)\n\n\n![](images/StaticSingleAssignment_Part73.jpg)\n\n\n\n\n### Converting from SSA\n\nEventually, we need to convert *out of* SSA form to generate efficient code for real machines that don't have `phi`-nodes and do have finite space for variable storage.\n\nThe basic algorithm is pretty straightforward.\nIf you have a ϕ-node:\n\n    v = phi .l1 x .l2 y;\n\nThen there must be assignments to `x` and `y` (recursively) preceding this statement in the CFG.\nThe paths from `x` to the `phi`-containing block and from `y` to the same block must \"converge\" at that block.\nSo insert code into the `phi`-containing block's immediate predecessors along each of those two paths:\none that does `v = id x` and one that does `v = id y`.\nThen you can delete the `phi` instruction.\n\nThis basic approach can introduce some redundant copying.\n(Take a look at the code it generates after you implement it!)\nNon-SSA copy propagation optimization can work well as a post-processing step.\nFor a more extensive take on how to translate out of SSA efficiently, see [“Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al.](https://hal.inria.fr/inria-00349925v1/document)\n\n\n\nits possible that an optimization can give overlapping phi-functions\nb0 x = 1 y = 2 B1 z = x x = y y = z if() go to b1\nin ssa form \n\nb0 x1 = 1 y1 = 2 B1 x2 = phi(x1,x3) y2 = phi(y1, y3) z = x2 x3 = y2 y3= z if() go to b1 ’’’’\noptimze it\n``` b0 x1 = 1 y1 = 2 B1 x2 = phi(x1, y2) y2 = phi(y1, x2) if() go to b1 ’’’’\nlost the temp (this is called the swap problem) if we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nSome SSA slides from Todd Mowry at CMU",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "6 Static single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#getting-out-of-ssa",
    "href": "lectures/06_ssa.html#getting-out-of-ssa",
    "title": "6 Static single Assignment",
    "section": "",
    "text": "Compilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies.\n\n\n\n\n\ngraph TD;\nsubgraph a;\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    A0 --&gt; A2\n    A1--&gt; A2\n end\nsubgraph b;\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\nend\n\n\n\n\n\n\n\n\n\n\n\n\ngraph TB\nA0[\"L1\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1--&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\nwhere do we put the copy b2 = b0?\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors.\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge.\n\n\nVery simple scheme\n\n\n\n\n\ngraph TB\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX--&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nThere should be a phi-function for variable b at node z of the flow graph exactly when all of the following are true:\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other.\n\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work\nTo convert to SSA, we want to insert ϕ-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need ϕ-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition? The dominance frontier!\nThis is going to be almost linear\nWe do it in two steps. 1) insert ϕ-nodes: 1) rename variables:\n\n\n\n\n\ngraph TB\n\na--&gt;b\na--&gt; e\na--&gt; i\n\nb--&gt;c\nc--- c\nc--&gt; d\ne--&gt; f[\"f\n  x = \"]\ne--&gt; g\ng--&gt; h\nf--&gt; h\nh--&gt;l\nf--&gt; d\nh--&gt; e\ni--&gt; k\ni--&gt; j\nj--&gt; k\nk--&gt; l\nd--&gt; l\n\n\n\n\n\n\n\nWe need phi functions for x in d and h, where else?\nwe need to iterate and keep adding phi nodes\nfor each node in the cfg \n   for each variable with a def in node\n     add node to Defs[v]   # Blocks where v is assigned.\n\nfor each v in vars:\n    W = Defs[v]\n    while W is not empty\n      remove a node n from w\n         for block in DF[d]:  # Dominance frontier.\n           Add a ϕ-node to block,\n             unless we have done so already.\n           Add block to W (because it now writes to v!),\n             unless it's already in there.\nSince we keep adding nodes to W how do we know this terminates?\nThen, rename variables:\nrename(n):\n  rename_basic_block(n)  # from before \n  for each successor Y of n, where n is the jth pred of Y\n    for each phi-function f in Y where the operand of f is 'a'\n      i = top(stack[a])\n      replace jth operand wit a_i\n  for each child of X of n (in the dominator tree)\n    rename(X)\n    for each instruction S in n\n       pop stack(S.dest)\n\n   \nThe arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\n\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\n\ni is only live in blocks l2 and l4 so no need to add phi-node at l1, this gives us pruned ssa form",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "6 Static single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#making-use-of-ssa-form",
    "href": "lectures/06_ssa.html#making-use-of-ssa-form",
    "title": "6 Static single Assignment",
    "section": "",
    "text": "Our previous analyses always used a (variable, program point), but in ssa these are the same",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "6 Static single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "href": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "title": "6 Static single Assignment",
    "section": "",
    "text": "while there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "6 Static single Assignment"
    ]
  },
  {
    "objectID": "lectures/06_ssa.html#sparse-constant-prop",
    "href": "lectures/06_ssa.html#sparse-constant-prop",
    "title": "6 Static single Assignment",
    "section": "",
    "text": "we define a partial order on consts, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is &gt; \n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn\nWhat order do we process nodes? because the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments\nB0: x  = input \n    a = 1 \n    c = a +10\n    if a &lt; c go to b1\n\nB1: b = x * a\n    print b \n    a = a +1 \n    go to b1\n\nin ssa form \n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a1,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nwalking the dominator tree b0 -&gt; b1\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 = 1 (only one input of phi is defined)\nb0 = any\na2 = 2\n\nupdate the uses of a2 - which is the phi a1 -&gt; any\nupdate the uses of a1 which is the increment no change \n\n\n\n## liveness \n\n![](images/StaticSingleAssignment_Part69.jpg)\n\n![](images/StaticSingleAssignment_Part70.jpg)\n\n![](images/StaticSingleAssignment_Part71.jpg)\n\n\n![](images/StaticSingleAssignment_Part73.jpg)\n\n\n\n\n### Converting from SSA\n\nEventually, we need to convert *out of* SSA form to generate efficient code for real machines that don't have `phi`-nodes and do have finite space for variable storage.\n\nThe basic algorithm is pretty straightforward.\nIf you have a ϕ-node:\n\n    v = phi .l1 x .l2 y;\n\nThen there must be assignments to `x` and `y` (recursively) preceding this statement in the CFG.\nThe paths from `x` to the `phi`-containing block and from `y` to the same block must \"converge\" at that block.\nSo insert code into the `phi`-containing block's immediate predecessors along each of those two paths:\none that does `v = id x` and one that does `v = id y`.\nThen you can delete the `phi` instruction.\n\nThis basic approach can introduce some redundant copying.\n(Take a look at the code it generates after you implement it!)\nNon-SSA copy propagation optimization can work well as a post-processing step.\nFor a more extensive take on how to translate out of SSA efficiently, see [“Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al.](https://hal.inria.fr/inria-00349925v1/document)\n\n\n\nits possible that an optimization can give overlapping phi-functions\nb0 x = 1 y = 2 B1 z = x x = y y = z if() go to b1\nin ssa form \n\nb0 x1 = 1 y1 = 2 B1 x2 = phi(x1,x3) y2 = phi(y1, y3) z = x2 x3 = y2 y3= z if() go to b1 ’’’’\noptimze it\n``` b0 x1 = 1 y1 = 2 B1 x2 = phi(x1, y2) y2 = phi(y1, x2) if() go to b1 ’’’’\nlost the temp (this is called the swap problem) if we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nSome SSA slides from Todd Mowry at CMU",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "6 Static single Assignment"
    ]
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html",
    "href": "lectures/13_dynamic_compilers.html",
    "title": "13_dynamic_compielrs",
    "section": "",
    "text": "Warning\n\n\n\nnot done\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "13_dynamic_compielrs"
    ]
  },
  {
    "objectID": "lectures/110_whole_program.html",
    "href": "lectures/110_whole_program.html",
    "title": "11 Whole program",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "11 Whole program"
    ]
  },
  {
    "objectID": "lectures/14_gpu_compilers.html",
    "href": "lectures/14_gpu_compilers.html",
    "title": "14_gpu_compilers",
    "section": "",
    "text": "Warning\n\n\n\nnot done\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "14_gpu_compilers"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html",
    "href": "lectures/04_data_flow.html",
    "title": "4. Data Flow",
    "section": "",
    "text": "We will see a single algorithm that can do lots of different analysis. And it works no matter what kind of control flow.\nThere is some theory to look at for this. How do we know if the algorithm will converge for any possible cfg.\nand some naming for each kind of problem\n\n\n\n\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \n     A[\"1: main cond\n   2: a int = const 47\n   3: b :int = const 42\n   4:br cond .left .right\"] \n   \n   B[\"5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A  -- true --&gt; B\n    A  --false --&gt; C\n    B --&gt; D\n    C --&gt; D",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "4. Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#reasoning-about-data-flow-global-analysis",
    "href": "lectures/04_data_flow.html#reasoning-about-data-flow-global-analysis",
    "title": "4. Data Flow",
    "section": "",
    "text": "We will see a single algorithm that can do lots of different analysis. And it works no matter what kind of control flow.\nThere is some theory to look at for this. How do we know if the algorithm will converge for any possible cfg.\nand some naming for each kind of problem\n\n\n\n\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \n     A[\"1: main cond\n   2: a int = const 47\n   3: b :int = const 42\n   4:br cond .left .right\"] \n   \n   B[\"5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A  -- true --&gt; B\n    A  --false --&gt; C\n    B --&gt; D\n    C --&gt; D",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "4. Data Flow"
    ]
  },
  {
    "objectID": "lectures/04_data_flow.html#first-we-are-going-to-look-at-a-fg-specific-problem-reaching-definitions",
    "href": "lectures/04_data_flow.html#first-we-are-going-to-look-at-a-fg-specific-problem-reaching-definitions",
    "title": "4. Data Flow",
    "section": "first we are going to look at a fg specific problem “reaching definitions”",
    "text": "first we are going to look at a fg specific problem “reaching definitions”\nReaching definitions are an example of a global property that require you to look at an entire CFG.\nUse: An instruction uses all of its arguments. (So any instruction with arguments is a “use.”), a binary instruction is two uses.\nA definition is place in the program that assigns a value to an instruction. For Bril, a definition is a value instruction (has a dest or an argument)\nThe above program has 8 definitions, Which we could represent by a bit vector of size 8.\nA definition D reaches a point P (instruction) in the program if there is an execution path from D to P, and the variable in D is not overwritten on the path.\nAvailable: Definitions that reach a given point in the program are available at that point.\nif an instruction writes a variable it kills all prior definitions that write the same variable\n\nReaching definitions problem determine which definitions reach which uses.\nWe could build a 2d matrix - definitions by uses, where a 1 bit indicates that this definition reaches this use. As a matrix this would be very sparse, later when we do ssa forms will see a very cool compression technique. Algorithms that use this kind of matrix are called bit-vector methods.\nA program point is an instruction\na definition of a variable v reaches a program point p if and only if:\n\nthe definition reaches the point just before p\nthe variable v is not redefined at p\n\nor\n\nthe variable v is defined at p.\n\nWhat about multiple predecessors? p is the first instruction of a block with multiple preds.\nIf a definition reaches a point immediately after at least one pred of p then it reaches the point immediately before p. This is a union operation.\nWe are moving information down from definition. This is called forward propagation\nDefine two sets IN and OUT that hold definitions\nIN is the set of definitions that reach a point immediately before p\nOUT is the set of definitions that reach a point immediately after p\nTo illustrate this, I”ll use pairs (variable, def) for each set, but the def already includes the variable so real implementations can just use the def.\n\n\n\n\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \nA_IN[\"A_IN={}\"]\nA_OUT[\"A_OUT={(cond,1),(a,2),(b,3)}\"]\n\nB_IN[\"B_IN={(cond,1),(a,2),(b,3)}\"]\nB_OUT[\"B_OUT={(cond,1),(a,2),(b,5),(c,6)}\"]\n\nC_IN[\"IN={(cond,1),(a,2),(b,3)}\"]\nC_OUT[\"OUT={(cond,1),(a,8),(b,3,(c,9)}\"]\n\nD_IN[\"IN={(cond,1),(a,2),(a,8) (b,5), (b,3), (c,6), (c,9)}\"]\n\n  A[\"blk a\n    1: main cond\n   2: a int = const 47\n   3: b :int = const 42\n   4:br cond .left .right\"] \n   \n   B[\"blk b\n   5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"blk c\n     8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A_IN --&gt; A \n    A --&gt; A_OUT\n    A_OUT  -- true --&gt; B_IN\n    B_IN --&gt; B\n    B --&gt; B_OUT\n    A_OUT --false --&gt; C_IN\n    C_IN --&gt; C\n    C--&gt;   C_OUT\n    B_OUT--&gt; D_IN\n    C_OUT--&gt; D_IN\n    D_IN --&gt; D\n\n\n\n\n\n\nFor a given block b, we can compute two sets:\n\nkill(b) = all defs in the program that assign to y, and there is a def of y in b\n\ngen(b) = definitions in b that reach the bottom of b\n\nAnd now globally:\n\nOUT(b) = (in(b) - kill(b) ) union gen(b)\nIN(b) = union of OUT(pred) where pred is a predecessor of b\n\nWe call the function for 1 the transfer function for the block, and the function for 2 the merge function\nWe can solve for IN and OUT iteratively using a worklist\n// Initialize\nfor all CFG nodes n in N,\n    OUT[n] = emptyset; // can optimize by OUT[n] = GEN[n];\n\n// put all nodes into the changed set\n// N is all nodes in graph,\nChanged = N;\n\n// Iterate \nwhile (Changed != emptyset)\n{\n    choose a node n in Changed;\n    // remove it from the changed set\n    Changed = Changed -{ n };\n\n    // init IN[n] to be empty\n    IN[n] = emptyset;\n  \n    // calculate IN[n] from predecessors' OUT[p]\n    for all nodes p in predecessors(n)\n         IN[n] = IN[n] Union OUT[p];\n\n    oldout = OUT[n]; // save old OUT[n]\n    \n    // update OUT[n] using transfer function f_n ()\n    OUT[n] = GEN[n] Union (IN[n] -KILL[n]);\n\n    // any change to OUT[n] compared to previous value?\n    if (OUT[n] changed) // compare oldout vs. OUT[n]\n    {    \n        // if yes, put all successors of n into the changed set\n        for all nodes s in successors(n)\n             Changed = Changed U { s };\n    }\n}\n\nDoes this always converge?\nwhat order do we want to select nodes (basic blocks)?\nvisit a node after visiting its preds. Revese post order.\n\n\na second problem liveness-\nA variable is live at some point if it holds a value that may be needed in the future, or equivalently if its value may be read before the next time the variable is written to.\n             live = {}\nb = 3        live = b\nc = 5        live = b c \na = f(b * c) live = a\nWe had to consider flow starting at the bottom so this is a backwards analysis\nfor a basic block (b):\n\nGEN(s) the set of variables used in s before any assignment to s in the same block\nkill(s) the set of variables assigned in s\n\nglobal\n\nOUT(exit) = {}\nIN(b) = gen(b) union ( OUT(b) - KILL(b))\nOUT(b) = union IN(b)\n\nAn example\n// in: {}; predecessor blocks: none\nb1: a = 3; \n    b = 5;\n    d = 4;\n    x = 100; //x is never being used later thus not in the out set {a,b,d}\n    t = a &gt; b\n    br t .t .f \n   // out: {a,b,d}    //union of all (in) successors of b1 =&gt; b2: {a,b}, and b3:{b,d}  \n\n\n\n.t   // in: {a,b}; predecessor blocks: b1\nb2: c = a + b;\n    d = 2;\n// out: {b,d}\n\n\n.f \nb3:  in: {b,d}; predecessor blocks: b1 and b2\n    c = 4;\n    return b * d + c;\n// out:{}\nThis can be solved using the same code as before, flip pred, successors because its backward, reverse in and out, set elements are variable names\ndata flow framework\nThe data flow framework. Here’s how you solve a global analysis problem by imbuing a local analysis with a dose of data-flow magic:\n\nFigure out the thing you want to know at the entry and exit of each block.\nWrite an equation for every block relating that thing at the entry to that thing at the exit. (In general, this is a local analysis for the block.), calculate GEN and KILL\nGenerate equalities according to the edges in the CFG.\nSolve the system of equations! (Using a general solver algorithm that you don’t need to adapt to every problem.)\n\nstep 2 only looks at a single block, the iteration does not need to refigure out GEN and KILL\nThis algorithm has no problems with loops!\nTheory – the requirements for a general data flow analysis. How do you know the worklist algorithm terminates and gives you the right answer?\nThe domain of values you’re trying compute needs to form a partial order with a unique lower bound. The rough idea is that the worklist algorithm should only “move” values monotonically in the order, so it’s guaranteed to eventually terminate.\nIn terms of a partial order ⊑, the merge function is the meet (greatest lower bound) operator ⊓; the initial value is the top value ⊤; and the transfer function must be a monotonic function, so x ⊑ y implies f(x) ⊑ f(y).\nThe usual definition of a “correct” solution to a data-flow problem is the meet-over-all-paths solution: the meet of chained applications of the transfer functions for every path in the CFG from the entry block to any given block\nMore examples of things you can do with the data flow framework. 1) Reaching definitions. 1) Live variables: which variables are both defined and going to be used at some point in the future? 1) Constant propagation: which variables have statically knowable constant values? 1) Available expressions: which expressions have already been computed computed in the past? (Useful in CSE.) 1) Initialized variables: like in Java, which variables have had something written to them? 1) Interval analysis: what is the numerical range of values that a given variable might hold?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "4. Data Flow"
    ]
  },
  {
    "objectID": "lectures/03_local.html",
    "href": "lectures/03_local.html",
    "title": "3 Local Analysis & Optimization",
    "section": "",
    "text": "I want to separate 3 flavors of optimization.\nUsually an optimization takes time that is more then linear in some property, For example a local optimization might take time \\(n^2\\) in the number of instructions in the block. a global optimization might take much longer, and an inter-procedural longer still. To keep compile time reasonable many compilers limit the number of global optimizations and skip inter-procedural optimizations. As a consequence many more optimizations get published but not used in production.\nFor a local optimization, instructions within a block are ordered, so it makes sense to talk about instructions coming before or after others.\nFor a global optimization, two instructions are ordered by a path from one block to another and different paths through the program give different orders.\nOne special case is JIT (just in time) compilers, where programs get compiled at the start of execution. GPU compilers (and java compilers) look like this. They may use run-time information to decide of recompiling a function is a good idea. This is called Hotspot compiling. Some JIT compilers use hot/cold compiling, where they only run the fancy compiler on basic blocks that are hotl, i.e., execute a lot.\nflowchart LR\nA[application] -- offline --&gt; B[byte code/ptx]\nB --&gt; C[quick run time compiler/ finalizer]\nC --&gt; D[isa]\nB --&gt; C1[fancy compiler - only run on long running functions];\nC1 --&gt; D;\nWe are going to consider several versions of trivial dead code elimination. Trivial because we are going to hold off on control flow related optimizations till later. Sometimes people call this DCE or trivial DCE.\nFor each case, we start by defining what we mean by dead code.\nexample 1\nWhat instruction is dead? (meaning get the same answer if we delete the instruction) What is your definition? Is this meaning of dead code local or global?\nWhy would you ever have dead code in a program? One reason is that have DCE as a separate pass means other optimizations do not have to clean up.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "3 Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "href": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "title": "3 Local Analysis & Optimization",
    "section": "Definition 1- Dead if instruction writes a variable and the variable is never used.",
    "text": "Definition 1- Dead if instruction writes a variable and the variable is never used.\nAn instruction that has side-effects, like a print statement does not write a variable so it never gets deleted. Labels no not write a variable so they get deleted as well.\nWhat is the pseudo code to find dead instructions using this definition?\nused = empty set \nfor instr in func \n   used += instr.args \nfor instd in func\n    if instr has a dest and dest in not in used \n       delete instr\nexample 2\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;  \n  d: int = add a b;\n  e: int = add c d; \n  print d;\n}\nThe code so far only deletes one instruction, but we would like to get rid of two. Instruction c should also be dead. How do we change the definition",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "3 Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "href": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "title": "3 Local Analysis & Optimization",
    "section": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "text": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.\nA slow way to do this. - iterating till convergence\nwhile changes:\n       run one pass of tdce above\nwhat would be faster? What is some pseudo code for the change\nexample 3\n@main {\n  a: int = const 4;\n  a: int = const 200;\n  print a;\n}",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "3 Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "title": "3 Local Analysis & Optimization",
    "section": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v",
    "text": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v\nthis talks about paths (control flow paths)\n@main {\n  a: int = const 4;\n     br input .then .else \n  .then\n  a: int = const 200;\n  .else \n  print a;\n}\nfor now we want to skip control flow, so we",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "3 Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "title": "3 Local Analysis & Optimization",
    "section": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\ncands are the variables that are defined but not used \nlast_def = {}  variables -&gt; instructions \nthis is a mapping variables that have been defined but not used\n\n   for instr in block:\n      each arg (use) removes arg from last def \n      if the instr has a dest \n          if the dest is in last_def, \n      add dest-&gt;instr to last def\n  \nand as you might expect, we need to interate this till convergence\nDoes running dce make compilation time go up?\nCompilers often run dce more then once- why?\ntesting out dce\n\nprogram should get the same answer\nprogram should run less instructions\n\nSome test cases:\n\nsimple.bril,\nreassign.bril,\nother examples in the DCE test directory\n\nbril2json &lt; bench.bril | python3 tdce.py | bril2txt\nNext, try using wc to check static code size differences:\nbril2json &lt; bench.bril | wc -l\nbril2json &lt; bench.bril | python3 tdce.py | wc -l\nThen profiling to measure dynamic instruction count: The bril interpreter has a flag -p which prints the number of dynamcially executed instructions. How good a measure is this for real programs?\nbril2json &lt; bench.bril | brili -p\n\nbril2json &lt; bench.bril | python3 tdce.py | brili -p\nname = “slides from Phil Gibbons at CMU” url = “http://www.cs.cmu.edu/afs/cs/academic/class/15745-s19/www/lectures/L3-Local-Opts.pdf” details = “for more details and context on LVN",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "3 Local Analysis & Optimization"
    ]
  },
  {
    "objectID": "lectures/bril.html",
    "href": "lectures/bril.html",
    "title": "bril.ipynb",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "bril.ipynb"
    ]
  },
  {
    "objectID": "lectures/02a_representation.html",
    "href": "lectures/02a_representation.html",
    "title": "2 Representation",
    "section": "",
    "text": "#| echo: false from graphviz import Digraph import ast import os\ndef cmd(x): os.system(x)\ndef ast_syntax(line): return ast.dump(ast.parse(line).body[0], indent=4)\n\nDefine a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None): node_name = str(node.__class__.__name__) dot.node(str(id(node)), node_name) if parent: dot.edge(str(id(parent)), str(id(node))) for child in ast.iter_child_nodes(node): add_node(dot, child, node)\n\n\nAdd nodes to the Digraph\ndef graph(line): dot = Digraph() add_node(dot, ast.parse(line).body[0]) return dot\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "2 Representation"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html",
    "href": "lectures/01a_performance_measurement.html",
    "title": "__ Performance and Measurement",
    "section": "",
    "text": "##example 1\nlets look at the paper\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\no avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\nA sample blog post about this paper blog\n\n\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "__  Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#another-example",
    "href": "lectures/01a_performance_measurement.html#another-example",
    "title": "__ Performance and Measurement",
    "section": "",
    "text": "Strangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "__  Performance and Measurement"
    ]
  },
  {
    "objectID": "lectures/revealjs-performance.html#another-example",
    "href": "lectures/revealjs-performance.html#another-example",
    "title": "__ Performance and Measurement",
    "section": "another example",
    "text": "another example\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines"
  },
  {
    "objectID": "lectures/07_llvm.html",
    "href": "lectures/07_llvm.html",
    "title": "7 LLVM",
    "section": "",
    "text": "intro to llvm\ndifference between bril and llvm\nlinks\nllvm page\nAdrians tutorial\nllvm doc\ngoogle or github pilot is very useful for this\n\n#as a first step I'm going to show how to install clang and cmake \n\n# step remove any old copies \n# the -S flag to sudo means - read from stdinput\n# the -y flag means always ans yes to apt \n# since sudo needs a password \n# -qq is the very quiet option \n!sudo -S apt purge -y -qq clang cmake &lt;  ~/pw\n!sudo -S apt install -y -qq clang cmake &lt; ~/pw\n\n\n[sudo] password for norm: The following packages were automatically installed and are no longer required:\n  cmake-data dh-elpa-helper emacsen-common libarchive13 libjsoncpp25 librhash0\nUse 'sudo apt autoremove' to remove them.\nThe following packages will be REMOVED:\n  clang* cmake*\n0 upgraded, 0 newly installed, 2 to remove and 48 not upgraded.\nAfter this operation, 21.3 MB disk space will be freed.\n\n(Reading database ... 40226 files and directories currently installed.)\nRemoving clang (1:14.0-55~exp2) ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Progress: [ 22%] [############..............................................] Progress: [ 33%] [###################.......................................] Progress: [ 44%] [#########################.................................] emoving cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] Progress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n[sudo] password for norm: Suggested packages:\n  cmake-doc ninja-build cmake-format\nThe following NEW packages will be installed:\n  clang cmake\n0 upgraded, 2 newly installed, 0 to remove and 48 not upgraded.\nNeed to get 0 B/5014 kB of archives.\nAfter this operation, 21.3 MB of additional disk space will be used.\n\nSelecting previously unselected package clang.\n(Reading database ... 40203 files and directories currently installed.)\nPreparing to unpack .../clang_1%3a14.0-55~exp2_amd64.deb ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Unpacking clang (1:14.0-55~exp2) ...\nProgress: [ 22%] [############..............................................] electing previously unselected package cmake.\nPreparing to unpack .../cmake_3.22.1-1ubuntu1.22.04.2_amd64.deb ...\nProgress: [ 33%] [###################.......................................] Unpacking cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 44%] [#########################.................................] etting up clang (1:14.0-55~exp2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] etting up cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n\n\nlets take a look at llvm ir\n\n%%writefile temp.c\nint main(int argc, char** argv){\n    return argc;\n}\n\nOverwriting temp.c\n\n\n\n# call clang and dump the ir\n# # -emit-llvm  print the ir\n# -S print as text not as binary \n# 0 -  output to stdout \n# \n!clang -emit-llvm -S -o - temp.c\n\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"frame-pointer\"=\"all\" \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\n!llvm.ident = !{!5}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 7, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"PIE Level\", i32 2}\n!3 = !{i32 7, !\"uwtable\", i32 1}\n!4 = !{i32 7, !\"frame-pointer\", i32 2}\n!5 = !{!\"Ubuntu clang version 14.0.0-1ubuntu1.1\"}\n\n\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThere is a cs6120 package that makes setting up the build process for plugins simple\nllvm ir, has two forms .bc files are bitcode, .ll forms are text versions that look like assembly.\nllvm is not written in C++ but it has a lot of features that look like C++.\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\n\n\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions so if I is an instruction\nouts() &lt;&lt; *(I.getOperand(0)) ; prints an instruction\nGiven a Value* V, what kind of thing is V?\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument\n\nStatic bool isLoopInvariant(const Value *V, const Loop *L) { \n    if (isa&lt;Constant&gt;(V) || isa&lt;Argument&gt;(V) || isa&lt;GlobalValue&lt;(V)) {\n         return true; } \n    //otherwise it must be an instruction…    \n    return !L-&gt;contains(cast&lt;Instruction&gt;(V)-&gt;getParent());\n     … \n}\nNavigating llvm IR - IT Containers\n\nModule - two way linked list of Functions\nFunction - two way linked list of Basic Blocks\nBasic Block - two way linked list of Instructions\n\n%5 = add i32 %4,2\nthis instruction adds two 32 bit ints, input is in register %4 and the constant 2, result goes into register %5\nblog post: Why would a grad student care about llvm\n\n%%bash \nrm -r llvm-pass-skeleton/\ngit clone   https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n# look at  llvm-pass-skeleton/skeleton/Skeleton.cpp\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\nThe function returns PreservedAnalyses::all() to indicate that it didn’t modify M. Later, when we actually transform the program, we’ll need to return something like PreservedAnalyses::none().\nThe ModuleAnalysisManager is responsible for managing the analysis results for Module passes.\nWhen a pass requests an analysis, the ModuleAnalysisManager checks if the analysis result is already available. If it is, the ModuleAnalysisManager returns the cached result. If it’s not, the ModuleAnalysisManager runs the analysis pass, caches the result, and then returns it.\nThis allows LLVM to avoid recomputing analysis results unnecessarily, which can significantly improve the performance of the compiler.\nHere’s an example of how you might use it:\nPreservedAnalyses MyPass::run(Module &M, ModuleAnalysisManager &MAM) {\n    // Request an analysis result.\n    const auto &Result = MAM.getResult&lt;SomeAnalysis&gt;(M);\n\n    // Use the analysis result.\n    // ...\n\n    return PreservedAnalyses::all();\n}\nHere is a second example getting the dominator tree\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Request the dominator tree of the function.\n            const DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Use the dominator tree.\n            // ...\n        }\n\n        return PreservedAnalyses::all();\n    }\nnow let look at the containers\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b containers  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\nError while terminating subprocess (pid=71626): \n[100%] Built target SkeletonPass\n\n\n\n# run the plugin \n# \n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp.c\n\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  ret i32 %6\nI saw a function called main!\n\n\n\n%%writefile temp1.c\nint main(int argc, char** argv){\n    if (argc &gt;2 )\n        return argc;\n    return 0;\n}\n\nOverwriting temp1.c\n\n\n\n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp1.c\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  %7 = icmp sgt i32 %6, 2\nInstruction: \n  br i1 %7, label %8, label %10\nBasic block:\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\nInstruction: \n  %9 = load i32, i32* %4, align 4\nInstruction: \n  store i32 %9, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\nInstruction: \n  %12 = load i32, i32* %3, align 4\nInstruction: \n  ret i32 %12\nI saw a function called main!\n\n\n\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\n[100%] Built target SkeletonPass\n\n\n\n%%bash \ncat ls ~/llvm/llvm-pass-skeleton/skeleton/Skeleton.cpp \necho done\n\ncat: ls: No such file or directory\n\n\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/Transforms/Utils/BasicBlockUtils.h\"\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}\ndone\n\n\n\n%%bash \ncat /home/norm/llvm/llvm-pass-skeleton/rtlib.c\necho\n\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}\n\n\n\n\n%%writefile llvm-pass-skeleton/test_r.cpp\n#include &lt;stdio.h&gt;\nint main (int argc, char** argv) {\n    printf(\"%d %d\", argc, (argc + 2) * (argc +3));\n}\n\nOverwriting llvm-pass-skeleton/test_r.cpp\n\n\n\n%%bash \ncd llvm-pass-skeleton/\ncc -c rtlib.c\nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test_r.cpp\ncc test_r.o rtlib.o\n./a.out 1 2 3 4\necho \n\ncomputed: 7\n5 56\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "7 LLVM"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "EECS 7398 Fall 2024\nInstructor: Dr. Norman Rubin\nemail: n.rubin@northeastern.edu\n\n\n\n\n\n\nWarning\n\n\n\nOffice hours: TBA\nWhere TBA\nOffice hours by appointment\n\n\n“This course draws heavily from the CS6120 Advanced Compilers course at Cornell University.” Special thanks to Adrian Sampson for granting permission to use his course materials.\nYou can find videos of Adrian Sampson’s lectures on the CS6120 self-guided page. These videos provide an in-depth explanation of many topics we’ll cover in this course.\nI want to take a moment to address an important aspect of this course: its evolving nature. Since this is the first time this course is being offered, please be aware that both the schedule and assignments may change as we progress.\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/02aa_reps.html",
    "href": "notebooks/02aa_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02aa_reps.html#a-more-regular-representation",
    "href": "notebooks/02aa_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02_reps.html",
    "href": "notebooks/02_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02_reps.html#a-more-regular-representation",
    "href": "notebooks/02_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/bril.html",
    "href": "notebooks/bril.html",
    "title": "overview of Bril",
    "section": "",
    "text": "How to use Bril with real code\nBril is very simple, very regular, ir. Bril can be extended easily.\nBril has lots of tools and examples.\nlets look at a bril program.\nBril is written in JSON format. Almost all programming languages have a way to read json.\n\nimport json\nimport subprocess\nimport os \n\nwith open(\"tests/add.json\", \"r\") as f:\n    bril_program = json.load(f)\n\n# print the json with nice indenting\nprint(json.dumps(bril_program, indent=2))\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        }\n      ],\n      \"args\": []\n    }\n  ]\n}\n\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}\nThere is also a text form which is more readable\nwe have program bril2txt and bril2json that make it easy to convert. Keep in mind that the json format is Bril and thats where you will do all the work.\n\nimport os \nos.system(\"bril2txt &lt; tests/add.json\")\n\n@main {\n  v0: int = const 1;\n  v1: int = const 2;\n  v2: int = add v0 v1;\n  print v2;\n}\n\n\n0\n\n\n\n!bril2txt &lt; tests/add.json\n\n@main {\n  v0: int = const 1;\n  v1: int = const 2;\n  v2: int = add v0 v1;\n  print v2;\n}\n\n\n\n# you can connect tools via pipes \nos.system(\"bril2txt &lt; tests/add.json | bril2json\")\n\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\n          \"dest\": \"v0\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 1\n        },\n        {\n          \"dest\": \"v1\",\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"value\": 2\n        },\n        {\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ],\n          \"dest\": \"v2\",\n          \"op\": \"add\",\n          \"type\": \"int\"\n        },\n        {\n          \"args\": [\n            \"v2\"\n          ],\n          \"op\": \"print\"\n        }\n      ],\n      \"name\": \"main\"\n    }\n  ]\n}\n\n\n0\n\n\nBril tools were mostly student projects, as you think about your projects, you might consider adding a new tool. you can setup Bril on your local linux (wsl) machine by cloning the bril github and installing all the tools\n\n# Bril has an interpreter which reads in json and output the result\n\nos.system(f'brili &lt;tests/add.json')\n\n3\n\n\n0\n\n\nLets write a sample program - generating the cfg\nI’ll do this in two steps 1) find all the basic blocks 2) add all the cfg edges\nfinding the basic blocks from a list of instructions-\nkeep adding instructions till we get to a terminator or a label (do we add labels?)\nin: list of instrs \nout: list of lists of instrs \n\nblocks = []\ncurr_block = []\nfor each instr in list \n   if the instruction is not a label put it on curr_block\n   if instr is a label or terminator \n      put curr_block on blocks\n      curr_block = []\n\nif curr_block is not empty add it to blocks\nreturn blocks \nfind cfg: in is bril progmam in json \nfor each function find the list of instructions \n    get last_instr \n    if it is a terminator  br/jmp/ret  \n    --- what do we want to do with call? \n    else it is a fall through\nwe need a map (block_map) label-&gt;block so we can add edges for blocks that end in br/jmp - can build this while getting the blocks or we can put the label as the first instruction\nhow do we get fall through?\nwhat about a return\nif every block ends with a terminator, and every block has a label, then no fall through case what happens if try to delete the terminator (because the block never executes)\nI’ll use a python data structure called OrderedDict, when you iterate over the items in a ordered dict, they come back in the order that they were installed.\n\n# playing around with hacking- I'll use a generator \n\n\n#Instructions that terminate a basic block.\nTERMINATORS = 'br', 'jmp', 'ret'\n\n\ndef form_blocks(instrs):\n    \"\"\"Given a list of Bril instructions, generate a sequence of\n    instruction lists representing the basic blocks in the program.\n\n    Every instruction in `instr` will show up in exactly one block. Jump\n    and branch instructions may only appear at the end of a block, and\n    control can transfer only to the top of a basic block---so labels\n    can only appear at the *start* of a basic block. Basic blocks may\n    not be empty.\n    \"\"\"\n\n    # Start with an empty block.\n    cur_block = []\n\n    for instr in instrs:\n        if 'op' in instr:  # It's an instruction.\n            # Add the instruction to the currently-being-formed block.\n            cur_block.append(instr)\n\n            # If this is a terminator (branching instruction), it's the\n            # last instruction in the block. Finish this block and\n            # start a new one.\n            if instr['op'] in TERMINATORS:\n                yield cur_block\n                cur_block = []\n\n        else:  # It's a label.\n            # End the block here (if it contains anything).\n            if cur_block:\n                yield cur_block\n\n            # Start a new block with the label.\n            cur_block = [instr]\n\n    # Produce the final block, if any.\n    if cur_block:\n        yield cur_block\n\n\ndef print_blocks(bril):\n    \"\"\"Given a Bril program, print out its basic blocks.\n    \"\"\"\n\n\n    func = bril['functions'][0]  # We only process one function.\n    for block in form_blocks(func['instrs']):\n        # Mark the block.\n        leader = block[0]\n        if 'label' in leader:\n            print( f\"block {leader['label']}\")\n            block = block[1:]  # Hide the label, for concision.\n        else:\n            print('anonymous block:')\n\n        # Print the instructions.\n        for instr in block:\n            print(instr)\n\n\nprint_blocks(bril_program)\n\nanonymous block:\n{'op': 'const', 'type': 'int', 'dest': 'v0', 'value': 1}\n{'op': 'const', 'type': 'int', 'dest': 'v1', 'value': 2}\n{'op': 'add', 'type': 'int', 'dest': 'v2', 'args': ['v0', 'v1']}\n{'op': 'print', 'args': ['v2']}\n\n\n\nwith open(\"tests/jmp.bril\", 'r') as f:\n          test2 = f.read()\n\nprint(test2)\n\n\nresult = subprocess.check_output('bril2json &lt;tests/jmp.bril', shell=True)\n\ntest2json = json.loads(result)\nprint(test2json)\n\n@main {\n  v: int = const 4;\n  jmp .somewhere;\n  v: int = const 2;\n.somewhere:\n  print v;\n}\n\n{'functions': [{'instrs': [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}, {'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}, {'label': 'somewhere'}, {'args': ['v'], 'op': 'print'}], 'name': 'main'}]}\n\n\n\nprint_blocks(test2json['functions'][0])\n\nKeyError: 'functions'\n\n\n\n# now for the map \nfrom collections import OrderedDict\n\n\ndef block_map(blocks):\n    \"\"\"Given a sequence of basic blocks, which are lists of instructions,\n    produce a `OrderedDict` mapping names to blocks.\n\n    The name of the block comes from the label it starts with, if any.\n    Anonymous blocks, which don't start with a label, get an\n    automatically generated name. Blocks in the mapping have their\n    labels removed.\n    \"\"\"\n    by_name = OrderedDict()\n\n    for block in blocks:\n        # Generate a name for the block.\n        if 'label' in block[0]:\n            # The block has a label. Remove the label but use it for the\n            # block's name.\n            name = block[0]['label']\n            block = block[1:]\n        else:\n            # Make up a new name for this anonymous block.\n            name = f'gen_bk_{len(by_name)}'\n\n        # Add the block to the mapping.\n        by_name[name] = block\n\n    return by_name\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\nfor (name, instrs) in od.items():\n    print (name, instrs)\n\ngen_bk_0 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}]\ngen_bk_1 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}]\nsomewhere [{'args': ['v'], 'op': 'print'}]\n\n\n\nfinally the cfg\nout cfg = {} map label -&gt; list of labels the successors of the block\n\nfor i , block in enumerate(blocks)  # blocks is a ordereddict \n  last = block[i]  # last instruction\n  if last is jmp:\n     cfg[block_name] = jmp.dest\n  elif last is br:\n    cfg[block.name] = [ last.if_label, last.else_label]\n  else\n     # fall through\n    cfg[block_name = blocks[i+1].name  ## special case for last block\n\ndef get_cfg(ordered_blocks):\n    cfg = {}\n\n    labels = list(ordered_blocks.keys())\n\n    for i, (block_name, block) in enumerate(ordered_blocks.items()):\n        last = block[-1]\n        op = last['op']\n\n        if op == 'jmp':\n            cfg[block_name] = last['labels']\n        elif op == 'br':\n            cfg[block_name] = last['labels']\n        else:\n            if i+1 &lt; len(labels):  # last block does not fall through\n                cfg[block_name] = [labels[i+1]]\n    return cfg\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\ncfg = get_cfg(od)\n\nprint(cfg)\n\n{'gen_bk_0': ['somewhere'], 'gen_bk_1': ['somewhere']}\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/intro.html",
    "href": "src/briltxt/docs/intro.html",
    "title": "Bril: A Compiler Intermediate Representation for Learning",
    "section": "",
    "text": "Bril: A Compiler Intermediate Representation for Learning\nBril, the Big Red Intermediate Language, is a programming language for learning about compilers. It’s the intermediate representation we use in CS 6120, a PhD-level compilers course. Bril’s design tenets include:\n\nBril is an instruction-oriented language, like most good IRs.\nThe core is minimal and ruthlessly regular. Extensions make it interesting.\nThe tooling is language agnostic. Bril programs are just JSON.\nBril is typed.\n\nSee the language reference for the complete language specification and the tool documentation for details on the “batteries included” monorepo.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/brench.html",
    "href": "src/briltxt/docs/tools/brench.html",
    "title": "Brench",
    "section": "",
    "text": "Brench is a simple benchmark runner to help you measure the impact of optimizations. It can run the same set of benchmarks under multiple treatments, check that they still produce the correct answer, and report their performance under every condition.\n\n\nBrench is a Python tool. There is a brench/ subdirectory in the Bril repository. Get Flit and then type:\n$ flit install --symlink --user\n\n\n\nWrite a configuration file using TOML. Start with something like this:\nextract = 'total_dyn_inst: (\\d+)'\nbenchmarks = '../benchmarks/*.bril'\n\n[runs.baseline]\npipeline = [\n    \"bril2json\",\n    \"brili -p {args}\",\n]\n\n[runs.myopt]\npipeline = [\n    \"bril2json\",\n    \"myopt\",\n    \"brili -p {args}\",\n]\nThe global options are:\n\nextract: A regular expression to extract the figure of merit from a given run of a given benchmark. The example above gets the simple profiling output from the Bril interpreter in -p mode.\nbenchmarks (optional): A shell glob matching the benchmark files to run. You can also specify the files on the command line (see below).\ntimeout (optional): The timeout of each benchmark run in seconds. Default of 5 seconds.\n\nThen, define an map of runs, which are the different treatments you want to give to each benchmark. Each one needs a pipeline, which is a list of shell commands to run in a pipelined fashion on the benchmark file, which Brench will send to the first command’s standard input. The first run constitutes the “golden” output; subsequent runs will need to match this output.\nRun\n\nJust give Brench your config file and it will give you results as a CSV:\n$ brench example.toml &gt; results.csv\nYou can also specify a list of files after the configuration file to run a specified list of benchmarks, ignoring the pre-configured glob in the configuration file.\nThe command has only one command-line option:\n\n--jobs or -j: The number of parallel jobs to run. Set to 1 to run everything sequentially. By default, Brench tries to guess an adequate number of threads to fill up your machine.\n\nThe output CSV has three columns: benchmark, run, and result. The latter is the value extracted from the run’s standard output and standard error using the extract regular expression or one of these three status indicators:\n\nincorrect: The output did not match the “golden” output (from the first run).\ntimeout: Execution took too long.\nmissing: The extract regex did not match in the final pipeline stage’s standard output or standard error.\n\nTo check that a run’s output is “correct,” Brench compares its standard output to that of the first run (baseline in the above example, but it’s whichever run configuration comes first). The comparison is an exact string match."
  },
  {
    "objectID": "src/briltxt/docs/tools/brench.html#set-up",
    "href": "src/briltxt/docs/tools/brench.html#set-up",
    "title": "Brench",
    "section": "",
    "text": "Brench is a Python tool. There is a brench/ subdirectory in the Bril repository. Get Flit and then type:\n$ flit install --symlink --user"
  },
  {
    "objectID": "src/briltxt/docs/tools/brench.html#configure",
    "href": "src/briltxt/docs/tools/brench.html#configure",
    "title": "Brench",
    "section": "",
    "text": "Write a configuration file using TOML. Start with something like this:\nextract = 'total_dyn_inst: (\\d+)'\nbenchmarks = '../benchmarks/*.bril'\n\n[runs.baseline]\npipeline = [\n    \"bril2json\",\n    \"brili -p {args}\",\n]\n\n[runs.myopt]\npipeline = [\n    \"bril2json\",\n    \"myopt\",\n    \"brili -p {args}\",\n]\nThe global options are:\n\nextract: A regular expression to extract the figure of merit from a given run of a given benchmark. The example above gets the simple profiling output from the Bril interpreter in -p mode.\nbenchmarks (optional): A shell glob matching the benchmark files to run. You can also specify the files on the command line (see below).\ntimeout (optional): The timeout of each benchmark run in seconds. Default of 5 seconds.\n\nThen, define an map of runs, which are the different treatments you want to give to each benchmark. Each one needs a pipeline, which is a list of shell commands to run in a pipelined fashion on the benchmark file, which Brench will send to the first command’s standard input. The first run constitutes the “golden” output; subsequent runs will need to match this output.\nRun\n\nJust give Brench your config file and it will give you results as a CSV:\n$ brench example.toml &gt; results.csv\nYou can also specify a list of files after the configuration file to run a specified list of benchmarks, ignoring the pre-configured glob in the configuration file.\nThe command has only one command-line option:\n\n--jobs or -j: The number of parallel jobs to run. Set to 1 to run everything sequentially. By default, Brench tries to guess an adequate number of threads to fill up your machine.\n\nThe output CSV has three columns: benchmark, run, and result. The latter is the value extracted from the run’s standard output and standard error using the extract regular expression or one of these three status indicators:\n\nincorrect: The output did not match the “golden” output (from the first run).\ntimeout: Execution took too long.\nmissing: The extract regex did not match in the final pipeline stage’s standard output or standard error.\n\nTo check that a run’s output is “correct,” Brench compares its standard output to that of the first run (baseline in the above example, but it’s whichever run configuration comes first). The comparison is an exact string match."
  },
  {
    "objectID": "src/briltxt/docs/tools/infer.html",
    "href": "src/briltxt/docs/tools/infer.html",
    "title": "Type Inference",
    "section": "",
    "text": "Type Inference\nBril requires exhaustive type annotations on every instruction, which can quickly get tedious. The type-infer directory contains a simple global type inference tool that fills in missing type annotations. For example, it can turn this easier-to-write program:\n@main(arg: int) {\n  five = const 5;\n  ten = const 10;\n  res = add arg five;\n  cond = le res ten;\n  br cond .then .else;\n.then:\n  print res;\n.else:\n}\nInto this actually executable program:\n@main(arg: int) {\n  five: int = const 5;\n  ten: int = const 10;\n  res: int = add arg five;\n  cond: bool = le res ten;\n  br cond .then .else;\n.then:\n  print res;\n.else:\n}\nThe tool is a simple Python program, infer.py, that takes JSON programs that are missing types and adds types to them. It is also useful even on fully-typed programs as a type checker to rule out common run-time errors. The included text format tools support missing types for both parsing and printing, so here’s a shell pipeline that adds types to your text-format Bril program:\ncat myprog.bril | bril2json | python type-infer/infer.py | bril2txt\nYou can read more about the inference tool, which is originally by Christopher Roman.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/swift.html",
    "href": "src/briltxt/docs/tools/swift.html",
    "title": "Swift Library",
    "section": "",
    "text": "Swift Library\nThe Swift bril library, which lives in the bril-swift directory, provides a Swift interface for Bril’s JSON files. It supports the Bril core and the SSA extension.\nUse\n\nTo use this package in a SwiftPM project, add a dependency to your Package.swift:\nlet package = Package(\n  name: \"MyPackage\",\n  dependencies: [\n    .package(name: \"Bril\", path: \"../bril-swift\"),\n  ]\n)\nand add \"Bril\" to the dependencies array for any target that needs it:\ntargets: [\n    .target(\n        name: \"MyTarget\",\n        dependencies: [\"Bril\"]),\n// ...\nThe Bril objects conform to Decodable. Instantiate a program from data as follows:\nimport Bril\n\n/// to read from stdin:\n/// let data = FileHandle.standardInput.availableData\n\n/// or from a string:\n/// let data = \"&lt;Bril JSON&gt;\".data(using: .utf8)!\n\nlet program = try JSONDecoder().decode(Program.self, from: data)\nThe models conform to CustomStringConvertible so printing the Bril representation is simply:\nprint(program)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/bench.html",
    "href": "src/briltxt/docs/tools/bench.html",
    "title": "Benchmarks",
    "section": "",
    "text": "Benchmarks\nThe bench directory in the Bril repository contains a fledgling suite of microbenchmarks that you can use to measure the impact of your optimizations. (Benchmarks are different from tests because they are meant to actually calculate something instead of just exercising a language feature.)\nThe current benchmarks are:\n\nackermann: Print the value of Ack(m, n), the two-argument Ackermann–Péter function.\nadj2csr: Convert a graph in adjacency matrix format (dense representation) to Compressed Sparse Row (CSR) format (sparse representation). The random graph is generated using the same linear congruential generator.\nadler32: Computes the Adler-32 Checksum of an integer array.\narmstrong: Determines if the input is an Armstrong number, a number that is the sum of its own digits each raised to the power of the number of digits.\nbinary-fmt: Print the binary format for the given positive integer.\nbinary-search: Search a target integer within an integer array, outputs the index of target.\nbirthday: Simulation of the birthday paradox with an input of n people in a given room.\nbitwise-ops: Computes the OR, AND, or XOR between two 64-bit integers. (Three modes: 0 = AND, 1 = OR, 2 = XOR)\nbitshift: Computes the LEFTSHIFT and RIGHTSHIFT for any integer, also implements an efficient pow function for integers\nbubblesort: Sorting algorithm that works by repeatedly swapping the adjacent elements if they are in wrong order.\ncatalan: Print the nth term in the Catalan sequence, compute using recursive function calls.\ncheck-primes: Check the first n natural numbers for primality, printing out a 1 if the number is prime and a 0 if it’s not.\ncholesky: Perform Cholesky decomposition of a Hermitian and positive definite matrix. The result is validated by comparing with Python’s scipy.linalg.cholesky.\ncollatz: Print the Collatz sequence starting at n. Note: it is not known whether this will terminate for all n.\nconjugate-gradient: Uses conjugate gradients to solve Ax=b for any arbitrary positive semidefinite A.\ncordic: Print an approximation of sine(radians) using 8 iterations of the CORDIC algorithm.\ncsrmv: Multiply a sparse matrix in the Compressed Sparse Row (CSR) format with a dense vector. The matrix and input vector are generated using a Linear Feedback Shift Register random number generator.\ndigial-root: Computes the digital root of the input number.\ndead-branch: Repeatedly call a br instruction whose condition always evaluates to false. The dead branch should be pruned by a smart compiler.\ndot-product: Computes the dot product of two vectors.\neight-queens: Counts the number of solutions for n queens problem, a generalization of Eight queens puzzle.\neuclid: Calculates the greatest common divisor between two large numbers using the Euclidean Algorithm with a helper function for the modulo operator.\neuler: Approximates Euler’s number using the Taylor series.\nfact: Prints the factorial of n, computing it recursively.\nfactors: Print the factors of the n using the trial division method.\nfib: Calculate the nth Fibonacci number by allocating and filling an array of numbers up to that point.\nfizz-buzz: The infamous programming test.\nfunction_call: For benchmarking the overhead of simple function calls.\ngcd: Calculate Greatest Common Divisor (GCD) of two input positive integer using Euclidean algorithm.\nhanoi: Print the solution to the n-disk Tower of Hanoi puzzle.\nis-decreasing: Print if a number contains strictly decreasing digits.\nlcm: Compute LCM for two numbers using a very inefficient loop.\nloopfact: Compute n! imperatively using a loop.\nmajor-elm: Find the majority element in an array using a linear time voting algorithm.\nmandelbrot: Generates a really low resolution, ascii, mandelbrot set.\nmat-inv : Calculates the inverse of a 3x3 matrix and prints it out.\nmat-mul: Multiplies two nxn matrices using the naive matrix multiplication algorithm. The matrices are randomly generated using a linear congruential generator.\nmax-subarray: solution to the classic Maximum Subarray problem.\nmod_inv: Calculates the modular inverse of n under to a prime modulus p.\nnewton: Calculate the square root of 99,999 using the newton method\nnorm: Calculate the euclidean norm of a vector\nn_root: Calculate nth root of a float using newton’s method.\norders: Compute the order ord(u) for each u in a cyclic group &lt;Zn,+&gt; of integers modulo n under the group operation + (modulo n). Set the second argument is_lcm to true if you would like to compute the orders using the lowest common multiple and otherwise the program will use the greatest common divisor.\npascals-row: Computes a row in Pascal’s Triangle.\npalindrome: Outputs a 0-1 value indicating whether the input is a palindrome number.\nperfect: Check if input argument is a perfect number. Returns output as Unix style return code.\npow: Computes the n^th power of a given (float) number.\nprimes-between: Print the primes in the interval [a, b].\nprimitive-root: Computes a primitive root modulo a prime number input.\npythagorean_triple: Prints all Pythagorean triples with the given c, if such triples exist. An intentionally very naive implementation.\nquadratic: The quadratic formula, including a hand-rolled implementation of square root.\nquickselect: Find the kth smallest element in an array using the quickselect algorithm.\nquicksort: Quicksort using the Lomuto partition scheme.\nquicksort-hoare: Quicksort using Hoare partioning and median of three pivot selection.\nrecfact: Compute n! using recursive function calls.\nrectangles-area-difference: Output the difference between the areas of rectangles (as a positive value) given their respective side lengths.\nfitsinside: Output whether or not a rectangle fits inside of another rectangle given the width and height lengths.\nrelative-primes: Print all numbers relatively prime to n using Euclidean algorithm.\nriemann: Prints the left, midpoint, and right Riemann Sums for a specified function, which is the square function in this benchmark.\nsieve: Print all prime numbers up to n using the Sieve of Eratosthenes.\nsqrt: Implements the Newton–Raphson Method of approximating the square root of a number to arbitrary precision\nsum-bit: Print the number of 1-bits in the binary representation of the input integer.\nsum-check: Compute the sum of [1, n] by both loop and formula, and check if the result is the same.\nsum-divisors: Prints the positive integer divisors of the input integer, followed by the sum of the divisors.\nsum-sq-diff: Output the difference between the sum of the squares of the first n natural numbers and the square of their sum.\ntotient: Computes Euler’s totient function on an input integer n.\ntwo-sum: Print the indices of two distinct elements in the list [2, 7, 11, 13] whose sum equals the input.\nup-arrow: Computes Knuth’s up arrow notation, with the first argument being the number, the second argument being the number of Knuth’s up arrows, and the third argument being the number of repeats.\nvsmul: Multiplies a constant scalar to each element of a large array. Tests the performance of vectorization optimizations.\nreverse: Compute number with reversed digits (e.g. 123 -&gt; 321).\n\nCredit for several of these benchmarks goes to Alexa VanHattum and Gregory Yauney, who implemented them for their global value numbering project.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/ts2bril.html",
    "href": "src/briltxt/docs/tools/ts2bril.html",
    "title": "TypeScript-to-Bril Compiler",
    "section": "",
    "text": "Bril comes with a compiler from a very small subset of TypeScript to Bril called ts2bril.\nIt is not supposed to make it easy to port existing JavaScript code to Bril; it is a convenient way to write larger, more interesting programs without manually fiddling with Bril directly. It also emits somewhat obviously inefficient code to keep the compiler simple; some obvious optimizations can go a long way.\n\n\nThe TypeScript compiler uses Deno. Type this:\n$ deno install --allow-env --allow-read ts2bril.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path].\nUse\n\nCompile a TypeScript program to Bril by giving a filename on the command line:\n$ ts2bril mycode.ts\nThe compiler supports both integers (from core Bril) and floating point numbers. Perhaps somewhat surprisingly, plain JavaScript numbers and the TypeScript number type map to float in Bril. For integers, use JavaScript big integers whenever you need an integer, like this:\nvar x: bigint = 5n;\nprintInt(x);\n\nfunction printInt(x: bigint) {\n    console.log(x);\n}\nThe n suffix on literals distinguishes integer literals, and the bigint type in TypeScript reflects them."
  },
  {
    "objectID": "src/briltxt/docs/tools/ts2bril.html#install",
    "href": "src/briltxt/docs/tools/ts2bril.html#install",
    "title": "TypeScript-to-Bril Compiler",
    "section": "",
    "text": "The TypeScript compiler uses Deno. Type this:\n$ deno install --allow-env --allow-read ts2bril.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path].\nUse\n\nCompile a TypeScript program to Bril by giving a filename on the command line:\n$ ts2bril mycode.ts\nThe compiler supports both integers (from core Bril) and floating point numbers. Perhaps somewhat surprisingly, plain JavaScript numbers and the TypeScript number type map to float in Bril. For integers, use JavaScript big integers whenever you need an integer, like this:\nvar x: bigint = 5n;\nprintInt(x);\n\nfunction printInt(x: bigint) {\n    console.log(x);\n}\nThe n suffix on literals distinguishes integer literals, and the bigint type in TypeScript reflects them."
  },
  {
    "objectID": "src/briltxt/docs/tools/ocaml.html",
    "href": "src/briltxt/docs/tools/ocaml.html",
    "title": "OCaml Library",
    "section": "",
    "text": "The OCaml bril library, which lives in the bril-ocaml directory, provides an OCaml interface and parser for Bril’s JSON files.\n\n\nTo build the library, you first need to install OCaml. Then, install the dependencies with opam install core yojson.\nTo install the bril-ocaml library:\ngit clone https://github.com/sampsyo/bril path/to/my/bril\nopam pin add -k path bril path/to/brill/bril-ocaml\nopam install bril\nThat’s it! You can include it in your Dune files as bril, like any other OCaml library.\nUse\n\nThe interface for the library can be found in bril.mli—good starting points are from_string, from_file, and to_string. A small code example for the library lives in the count subdirectory.\nIf you wish to make changes to the bril OCaml library, simply hack on the git clone.\nWhen you are done, simply reinstall the package with opam reinstall bril. Restart the build of your local project to pick up changes made to bril-ocaml.\n\n\n\nocamlformat is recommended for style consistency. The dune documentation on Automatic Formatting has information about using ocamlformat with dune."
  },
  {
    "objectID": "src/briltxt/docs/tools/ocaml.html#install",
    "href": "src/briltxt/docs/tools/ocaml.html#install",
    "title": "OCaml Library",
    "section": "",
    "text": "To build the library, you first need to install OCaml. Then, install the dependencies with opam install core yojson.\nTo install the bril-ocaml library:\ngit clone https://github.com/sampsyo/bril path/to/my/bril\nopam pin add -k path bril path/to/brill/bril-ocaml\nopam install bril\nThat’s it! You can include it in your Dune files as bril, like any other OCaml library.\nUse\n\nThe interface for the library can be found in bril.mli—good starting points are from_string, from_file, and to_string. A small code example for the library lives in the count subdirectory.\nIf you wish to make changes to the bril OCaml library, simply hack on the git clone.\nWhen you are done, simply reinstall the package with opam reinstall bril. Restart the build of your local project to pick up changes made to bril-ocaml."
  },
  {
    "objectID": "src/briltxt/docs/tools/ocaml.html#for-development",
    "href": "src/briltxt/docs/tools/ocaml.html#for-development",
    "title": "OCaml Library",
    "section": "",
    "text": "ocamlformat is recommended for style consistency. The dune documentation on Automatic Formatting has information about using ocamlformat with dune."
  },
  {
    "objectID": "src/briltxt/docs/tools/web-playground.html",
    "href": "src/briltxt/docs/tools/web-playground.html",
    "title": "Web Playground",
    "section": "",
    "text": "Web playground is available for Bril.\nFeatures: - Code evaluation using the reference interpreter - CFG visualization - Dominator visualization - SSA transformation\n\n\nhttps://github.com/agentcooper/bril-playground"
  },
  {
    "objectID": "src/briltxt/docs/tools/web-playground.html#source-code",
    "href": "src/briltxt/docs/tools/web-playground.html#source-code",
    "title": "Web Playground",
    "section": "",
    "text": "https://github.com/agentcooper/bril-playground"
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html",
    "href": "src/briltxt/docs/lang/float.html",
    "title": "Floating Point",
    "section": "",
    "text": "Bril has an extension for computing on floating-point numbers.\nYou can read more about the extension, which is originally by Dietrich Geisler and originally included two FP precision levels.\n\n\nThe floating point extension adds one new base type:\n\"float\"\nFloating point numbers are 64-bit, double-precision IEEE 754 values. (There is no single-precision type.)\n\n\n\nThere are the standard arithmetic operations, which take two float values and produce a new float value:\n\nfadd\nfmul\nfsub\nfdiv\n\nIt is not an error to fdiv by zero; as in IEEE 754, the result is infinity.\nThere are also comparison operators, which take two float values and produce a bool:\n\nfeq\nflt\nfle\nfgt\nfge\n\n\n\n\nThe core print operation prints float values with 17 decimal digits of precision, including trailing zeros. (This is like using the %.17lf format specifier in C’s printf.) Positive and negative zero, while they are equal according to feq, look different when printed. Not-a-number values are printed as NaN; infinite values are printed as the strings Infinity or -Infinity."
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html#types",
    "href": "src/briltxt/docs/lang/float.html#types",
    "title": "Floating Point",
    "section": "",
    "text": "The floating point extension adds one new base type:\n\"float\"\nFloating point numbers are 64-bit, double-precision IEEE 754 values. (There is no single-precision type.)"
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html#operations",
    "href": "src/briltxt/docs/lang/float.html#operations",
    "title": "Floating Point",
    "section": "",
    "text": "There are the standard arithmetic operations, which take two float values and produce a new float value:\n\nfadd\nfmul\nfsub\nfdiv\n\nIt is not an error to fdiv by zero; as in IEEE 754, the result is infinity.\nThere are also comparison operators, which take two float values and produce a bool:\n\nfeq\nflt\nfle\nfgt\nfge"
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html#printing",
    "href": "src/briltxt/docs/lang/float.html#printing",
    "title": "Floating Point",
    "section": "",
    "text": "The core print operation prints float values with 17 decimal digits of precision, including trailing zeros. (This is like using the %.17lf format specifier in C’s printf.) Positive and negative zero, while they are equal according to feq, look different when printed. Not-a-number values are printed as NaN; infinite values are printed as the strings Infinity or -Infinity."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html",
    "href": "src/briltxt/docs/lang/char.html",
    "title": "Character",
    "section": "",
    "text": "The character extension adds one new base type:\n\"char\"\nCharacters are a singular Unicode character.\n\n\n\nComparison operators, which take two char values and produce a bool:\n\nceq\nclt\ncle\ncgt\ncge\n\nConversion operators:\n\nchar2int: One argument: a variable of type char. Returns an integer representing the Unicode code point of the given value.\nint2char: One argument: a variable of type int. Returns the corresponding Unicode character. Throws if the value does not correspond to a valid Unicode code point.\n\n\n\n\nThe core print operation prints char values."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html#types",
    "href": "src/briltxt/docs/lang/char.html#types",
    "title": "Character",
    "section": "",
    "text": "The character extension adds one new base type:\n\"char\"\nCharacters are a singular Unicode character."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html#operations",
    "href": "src/briltxt/docs/lang/char.html#operations",
    "title": "Character",
    "section": "",
    "text": "Comparison operators, which take two char values and produce a bool:\n\nceq\nclt\ncle\ncgt\ncge\n\nConversion operators:\n\nchar2int: One argument: a variable of type char. Returns an integer representing the Unicode code point of the given value.\nint2char: One argument: a variable of type int. Returns the corresponding Unicode character. Throws if the value does not correspond to a valid Unicode code point."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html#printing",
    "href": "src/briltxt/docs/lang/char.html#printing",
    "title": "Character",
    "section": "",
    "text": "The core print operation prints char values."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html",
    "href": "src/briltxt/docs/lang/core.html",
    "title": "Core Language",
    "section": "",
    "text": "This section describes the core Bril instructions. Any self-respecting Bril tool must support all of these operations; other extensions are more optional.\n\n\nCore Bril defines two primitive types:\n\nint: 64-bit, two’s complement, signed integers.\nbool: True or false.\n\n\n\n\nThese instructions are the obvious binary integer arithmetic operations. They all take two arguments, which must be names of variables of type int, and produce a result of type int:\n\nadd: x + y.\nmul: x × y.\nsub: x - y.\ndiv: x ÷ y.\n\nIn each case, overflow follows two’s complement rules. It is an error to div by zero.\n\n\n\nThese instructions compare integers. They all take two arguments of type int and produce a result of type bool:\n\neq: Equal.\nlt: Less than.\ngt: Greater than.\nle: Less than or equal to.\nge: Greater than or equal to.\n\n\n\n\nThese are the basic Boolean logic operators. They take arguments of type bool and produce a result of type bool:\n\nnot (1 argument)\nand (2 arguments)\nor (2 arguments)\n\n\n\n\nThese are the control flow operations. Unlike the value operations above, they take labels and functions in addition to normal arguments.\n\njmp: Unconditional jump. One label: the label to jump to.\nbr: Conditional branch. One argument: a variable of type bool. Two labels: a true label and a false label. Transfer control to one of the two labels depending on the value of the variable.\ncall: Function invocation. Takes the name of the function to call and, as its arguments, the function parameters. The call instruction can be a Value Operation or an Effect Operation, depending on whether the function returns a value.\nret: Function return. Stop executing the current activation record and return to the parent (or exit the program if this is the top-level main activation record). It has one optional argument: the return value for the function.\n\nOnly call may (optionally) produce a result; the rest appear only as Effect Operations.\n\n\n\n\nid: A type-insensitive identity. Takes one argument, which is a variable of any type, and produces the same value (which must have the same type, obvi).\nprint: Output values to the console (with a newline). Takes any number of arguments of any type and does not produce a result.\nnop: Do nothing. Takes no arguments and produces no result."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#types",
    "href": "src/briltxt/docs/lang/core.html#types",
    "title": "Core Language",
    "section": "",
    "text": "Core Bril defines two primitive types:\n\nint: 64-bit, two’s complement, signed integers.\nbool: True or false."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#arithmetic",
    "href": "src/briltxt/docs/lang/core.html#arithmetic",
    "title": "Core Language",
    "section": "",
    "text": "These instructions are the obvious binary integer arithmetic operations. They all take two arguments, which must be names of variables of type int, and produce a result of type int:\n\nadd: x + y.\nmul: x × y.\nsub: x - y.\ndiv: x ÷ y.\n\nIn each case, overflow follows two’s complement rules. It is an error to div by zero."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#comparison",
    "href": "src/briltxt/docs/lang/core.html#comparison",
    "title": "Core Language",
    "section": "",
    "text": "These instructions compare integers. They all take two arguments of type int and produce a result of type bool:\n\neq: Equal.\nlt: Less than.\ngt: Greater than.\nle: Less than or equal to.\nge: Greater than or equal to."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#logic",
    "href": "src/briltxt/docs/lang/core.html#logic",
    "title": "Core Language",
    "section": "",
    "text": "These are the basic Boolean logic operators. They take arguments of type bool and produce a result of type bool:\n\nnot (1 argument)\nand (2 arguments)\nor (2 arguments)"
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#control",
    "href": "src/briltxt/docs/lang/core.html#control",
    "title": "Core Language",
    "section": "",
    "text": "These are the control flow operations. Unlike the value operations above, they take labels and functions in addition to normal arguments.\n\njmp: Unconditional jump. One label: the label to jump to.\nbr: Conditional branch. One argument: a variable of type bool. Two labels: a true label and a false label. Transfer control to one of the two labels depending on the value of the variable.\ncall: Function invocation. Takes the name of the function to call and, as its arguments, the function parameters. The call instruction can be a Value Operation or an Effect Operation, depending on whether the function returns a value.\nret: Function return. Stop executing the current activation record and return to the parent (or exit the program if this is the top-level main activation record). It has one optional argument: the return value for the function.\n\nOnly call may (optionally) produce a result; the rest appear only as Effect Operations."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#miscellaneous",
    "href": "src/briltxt/docs/lang/core.html#miscellaneous",
    "title": "Core Language",
    "section": "",
    "text": "id: A type-insensitive identity. Takes one argument, which is a variable of any type, and produces the same value (which must have the same type, obvi).\nprint: Output values to the console (with a newline). Takes any number of arguments of any type and does not produce a result.\nnop: Do nothing. Takes no arguments and produces no result."
  },
  {
    "objectID": "src/briltxt/docs/lang/ssa.html",
    "href": "src/briltxt/docs/lang/ssa.html",
    "title": "Static Single Assignment (SSA) Form",
    "section": "",
    "text": "This language extension lets you represent Bril programs in static single assignment (SSA) form. As in the standard definition, an SSA-form Bril program contains only one assignment per variable, globally—that is, variables within a function cannot be reassigned. This extension adds ϕ-nodes to the language.\n\n\nThere is one new instruction:\n\nphi: Takes n labels and n arguments, for any n. Copies the value of the ith argument, where i is the index of the second-most-recently-executed label. (It is an error to use a phi instruction when two labels have not yet executed, or when the instruction does not contain an entry for the second-most-recently-executed label.)\n\nIntuitively, a phi instruction takes its value according to the current basic block’s predecessor.\n\n\n\nIn the text format, you can write phi instructions like this:\nx: int = phi a .here b .there;\nThe text format doesn’t care how you interleave arguments and labels, so this is equivalent to (but more readable than) phi a b .here .there. The “second-most-recent label” rule means that the labels refer to predecessor basic blocks, if you imagine blocks being “named” by their labels.\nHere’s a small example:\n.top:\n  a: int = const 5;\n  br cond .here .there;\n.here:\n  b: int = const 7;\n.there:\n  c: int = phi a .top b .here;\n  print c;\nA phi instruction is sensitive to the incoming CFG edge that execution took to arrive at the current block. The phi instruction in this program, for example, gets its value from a if control came from the .top block and b if control came from the .here block.\nThe reference interpreter can supports programs in SSA form because it can faithfully execute the phi instruction."
  },
  {
    "objectID": "src/briltxt/docs/lang/ssa.html#operations",
    "href": "src/briltxt/docs/lang/ssa.html#operations",
    "title": "Static Single Assignment (SSA) Form",
    "section": "",
    "text": "There is one new instruction:\n\nphi: Takes n labels and n arguments, for any n. Copies the value of the ith argument, where i is the index of the second-most-recently-executed label. (It is an error to use a phi instruction when two labels have not yet executed, or when the instruction does not contain an entry for the second-most-recently-executed label.)\n\nIntuitively, a phi instruction takes its value according to the current basic block’s predecessor."
  },
  {
    "objectID": "src/briltxt/docs/lang/ssa.html#examples",
    "href": "src/briltxt/docs/lang/ssa.html#examples",
    "title": "Static Single Assignment (SSA) Form",
    "section": "",
    "text": "In the text format, you can write phi instructions like this:\nx: int = phi a .here b .there;\nThe text format doesn’t care how you interleave arguments and labels, so this is equivalent to (but more readable than) phi a b .here .there. The “second-most-recent label” rule means that the labels refer to predecessor basic blocks, if you imagine blocks being “named” by their labels.\nHere’s a small example:\n.top:\n  a: int = const 5;\n  br cond .here .there;\n.here:\n  b: int = const 7;\n.there:\n  c: int = phi a .top b .here;\n  print c;\nA phi instruction is sensitive to the incoming CFG edge that execution took to arrive at the current block. The phi instruction in this program, for example, gets its value from a if control came from the .top block and b if control came from the .here block.\nThe reference interpreter can supports programs in SSA form because it can faithfully execute the phi instruction."
  },
  {
    "objectID": "src/briltxt/docs/lang/wellformed.html",
    "href": "src/briltxt/docs/lang/wellformed.html",
    "title": "Well Formedness",
    "section": "",
    "text": "Well Formedness\nNot every syntactically complete Bril program is well formed. Here is an incomplete list of rules that well-formed Bril programs must follow:\n\nInstructions may name variables as arguments when they are defined elsewhere in the function. Similarly, they may only refer to labels that exist within the same function, and they can only refer to functions defined somewhere in the same file.\nDynamically speaking, during execution, instructions may refer only to variables that have already been defined earlier in execution. (This is a dynamic property, not a static property.)\nEvery variable may have only a single type within a function. It is illegal to have two assignments to the same variable with different types, even if the function’s logic guarantees that it is impossible to execute both instructions in a single call.\nMany operations have constraints on the types of arguments they can take; well-formed programs always provide the right type of value.\n\nTools do not need to handle ill-formed Bril programs. As someone working with Bril, you never need to check for well-formedness and can do anything when fed with ill-formed code, including silently working just fine, producing ill-formed output, or crashing and burning.\nTo help check for well-formedness, the reference interpreter has many dynamic checks and the type inference tool can check types statically.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html",
    "href": "src/briltxt/docs/lang/spec.html",
    "title": "Speculative Execution",
    "section": "",
    "text": "This extension lets Bril programs use a form of explicit speculative execution with rollback.\nIn general, speculation is when programs perform work that might not actually be necessary or even correct, under the assumption that it is likely to be right and useful. If this assumption turns out to be wrong, speculation typically needs some rollback mechanism to undo incorrect side effects and recover to a correct state.\nIn this Bril extension, programs can explicitly enter a speculative mode, where variable assignments are temporary. Then, they can either abort or commit those assignments, discarding them or making them permanent.\n\n\n\nspeculate: Enter a speculative execution context. No arguments.\ncommit: End the current speculative context, committing the current speculative state as the “real” state. No arguments.\nguard: Check a condition and possibly abort the current speculative context. One argument, the Boolean condition, and one label, to which control is transferred on abort. If the condition is true, this is a no-op. If the condition is false, speculation aborts: the program state rolls back to the state at the corresponding speculate instruction, execution jumps to the specified label.\n\nSpeculation can be nested, in which case aborting or committing a child context returns execution to the parent context. Aborting speculation rolls back normal variable assignments, but it does not affect the memory extension’s heap—any changes there remain. It is an error to commit or abort outside of speculation. It is not an error to perform side effects like print during speculation, but it is probably a bad idea.\n\n\n\nCommitting a speculative update makes it behave like normal:\nv: int = const 4;\nspeculate;\nv: int = const 2;\ncommit;\nprint v;\nSo this example prints 2. However, when a guard fails, it rolls back any modifications that happened since the last speculate instruction:\n  b: bool = const false;\n\n  v: int = const 4;\n  speculate;\n  v: int = const 2;\n  guard b .failed;\n  commit;\n\n.failed:\n  print v;\nThe guard here fails because b is false, then v gets restored to its pre-speculation value, and then control transfers to the .failed label. So this example prints 4. You can think of the code at .failed as the “recovery routine” that handles exceptional conditions.\n\n\n\nThe reference interpreter supports speculative execution. However, it does not support function calls during speculation, so you will get an error if you try to use a call or ret instruction while speculating."
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html#operations",
    "href": "src/briltxt/docs/lang/spec.html#operations",
    "title": "Speculative Execution",
    "section": "",
    "text": "speculate: Enter a speculative execution context. No arguments.\ncommit: End the current speculative context, committing the current speculative state as the “real” state. No arguments.\nguard: Check a condition and possibly abort the current speculative context. One argument, the Boolean condition, and one label, to which control is transferred on abort. If the condition is true, this is a no-op. If the condition is false, speculation aborts: the program state rolls back to the state at the corresponding speculate instruction, execution jumps to the specified label.\n\nSpeculation can be nested, in which case aborting or committing a child context returns execution to the parent context. Aborting speculation rolls back normal variable assignments, but it does not affect the memory extension’s heap—any changes there remain. It is an error to commit or abort outside of speculation. It is not an error to perform side effects like print during speculation, but it is probably a bad idea."
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html#examples",
    "href": "src/briltxt/docs/lang/spec.html#examples",
    "title": "Speculative Execution",
    "section": "",
    "text": "Committing a speculative update makes it behave like normal:\nv: int = const 4;\nspeculate;\nv: int = const 2;\ncommit;\nprint v;\nSo this example prints 2. However, when a guard fails, it rolls back any modifications that happened since the last speculate instruction:\n  b: bool = const false;\n\n  v: int = const 4;\n  speculate;\n  v: int = const 2;\n  guard b .failed;\n  commit;\n\n.failed:\n  print v;\nThe guard here fails because b is false, then v gets restored to its pre-speculation value, and then control transfers to the .failed label. So this example prints 4. You can think of the code at .failed as the “recovery routine” that handles exceptional conditions."
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html#interpreter",
    "href": "src/briltxt/docs/lang/spec.html#interpreter",
    "title": "Speculative Execution",
    "section": "",
    "text": "The reference interpreter supports speculative execution. However, it does not support function calls during speculation, so you will get an error if you try to use a call or ret instruction while speculating."
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html",
    "href": "src/briltxt/docs/lang/import.html",
    "title": "Import",
    "section": "",
    "text": "Typically, Bril programs are self-contained: they only use functions defined elsewhere in the same program. This import extension lets Bril code use functions defined in other files.\nA Bril import refers to a file and lists the functions to import from it, like this:\n{\n    \"path\": \"my_library.json\",\n    \"functions\": [{\"name\": \"libfunc\"}]\n}\nThis import assumes that there’s a Bril file called my_library.json, and that it declares a function @libfunc. The current Bril file may now invoke @libfunc as if it were defined locally.\n\n\nThe top-level Bril program is extended with an imports field:\n{ \"functions\": [&lt;Function&gt;, ...], \"imports\": [&lt;Import&gt;, ...] }\nEach import object has this syntax:\n{\n    \"path\": \"&lt;string&gt;\",\n    \"functions\": [\n        { \"name\": \"&lt;string&gt;\", \"alias\": \"&lt;string&gt;\"? },\n        ...\n    ]\n}\nThe path is a relative reference to a Bril JSON file containing the functions to import. In the objects in the functions list, the name is the original name of the function, and the optional alias is the local name that the program will use to refer to the function. A missing alias makes the local name equal to the original name.\nIt is an error to refer to functions that do not exist, or to create naming conflicts between imports and local functions (or between different imports). Import cycles are allowed.\n\n\n\nIn Bril’s text format, the import syntax looks like this:\nfrom \"something.json\" import @libfunc, @otherfunc as @myfunc;\n\n\n\nWe do not define the exact mechanism for using the path string to find the file to import. Reasonable options include:\n\nResolve the path relative to the file the import appears in.\nUse a pre-defined set of library search paths.\n\nWe only specify what it means to import JSON files; implementations can choose to allow importing other kinds of files too (e.g., text-format source code)."
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html#syntax",
    "href": "src/briltxt/docs/lang/import.html#syntax",
    "title": "Import",
    "section": "",
    "text": "The top-level Bril program is extended with an imports field:\n{ \"functions\": [&lt;Function&gt;, ...], \"imports\": [&lt;Import&gt;, ...] }\nEach import object has this syntax:\n{\n    \"path\": \"&lt;string&gt;\",\n    \"functions\": [\n        { \"name\": \"&lt;string&gt;\", \"alias\": \"&lt;string&gt;\"? },\n        ...\n    ]\n}\nThe path is a relative reference to a Bril JSON file containing the functions to import. In the objects in the functions list, the name is the original name of the function, and the optional alias is the local name that the program will use to refer to the function. A missing alias makes the local name equal to the original name.\nIt is an error to refer to functions that do not exist, or to create naming conflicts between imports and local functions (or between different imports). Import cycles are allowed."
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html#text-format",
    "href": "src/briltxt/docs/lang/import.html#text-format",
    "title": "Import",
    "section": "",
    "text": "In Bril’s text format, the import syntax looks like this:\nfrom \"something.json\" import @libfunc, @otherfunc as @myfunc;"
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html#search-paths",
    "href": "src/briltxt/docs/lang/import.html#search-paths",
    "title": "Import",
    "section": "",
    "text": "We do not define the exact mechanism for using the path string to find the file to import. Reasonable options include:\n\nResolve the path relative to the file the import appears in.\nUse a pre-defined set of library search paths.\n\nWe only specify what it means to import JSON files; implementations can choose to allow importing other kinds of files too (e.g., text-format source code)."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html",
    "href": "src/briltxt/docs/lang/syntax.html",
    "title": "Syntax Reference",
    "section": "",
    "text": "Bril programs are JSON objects that directly represent abstract syntax. This chapter exhaustively describes the structure of that syntax. All objects are JSON values of one sort or another.\n\n\n{ \"functions\": [&lt;Function&gt;, ...] }\nA Program is the top-level object. It has one key:\n\nfunctions, a list of Function objects.\n\n\n\n\n\"&lt;string&gt;\"\n{\"&lt;string&gt;\": &lt;Type&gt;}\nThere are two kinds of types: primitive types, whose syntax is just a string, and parameterized types, which wrap a smaller type. The semantics chapters list the particular types that are available—for example, core Bril defines the basic primitive types int and bool and the memory extension defines a parameterized pointer type.\n\n\n\n{\n  \"name\": \"&lt;string&gt;\",\n  \"args\": [{\"name\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;}, ...]?,\n  \"type\": &lt;Type&gt;?,\n  \"instrs\": [&lt;Instruction&gt;, ...]\n}\nA Function object represents a (first-order) procedure consisting of a sequence of instructions. There are four fields:\n\nname, a string.\nargs, optionally, a list of arguments, which consist of a name and a type. Missing args is the same as an empty list.\nOptionally, type, a Type object: the function’s return type, if any.\ninstrs, a list of Label and Instruction objects.\n\nWhen a function runs, it creates an activation record and transfers control to the first instruction in the sequence.\nA Bril program is executable if it contains a function named main. When execution starts, this function will be invoked. The main function can have arguments (which implementations may supply using command-line arguments) but must not have a return type.\n\n\n\n{ \"label\": \"&lt;string&gt;\" }\nA Label marks a position in an instruction sequence as a destination for control transfers. It only has one key:\n\nlabel, a string. This is the name that jump and branch instructions will use to transfer control to this position and proceed to execute the following instruction.\n\n\n\n\n{ \"op\": \"&lt;string&gt;\", ... }\nAn Instruction represents a unit of computational work. Every instruction must have this field:\n\nop, a string: the opcode that determines what the instruction does. (See the Core Language section and the subsequent extension sections for listings of the available opcodes.)\n\nDepending on the opcode, the instruction might also have:\n\ndest, a string: the name of the variable where the operation’s result is stored.\ntype, a Type object: the type of the destination variable.\nargs, a list of strings: the arguments to the operation. These are names of variables.\nfuncs, a list of strings: any names of functions referenced by the instruction.\nlabels, a list of strings: any label names referenced by the instruction.\n\nThere are three kinds of instructions: constants, value operations, and effect operations.\n\n\n{ \"op\": \"const\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"value\": &lt;literal&gt; }\nA Constant is an instruction that produces a literal value. Its op field must be the string \"const\". It has the dest and type fields described above, and also:\n\nvalue, the literal value for the constant. This is either a JSON number or a JSON Boolean value. The type field must match—i.e., it must be “int” or “bool”, respectively.\n\n\n\n\n{ \"op\": \"&lt;string&gt;\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nA Value Operation is an instruction that takes arguments, does some computation, and produces a value. Like a Constant, it has the dest and type fields described above, and also any of these three optional fields:\n\nargs, a list of strings. These are variable names defined elsewhere in the same function.\nfuncs, a list of strings. The names of any functions that this instruction references. For example, core Bril’s call instruction takes one function name.\nlabels, a list of strings. The names of any labels within the current function that the instruction references. For example, core Bril’s jump and branch instructions have target labels.\n\nIn all three cases, these keys may be missing and the semantics are identical to mapping to an empty list.\n\n\n\n{ \"op\": \"&lt;string&gt;\",\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nAn Effect Operation is like a Value Operation but it does not produce a value. It also has the optional args, funcs, and labels fields.\n\n\n\n\nAny syntax object may optionally have position fields to reflect a source position:\n{ ..., \"pos\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;},\n       \"pos_end\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;}?,\n       \"src\": \"&lt;string&gt;\"? }\nThe pos and pos_end objects have two keys: row (the line number) and col (the column number within the line). The src object can optionally provide the absolute path to a file which is referenced to by the source position. If pos_end is provided, it must be equal to or greater than pos. Front-end compilers that generate Bril code may add this information to help with debugging. The text format parser, for example, can optionally add source positions. However, tools can’t require positions to exist, to consistently exist or not on all syntax objects in a program, or to follow any particular rules."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#program",
    "href": "src/briltxt/docs/lang/syntax.html#program",
    "title": "Syntax Reference",
    "section": "",
    "text": "{ \"functions\": [&lt;Function&gt;, ...] }\nA Program is the top-level object. It has one key:\n\nfunctions, a list of Function objects."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#type",
    "href": "src/briltxt/docs/lang/syntax.html#type",
    "title": "Syntax Reference",
    "section": "",
    "text": "\"&lt;string&gt;\"\n{\"&lt;string&gt;\": &lt;Type&gt;}\nThere are two kinds of types: primitive types, whose syntax is just a string, and parameterized types, which wrap a smaller type. The semantics chapters list the particular types that are available—for example, core Bril defines the basic primitive types int and bool and the memory extension defines a parameterized pointer type."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#function",
    "href": "src/briltxt/docs/lang/syntax.html#function",
    "title": "Syntax Reference",
    "section": "",
    "text": "{\n  \"name\": \"&lt;string&gt;\",\n  \"args\": [{\"name\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;}, ...]?,\n  \"type\": &lt;Type&gt;?,\n  \"instrs\": [&lt;Instruction&gt;, ...]\n}\nA Function object represents a (first-order) procedure consisting of a sequence of instructions. There are four fields:\n\nname, a string.\nargs, optionally, a list of arguments, which consist of a name and a type. Missing args is the same as an empty list.\nOptionally, type, a Type object: the function’s return type, if any.\ninstrs, a list of Label and Instruction objects.\n\nWhen a function runs, it creates an activation record and transfers control to the first instruction in the sequence.\nA Bril program is executable if it contains a function named main. When execution starts, this function will be invoked. The main function can have arguments (which implementations may supply using command-line arguments) but must not have a return type."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#label",
    "href": "src/briltxt/docs/lang/syntax.html#label",
    "title": "Syntax Reference",
    "section": "",
    "text": "{ \"label\": \"&lt;string&gt;\" }\nA Label marks a position in an instruction sequence as a destination for control transfers. It only has one key:\n\nlabel, a string. This is the name that jump and branch instructions will use to transfer control to this position and proceed to execute the following instruction."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#instruction",
    "href": "src/briltxt/docs/lang/syntax.html#instruction",
    "title": "Syntax Reference",
    "section": "",
    "text": "{ \"op\": \"&lt;string&gt;\", ... }\nAn Instruction represents a unit of computational work. Every instruction must have this field:\n\nop, a string: the opcode that determines what the instruction does. (See the Core Language section and the subsequent extension sections for listings of the available opcodes.)\n\nDepending on the opcode, the instruction might also have:\n\ndest, a string: the name of the variable where the operation’s result is stored.\ntype, a Type object: the type of the destination variable.\nargs, a list of strings: the arguments to the operation. These are names of variables.\nfuncs, a list of strings: any names of functions referenced by the instruction.\nlabels, a list of strings: any label names referenced by the instruction.\n\nThere are three kinds of instructions: constants, value operations, and effect operations.\n\n\n{ \"op\": \"const\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"value\": &lt;literal&gt; }\nA Constant is an instruction that produces a literal value. Its op field must be the string \"const\". It has the dest and type fields described above, and also:\n\nvalue, the literal value for the constant. This is either a JSON number or a JSON Boolean value. The type field must match—i.e., it must be “int” or “bool”, respectively.\n\n\n\n\n{ \"op\": \"&lt;string&gt;\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nA Value Operation is an instruction that takes arguments, does some computation, and produces a value. Like a Constant, it has the dest and type fields described above, and also any of these three optional fields:\n\nargs, a list of strings. These are variable names defined elsewhere in the same function.\nfuncs, a list of strings. The names of any functions that this instruction references. For example, core Bril’s call instruction takes one function name.\nlabels, a list of strings. The names of any labels within the current function that the instruction references. For example, core Bril’s jump and branch instructions have target labels.\n\nIn all three cases, these keys may be missing and the semantics are identical to mapping to an empty list.\n\n\n\n{ \"op\": \"&lt;string&gt;\",\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nAn Effect Operation is like a Value Operation but it does not produce a value. It also has the optional args, funcs, and labels fields."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#source-positions",
    "href": "src/briltxt/docs/lang/syntax.html#source-positions",
    "title": "Syntax Reference",
    "section": "",
    "text": "Any syntax object may optionally have position fields to reflect a source position:\n{ ..., \"pos\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;},\n       \"pos_end\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;}?,\n       \"src\": \"&lt;string&gt;\"? }\nThe pos and pos_end objects have two keys: row (the line number) and col (the column number within the line). The src object can optionally provide the absolute path to a file which is referenced to by the source position. If pos_end is provided, it must be equal to or greater than pos. Front-end compilers that generate Bril code may add this information to help with debugging. The text format parser, for example, can optionally add source positions. However, tools can’t require positions to exist, to consistently exist or not on all syntax objects in a program, or to follow any particular rules."
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html",
    "href": "src/briltxt/docs/lang/memory.html",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "While core Bril only has simple scalar stack values, the memory extension adds a manually managed heap of array-like allocations. You can create regions, like with malloc in C, and it is the program’s responsibility to delete them, like with free. Programs can manipulate pointers within these regions; a pointer indicates a particular offset within a particular allocated region.\nYou can read more about the memory extension from its creators, Drew Zagieboylo and Ryan Doenges.\n\n\nThe memory extension adds a parameterized ptr type to Bril:\n{\"ptr\": &lt;Type&gt;}\nA pointer value represents a reference to a specific offset within a uniformly-typed region of values.\n\n\n\nThese are the operations that manipulate memory allocations:\n\nalloc: Create a new memory region. One argument: the number of values to allocate (an integer). The result type is a pointer; the type of the instruction decides the type of the memory region to allocate. For example, this instruction allocates a region of integers:\n{\n    \"op\": \"alloc\",\n    \"args\": [\"size\"],\n    \"dest\": \"myptr\",\n    \"type\": {\"ptr\": \"int\"}\n}\nfree: Delete an allocation. One argument: a pointer produced by alloc. No return value.\nstore: Write into a memory region. Two arguments: a pointer and a value. The pointer type must agree with the value type (e.g., if the second argument is an int, the first argument must be a ptr&lt;int&gt;). No return value.\nload: Read from memory. One argument: a pointer. The return type is the pointed-to type for that pointer.\nptradd: Adjust the offset for a pointer, producing a new pointer to a different location in the same memory region. Two arguments: a pointer and an offset (an integer, which may be negative). The return type is the same as the original pointer type.\n\nIt is an error to access or free a region that has already been freed. It is also an error to access (load or store) a pointer that is out of bounds, i.e., outside the range of valid indices for a given allocation. (Doing a ptradd to produce an out-of-bounds pointer is not an error; subsequently accessing that pointer is.)\n\n\n\nIt is not an error to use the core print operation on pointers, but the output is not specified. Implementations can choose to print any representation of the pointer that they deem helpful."
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html#types",
    "href": "src/briltxt/docs/lang/memory.html#types",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "The memory extension adds a parameterized ptr type to Bril:\n{\"ptr\": &lt;Type&gt;}\nA pointer value represents a reference to a specific offset within a uniformly-typed region of values."
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html#operations",
    "href": "src/briltxt/docs/lang/memory.html#operations",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "These are the operations that manipulate memory allocations:\n\nalloc: Create a new memory region. One argument: the number of values to allocate (an integer). The result type is a pointer; the type of the instruction decides the type of the memory region to allocate. For example, this instruction allocates a region of integers:\n{\n    \"op\": \"alloc\",\n    \"args\": [\"size\"],\n    \"dest\": \"myptr\",\n    \"type\": {\"ptr\": \"int\"}\n}\nfree: Delete an allocation. One argument: a pointer produced by alloc. No return value.\nstore: Write into a memory region. Two arguments: a pointer and a value. The pointer type must agree with the value type (e.g., if the second argument is an int, the first argument must be a ptr&lt;int&gt;). No return value.\nload: Read from memory. One argument: a pointer. The return type is the pointed-to type for that pointer.\nptradd: Adjust the offset for a pointer, producing a new pointer to a different location in the same memory region. Two arguments: a pointer and an offset (an integer, which may be negative). The return type is the same as the original pointer type.\n\nIt is an error to access or free a region that has already been freed. It is also an error to access (load or store) a pointer that is out of bounds, i.e., outside the range of valid indices for a given allocation. (Doing a ptradd to produce an out-of-bounds pointer is not an error; subsequently accessing that pointer is.)"
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html#printing",
    "href": "src/briltxt/docs/lang/memory.html#printing",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "It is not an error to use the core print operation on pointers, but the output is not specified. Implementations can choose to print any representation of the pointer that they deem helpful."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilck.html",
    "href": "src/briltxt/docs/tools/brilck.html",
    "title": "Type Checker",
    "section": "",
    "text": "Bril comes with a simple type checker to catch errors statically. It checks the types of instructions in the core language and the floating point, SSA, memory, and speculation extensions. It also checks calls and return values and the labels used in control flow.\n\n\nThe brilck tool uses Deno. Type this:\n$ deno install brilck.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path].\n\n\n\nJust pipe a Bril program into brilck:\nbril2json &lt; benchmarks/fizz-buzz.bril | brilck\nIt will print any problems it finds to standard error. (If it doesn’t find any problems, it doesn’t print anything at all.)\nYou can optionally provide a filename as a (sole) command-line argument. This filename will appear in any error messages for easier parsing when many files are involved.\nConsider supplying the -p flag to the bril2json parser to get source positions in the error messages."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilck.html#install",
    "href": "src/briltxt/docs/tools/brilck.html#install",
    "title": "Type Checker",
    "section": "",
    "text": "The brilck tool uses Deno. Type this:\n$ deno install brilck.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path]."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilck.html#check",
    "href": "src/briltxt/docs/tools/brilck.html#check",
    "title": "Type Checker",
    "section": "",
    "text": "Just pipe a Bril program into brilck:\nbril2json &lt; benchmarks/fizz-buzz.bril | brilck\nIt will print any problems it finds to standard error. (If it doesn’t find any problems, it doesn’t print anything at all.)\nYou can optionally provide a filename as a (sole) command-line argument. This filename will appear in any error messages for easier parsing when many files are involved.\nConsider supplying the -p flag to the bril2json parser to get source positions in the error messages."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilirs.html",
    "href": "src/briltxt/docs/tools/brilirs.html",
    "title": "Fast Interpreter in Rust",
    "section": "",
    "text": "The brilirs directory contains a fast Bril interpreter written in Rust. It is a drop-in replacement for the reference interpreter that prioritizes speed over completeness and hackability. It implements core Bril along with the SSA, memory, char, and floating point extensions.\nRead more about the implementation, which is originally by Wil Thomason and Daniel Glus.\n\n\nTo use brilirs you will need to install Rust. Use echo $PATH to check that $HOME/.cargo/bin is on your path.\nIn the brilirs directory, install the interpreter with:\n$ cargo install --path .\nDuring installation, brilirs will attempt to create a tab completions file for current shell. If this of interest, follow the instructions provided as a warning to finish enabling this.\nRun a program by piping a JSON Bril program into it:\n$ bril2json &lt; myprogram.bril | brilirs\nor\n$ brilirs --text --file myprogram.bril\nSimilar to brilck, brilirs can be used to typecheck and validate your Bril JSON program by passing the --check flag (similar to cargo --check).\nTo see all of the supported flags, run:\n$ brilirs --help"
  },
  {
    "objectID": "src/briltxt/docs/tools/brilirs.html#install",
    "href": "src/briltxt/docs/tools/brilirs.html#install",
    "title": "Fast Interpreter in Rust",
    "section": "",
    "text": "To use brilirs you will need to install Rust. Use echo $PATH to check that $HOME/.cargo/bin is on your path.\nIn the brilirs directory, install the interpreter with:\n$ cargo install --path .\nDuring installation, brilirs will attempt to create a tab completions file for current shell. If this of interest, follow the instructions provided as a warning to finish enabling this.\nRun a program by piping a JSON Bril program into it:\n$ bril2json &lt; myprogram.bril | brilirs\nor\n$ brilirs --text --file myprogram.bril\nSimilar to brilck, brilirs can be used to typecheck and validate your Bril JSON program by passing the --check flag (similar to cargo --check).\nTo see all of the supported flags, run:\n$ brilirs --help"
  },
  {
    "objectID": "src/briltxt/docs/tools/interp.html",
    "href": "src/briltxt/docs/tools/interp.html",
    "title": "Interpreter",
    "section": "",
    "text": "brili is the reference interpreter for Bril. It is written in TypeScript. You can find brili in the bril-ts directory in the Bril repository.\nThe interpreter supports core Bril along with the memory, floating point, SSA, and speculation extensions.\n\n\nTo use the interpreter, you will need Deno. Just run:\n$ deno install brili.ts\nAs Deno tells you, you will then need to add $HOME/.deno/bin to your $PATH.\nRun\n\nThe brili program takes a Bril program as a JSON file on standard input:\n$ brili &lt; my_program.json\nIt emits any print outputs to standard output. To provide inputs to the main function, you can write them as command-line arguments:\n$ brili 37 5 &lt; add.json\n42\n\n\n\nThe interpreter has a rudimentary profiling mode. Add a -p flag to print out a total number of dynamic instructions executed to stderr:\n$ brili -p 37 5 &lt; add.json\n42\ntotal_dyn_inst: 9"
  },
  {
    "objectID": "src/briltxt/docs/tools/interp.html#install",
    "href": "src/briltxt/docs/tools/interp.html#install",
    "title": "Interpreter",
    "section": "",
    "text": "To use the interpreter, you will need Deno. Just run:\n$ deno install brili.ts\nAs Deno tells you, you will then need to add $HOME/.deno/bin to your $PATH.\nRun\n\nThe brili program takes a Bril program as a JSON file on standard input:\n$ brili &lt; my_program.json\nIt emits any print outputs to standard output. To provide inputs to the main function, you can write them as command-line arguments:\n$ brili 37 5 &lt; add.json\n42"
  },
  {
    "objectID": "src/briltxt/docs/tools/interp.html#profiling",
    "href": "src/briltxt/docs/tools/interp.html#profiling",
    "title": "Interpreter",
    "section": "",
    "text": "The interpreter has a rudimentary profiling mode. Add a -p flag to print out a total number of dynamic instructions executed to stderr:\n$ brili -p 37 5 &lt; add.json\n42\ntotal_dyn_inst: 9"
  },
  {
    "objectID": "src/briltxt/docs/tools/text.html",
    "href": "src/briltxt/docs/tools/text.html",
    "title": "Bril Text Format",
    "section": "",
    "text": "While Bril’s canonical representation is a JSON AST, humans don’t like to read and write JSON. To accommodate our human foibles, we also have a simple textual representation. There is a parser and pretty printer tool that can convert the text representation to and from JSON.\nFor example, this Bril program in JSON:\n{\n  \"functions\": [{\n    \"name\": \"main\",\n    \"instrs\": [\n      { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n      { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n      { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\", \"args\": [\"v0\", \"v1\"] },\n      { \"op\": \"print\", \"args\": [\"v2\"] },\n      { \"op\": \"alloc\", \"type\": { \"ptr\" : \"int\" }, \"dest\": \"v3\", \"args\": [\"v0\"] },\n      { \"op\": \"free\", \"args\": [\"v3\"] },\n    ]\n  }]\n}\nGets represented in text like this:\n@main {\n  v0: int = const 1;\n  v1: int = const 2;\n  v2: int = add v0 v1;\n  print v2;\n  v3: ptr&lt;int&gt; = alloc v0;\n  free v3;\n}\n\n\nThe bril-txt parser & pretty printer are written in Python. You can install them with Flit by doing something like:\n$ pip install --user flit\n$ cd bril-txt\n$ flit install --symlink --user\nYou’ll now have tools called bril2json and bril2txt. Both read from standard input and write to standard output. You can try a “round trip” like this, for example:\n$ bril2json &lt; test/parse/add.bril | bril2txt\nThe bril2json parser also supports a -p flag to include source positions."
  },
  {
    "objectID": "src/briltxt/docs/tools/text.html#tools",
    "href": "src/briltxt/docs/tools/text.html#tools",
    "title": "Bril Text Format",
    "section": "",
    "text": "The bril-txt parser & pretty printer are written in Python. You can install them with Flit by doing something like:\n$ pip install --user flit\n$ cd bril-txt\n$ flit install --symlink --user\nYou’ll now have tools called bril2json and bril2txt. Both read from standard input and write to standard output. You can try a “round trip” like this, for example:\n$ bril2json &lt; test/parse/add.bril | bril2txt\nThe bril2json parser also supports a -p flag to include source positions."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html",
    "href": "src/briltxt/docs/tools/brilift.html",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Brilift is a ahead-of-time or just-in-time compiler from Bril to native code using the Cranelift code generator. It supports core Bril, floating point, and the memory extension.\nIn AOT mode, Brilift emits .o files and also provides a simple run-time library. By linking these together, you get a complete native executable. In JIT mode, Brilift mimics an interpreter.\n\n\nBrilift is a Rust project using the bril-rs library. You can build it using Cargo:\n$ cd brilift\n$ cargo run -- --help\n$ cargo install --path .  # If you want the executable on your $PATH.\n\n\n\nProvide the brilift executable with a Bril JSON program:\n$ bril2json &lt; something.bril | brilift\nBy default, Brilift produces a file bril.o. (You can pick your own output filename with -o something.o; see the full list of options below.)\nA complete executable will also need our runtime library, which is in rt.c. There is a convenient Makefile rule to produce rt.o:\n$ make rt.o\nThen, you will want to link rt.o and bril.o to produce an executable:\n$ cc bril.o rt.o -o myprog\nIf your Bril @main function takes arguments, those are now command-line arguments to the myprog executable.\n\n\n\nUse the -j flag to compile and run the program immediately:\n$ bril2json &lt; something.bril | brilift -j\nPass any arguments to the Bril @main function as command-line arguments to Brilift. For example, if you have a function @main(foo: int, bar: bool), you can type brilift -j 42 true.\n\n\n\nType brilift --help to see the full list of options:\n\n-j: JIT-compile the code and run it immediately, instead of AOT-compiling an object file (the default).\n-O [none|speed|speed_and_size]: An optimization level, according to Cranelift. The default is none.\n-v: Enable lots of logging from the Cranelift library.\n-d: Dump the Cranelift IR text for debugging.\n\nThese options are only relevant in AOT mode:\n\n-o &lt;FILE&gt;: Place the output object file in &lt;FILE&gt; instead of bril.o (the default).\n-t &lt;TARGET&gt;: Specify the target triple, as interpreted by Cranelift. These triples resemble the target triples that LLVM also understands, for example. For instance, x86_64-unknown-darwin-macho is the triple for macOS on Intel processors."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#build",
    "href": "src/briltxt/docs/tools/brilift.html#build",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Brilift is a Rust project using the bril-rs library. You can build it using Cargo:\n$ cd brilift\n$ cargo run -- --help\n$ cargo install --path .  # If you want the executable on your $PATH."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#ahead-of-time-compilation",
    "href": "src/briltxt/docs/tools/brilift.html#ahead-of-time-compilation",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Provide the brilift executable with a Bril JSON program:\n$ bril2json &lt; something.bril | brilift\nBy default, Brilift produces a file bril.o. (You can pick your own output filename with -o something.o; see the full list of options below.)\nA complete executable will also need our runtime library, which is in rt.c. There is a convenient Makefile rule to produce rt.o:\n$ make rt.o\nThen, you will want to link rt.o and bril.o to produce an executable:\n$ cc bril.o rt.o -o myprog\nIf your Bril @main function takes arguments, those are now command-line arguments to the myprog executable."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#just-in-time-compilation",
    "href": "src/briltxt/docs/tools/brilift.html#just-in-time-compilation",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Use the -j flag to compile and run the program immediately:\n$ bril2json &lt; something.bril | brilift -j\nPass any arguments to the Bril @main function as command-line arguments to Brilift. For example, if you have a function @main(foo: int, bar: bool), you can type brilift -j 42 true."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#options",
    "href": "src/briltxt/docs/tools/brilift.html#options",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Type brilift --help to see the full list of options:\n\n-j: JIT-compile the code and run it immediately, instead of AOT-compiling an object file (the default).\n-O [none|speed|speed_and_size]: An optimization level, according to Cranelift. The default is none.\n-v: Enable lots of logging from the Cranelift library.\n-d: Dump the Cranelift IR text for debugging.\n\nThese options are only relevant in AOT mode:\n\n-o &lt;FILE&gt;: Place the output object file in &lt;FILE&gt; instead of bril.o (the default).\n-t &lt;TARGET&gt;: Specify the target triple, as interpreted by Cranelift. These triples resemble the target triples that LLVM also understands, for example. For instance, x86_64-unknown-darwin-macho is the triple for macOS on Intel processors."
  },
  {
    "objectID": "src/briltxt/docs/tools/rust.html",
    "href": "src/briltxt/docs/tools/rust.html",
    "title": "Rust Library",
    "section": "",
    "text": "This is a no-frills interface between Bril’s JSON and your Rust code. It supports the Bril core along with the SSA, memory, floating point, speculative execution, char, and source positions extensions.\nUse\n\nInclude this by adding the following to your Cargo.toml:\n[dependencies.bril-rs]\nversion = \"0.1.0\"\npath = \"../bril-rs\"\nfeatures = [\"ssa\", \"memory\", \"float\", \"speculate\", \"position\"]\nEach of the extensions to Bril core is feature gated. To ignore an extension, remove its corresponding string from the features list.\nThere are two helper functions: load_program will read a valid Bril program from stdin, and output_program will write your Bril program to stdout. Otherwise, this library can be treated like any other serde JSON representation.\n\n\nThis library supports fully compatible Rust implementations of bril2txt and bril2json. This library also implements the import extension with a static linker called brild.\nThis library is used in a Rust compiler called rs2bril which supports generating core, float, and memory Bril from a subset of valid Rust.\nThis library is used in a Bril-to-LLVM IR compiler called brillvm which supports core, float, memory, and ssa.\nFor ease of use, these tools can be installed and added to your path by running the following in bril-rs/:\n$ make install\nMake sure that ~/.cargo/bin is on your path. Each of these tools supports the --help flag which specifies some helpful flags.\n\n\n\nTo maintain consistency and cleanliness, run:\ncargo fmt\ncargo clippy\ncargo doc\nmake test\nmake features"
  },
  {
    "objectID": "src/briltxt/docs/tools/rust.html#tools",
    "href": "src/briltxt/docs/tools/rust.html#tools",
    "title": "Rust Library",
    "section": "",
    "text": "This library supports fully compatible Rust implementations of bril2txt and bril2json. This library also implements the import extension with a static linker called brild.\nThis library is used in a Rust compiler called rs2bril which supports generating core, float, and memory Bril from a subset of valid Rust.\nThis library is used in a Bril-to-LLVM IR compiler called brillvm which supports core, float, memory, and ssa.\nFor ease of use, these tools can be installed and added to your path by running the following in bril-rs/:\n$ make install\nMake sure that ~/.cargo/bin is on your path. Each of these tools supports the --help flag which specifies some helpful flags."
  },
  {
    "objectID": "src/briltxt/docs/tools/rust.html#development",
    "href": "src/briltxt/docs/tools/rust.html#development",
    "title": "Rust Library",
    "section": "",
    "text": "To maintain consistency and cleanliness, run:\ncargo fmt\ncargo clippy\ncargo doc\nmake test\nmake features"
  },
  {
    "objectID": "src/briltxt/docs/tools/plugin.html",
    "href": "src/briltxt/docs/tools/plugin.html",
    "title": "Syntax Plugin for Text Editors",
    "section": "",
    "text": "Syntax Plugin for Text Editors\nThere is a Vim syntax highlighting plugin for Bril’s text format available in bril-vim. You can use it with a Vim plugin manager. For example, if you use vim-plug, you can add this to your .vimrc:\nPlug 'sampsyo/bril', { 'for': 'bril', 'rtp': 'bril-vim' }\nYou can read more about the plugin, which is originally by Edwin Peguero.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/ts.html",
    "href": "src/briltxt/docs/tools/ts.html",
    "title": "TypeScript Library",
    "section": "",
    "text": "TypeScript Library\nbril-ts is a TypeScript library for interacting with Bril programs. It is the basis for the reference interpreter and the included type checker, but it is also useful on its own.\nThe library includes:\n\nbril.ts: Type definitions for the Bril language. Parsing a JSON file produces a value of type Program from this module.\nbuilder.ts: A builder class that makes it more convenient to generate Bril programs from front-end compilers.\ntypes.ts: A description of the type signatures for Bril operations, including the core language and all currently known extensions.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/SUMMARY.html",
    "href": "src/briltxt/docs/SUMMARY.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIntroduction\n\nLanguage Reference\n\nSyntax\nWell Formedness\nCore\nStatic Single Assignment\nMemory\nFloating Point\nSpeculative Execution\nImport\nCharacter\n\nTools\n\nInterpreter\nText Representation\nTypeScript Compiler\nFast Interpreter\nEditor Plugin\nType Inference\nType Checker\nBenchmarks\nTypeScript Library\nOCaml Library\nRust Library\nBenchmark Runner\nCompiler\nWeb Playground\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/representation.html",
    "href": "notebooks/representation.html",
    "title": "Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/representation.html#a-more-regular-representation",
    "href": "notebooks/representation.html#a-more-regular-representation",
    "title": "Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "href": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "title": "Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/possible_papers.html",
    "href": "notebooks/possible_papers.html",
    "title": "Untitled",
    "section": "",
    "text": "End-to-end deep learning of optimization heuristics - Chris Cummins, Pavlos Petoumenos, Zheng Wang, and Hugh Leather PACT 2017. https://ieeexplore.ieee.org/document/8091247\nDistinguished Paper Award: Revealing Compiler Heuristics through Automated Discovery and Optimization, V. Seeker, C. Cummins, M. Cole, B. Franke, K. Hazelwood, H. Leather\nhttps://dl.acm.org/doi/abs/10.1145/3213846.3213848?casa_token=cbgdY_Wgz9kAAAAA:IMKfnKAYKl3t9wXFen_yauFHY__vyUHcqSgjENz7RB2QEGeTC1L70FEC5vM9FnKBWdAiL6tw1uC4 Compiler fuzzing through deep learning\nchrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://dada.cs.washington.edu/research/tr/2017/12/UW-CSE-17-12-01.pdf 12-01 TVM:End-to-End Optimization Stack for Deep Learnin\n“Effective Superword Level Parallelism for Multimedia Extension Architectures” by Samuel Larsen and Saman Amarasinghe (2000)\nEnergy-Aware Tile Size Selection for Affine Programs on GPUs, M. Jayaweera, M. Kong, Y. Wang, D. Kaeli, Pre-print, Artifact\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/llvm.html",
    "href": "notebooks/llvm.html",
    "title": "intro to llvm",
    "section": "",
    "text": "difference between bril and llvm\nlinks\nllvm page\nAdrians tutorial\nllvm doc\ngoogle or github pilot is very useful for this\n\n#as a first step I'm going to show how to install clang and cmake \n\n# step remove any old copies \n# the -S flag to sudo means - read from stdinput\n# the -y flag means always ans yes to apt \n# since sudo needs a password \n# -qq is the very quiet option \n!sudo -S apt purge -y -qq clang cmake &lt;  ~/pw\n!sudo -S apt install -y -qq clang cmake &lt; ~/pw\n\n\n[sudo] password for norm: The following packages were automatically installed and are no longer required:\n  cmake-data dh-elpa-helper emacsen-common libarchive13 libjsoncpp25 librhash0\nUse 'sudo apt autoremove' to remove them.\nThe following packages will be REMOVED:\n  clang* cmake*\n0 upgraded, 0 newly installed, 2 to remove and 48 not upgraded.\nAfter this operation, 21.3 MB disk space will be freed.\n\n(Reading database ... 40226 files and directories currently installed.)\nRemoving clang (1:14.0-55~exp2) ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Progress: [ 22%] [############..............................................] Progress: [ 33%] [###################.......................................] Progress: [ 44%] [#########################.................................] emoving cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] Progress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n[sudo] password for norm: Suggested packages:\n  cmake-doc ninja-build cmake-format\nThe following NEW packages will be installed:\n  clang cmake\n0 upgraded, 2 newly installed, 0 to remove and 48 not upgraded.\nNeed to get 0 B/5014 kB of archives.\nAfter this operation, 21.3 MB of additional disk space will be used.\n\nSelecting previously unselected package clang.\n(Reading database ... 40203 files and directories currently installed.)\nPreparing to unpack .../clang_1%3a14.0-55~exp2_amd64.deb ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Unpacking clang (1:14.0-55~exp2) ...\nProgress: [ 22%] [############..............................................] electing previously unselected package cmake.\nPreparing to unpack .../cmake_3.22.1-1ubuntu1.22.04.2_amd64.deb ...\nProgress: [ 33%] [###################.......................................] Unpacking cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 44%] [#########################.................................] etting up clang (1:14.0-55~exp2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] etting up cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n\n\nlets take a look at llvm ir\n\n%%writefile temp.c\nint main(int argc, char** argv){\n    return argc;\n}\n\nOverwriting temp.c\n\n\n\n# call clang and dump the ir\n# # -emit-llvm  print the ir\n# -S print as text not as binary \n# 0 -  output to stdout \n# \n!clang -emit-llvm -S -o - temp.c\n\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"frame-pointer\"=\"all\" \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\n!llvm.ident = !{!5}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 7, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"PIE Level\", i32 2}\n!3 = !{i32 7, !\"uwtable\", i32 1}\n!4 = !{i32 7, !\"frame-pointer\", i32 2}\n!5 = !{!\"Ubuntu clang version 14.0.0-1ubuntu1.1\"}\n\n\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThere is a cs6120 package that makes setting up the build process for plugins simple\nllvm ir, has two forms .bc files are bitcode, .ll forms are text versions that look like assembly.\nllvm is not written in C++ but it has a lot of features that look like C++.\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\n\n\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions so if I is an instruction\nouts() &lt;&lt; *(I.getOperand(0)) ; prints an instruction\nGiven a Value* V, what kind of thing is V?\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument\n\nStatic bool isLoopInvariant(const Value *V, const Loop *L) { \n    if (isa&lt;Constant&gt;(V) || isa&lt;Argument&gt;(V) || isa&lt;GlobalValue&lt;(V)) {\n         return true; } \n    //otherwise it must be an instruction…    \n    return !L-&gt;contains(cast&lt;Instruction&gt;(V)-&gt;getParent());\n     … \n}\nNavigating llvm IR - IT Containers\n\nModule - two way linked list of Functions\nFunction - two way linked list of Basic Blocks\nBasic Block - two way linked list of Instructions\n\n%5 = add i32 %4,2\nthis instruction adds two 32 bit ints, input is in register %4 and the constant 2, result goes into register %5\nblog post: Why would a grad student care about llvm\n\n%%bash \nrm -r llvm-pass-skeleton/\ngit clone   https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n# look at  llvm-pass-skeleton/skeleton/Skeleton.cpp\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\nThe function returns PreservedAnalyses::all() to indicate that it didn’t modify M. Later, when we actually transform the program, we’ll need to return something like PreservedAnalyses::none().\nThe ModuleAnalysisManager is responsible for managing the analysis results for Module passes.\nWhen a pass requests an analysis, the ModuleAnalysisManager checks if the analysis result is already available. If it is, the ModuleAnalysisManager returns the cached result. If it’s not, the ModuleAnalysisManager runs the analysis pass, caches the result, and then returns it.\nThis allows LLVM to avoid recomputing analysis results unnecessarily, which can significantly improve the performance of the compiler.\nHere’s an example of how you might use it:\nPreservedAnalyses MyPass::run(Module &M, ModuleAnalysisManager &MAM) {\n    // Request an analysis result.\n    const auto &Result = MAM.getResult&lt;SomeAnalysis&gt;(M);\n\n    // Use the analysis result.\n    // ...\n\n    return PreservedAnalyses::all();\n}\nHere is a second example getting the dominator tree\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Request the dominator tree of the function.\n            const DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Use the dominator tree.\n            // ...\n        }\n\n        return PreservedAnalyses::all();\n    }\nnow let look at the containers\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b containers  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\nError while terminating subprocess (pid=71626): \n[100%] Built target SkeletonPass\n\n\n\n# run the plugin \n# \n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp.c\n\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  ret i32 %6\nI saw a function called main!\n\n\n\n%%writefile temp1.c\nint main(int argc, char** argv){\n    if (argc &gt;2 )\n        return argc;\n    return 0;\n}\n\nOverwriting temp1.c\n\n\n\n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp1.c\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  %7 = icmp sgt i32 %6, 2\nInstruction: \n  br i1 %7, label %8, label %10\nBasic block:\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\nInstruction: \n  %9 = load i32, i32* %4, align 4\nInstruction: \n  store i32 %9, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\nInstruction: \n  %12 = load i32, i32* %3, align 4\nInstruction: \n  ret i32 %12\nI saw a function called main!\n\n\n\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\n[100%] Built target SkeletonPass\n\n\n\n%%bash \ncat ls ~/llvm/llvm-pass-skeleton/skeleton/Skeleton.cpp \necho done\n\ncat: ls: No such file or directory\n\n\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/Transforms/Utils/BasicBlockUtils.h\"\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}\ndone\n\n\n\n%%bash \ncat /home/norm/llvm/llvm-pass-skeleton/rtlib.c\necho\n\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}\n\n\n\n\n%%writefile llvm-pass-skeleton/test_r.cpp\n#include &lt;stdio.h&gt;\nint main (int argc, char** argv) {\n    printf(\"%d %d\", argc, (argc + 2) * (argc +3));\n}\n\nOverwriting llvm-pass-skeleton/test_r.cpp\n\n\n\n%%bash \ncd llvm-pass-skeleton/\ncc -c rtlib.c\nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test_r.cpp\ncc test_r.o rtlib.o\n./a.out 1 2 3 4\necho \n\ncomputed: 7\n5 56\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/09_poly.html",
    "href": "lectures/09_poly.html",
    "title": "9 polyhedral analysis",
    "section": "",
    "text": "We get a new flavor of IR - more math like\ntwo kinds of problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid\npolyhedral scheduling - find a transform that maximizes/minimizes some property\n\nThe base idea - A statement in a loop might execute a lot of times Each time it executes there is one instance of the statement\nWe want an ir that:\n\nlet us reason about each instance\nis finite (even in the number of instances is not)\nlets a compiler reason about what is going on\n\nNegative -\nOnly applies to loop nests, where everything, array indexs, bounds, statements etc are affine so not not loops hidden in recursion\n99% of hpc loops are affine C. Bastoul, A. Cohen, S. Girbal, S. Sharma, and O. Temam. Putting polyhedral loop transformations to work. In LCPC, 2003.\nover 95% of loops in deep learning are affine Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, RaminderBajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. 2017. In-datacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA). IEEE, 1–12.\nOver the course of this, I’ll use 3 pieces of math 1) ILP integer linear programming find a set of integers that satisfies a set of inequalities and maximize something 2) fourier-motzkin method 3) The affine form of Farkas Lemma",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "9 polyhedral analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#formalizing-the-schedule-lexicographic-ordering",
    "href": "lectures/09_poly.html#formalizing-the-schedule-lexicographic-ordering",
    "title": "9 polyhedral analysis",
    "section": "formalizing the schedule, Lexicographic ordering",
    "text": "formalizing the schedule, Lexicographic ordering\nschedule s(i,j) -&gt; (i,j) statements -&gt; vector (should be a time)\nHow do we interpret a vector as a time, e.g. hours, min, seconds.\nUsually written as $$ Generalization of alphabetical order\n\\[\n(i,j) \\gg (m,n) \\iff i &gt;  m \\lor (i=m \\land j&gt; n)\n\\]\nCompare left to right if terms are equal, go to next term, or different so compare the terms\nNotice the or we will need to call the ilp solver more than once\nChecking for loop interchange\nfor i in [1,2,3,4]                     for j in [1,2,3]\n  for j in [1,2,3]                       for i in [1,2,3,4]\ns:   a(i,j) = a(i-1,j+1)                   a(i,j) = a(i-1,j+1)  \n\n\ns(i, j) -&gt; (i,j)                          s(i,j)=(j,i)\ndata flow\n    read write\ns(1,1) a(0,2) a(1,1) s(1,2) a(0,3) a(1,2) s(1,3) a(0,4) a(1,3) s(1,4) a(0,5) a(1,4) s(2,1) a(1,2) a(2,1) s(1,2)-&gt; s(2,1) s(2,2) a(1,3) a(2,2) s(1,3)-&gt; s(2.2) …\ns(i,j) writes a value that is consumed in s(i+1, j-1)\n\\[\ns(i,j) \\rightarrow s(i+1, j-1)\n\\] constants:\nDoes there exist a statement s(i,j) and a statement \\(s(i',j')\\) where in the new schedule \\(s(i',j')\\) executes first and data flows backward in time \\[\n\\begin{align*}\n(i', j') \\gg (j,i)   &\\text{ $i',j'$ is first} \\\\\ni' = 1+ i            &\\text{ data\\  from \\ i+1 to $i'$}\\\\\nj' = -1 +j           &\\text{ data\\  from \\ j-1 to $j'$}\\\\\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 3  \\\\\n1 \\le i' le 4 \\\\\n1 \\le j' \\leftrightarrows 3\n\\end{align*}\n\\]\nbecause of the lexicographic order ( or) we have two ilp problems one where \\(i'\\) is greater then j, and one where \\(i'\\) = j, and the other where \\(j'\\) &gt; j\ni ran it through https://online-optimizer.appspot.com\nwhich gave me a solution\ns(4,2) reads s(3,3) but s(4,2) executes first",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "9 polyhedral analysis"
    ]
  },
  {
    "objectID": "lectures/09_poly.html#ir",
    "href": "lectures/09_poly.html#ir",
    "title": "9 polyhedral analysis",
    "section": "ir",
    "text": "ir\nHow do we represent these sets in the ir?\nfor i in [0,1,2,3,4,5]\n  for j from  i to 7\n     a(i,j) = 0\n\nchange the equations around so that they are … \\(\\ge 0\\)\n\\[\n\\begin{align*}\ni \\ge 0  &\\rightarrow  i \\ge 0 \\\\\ni \\le 5 &\\rightarrow -i + 5 \\ge 0 \\\\\nj \\ge i &\\rightarrow -i + j \\ge 0 \\\\\nj \\le 7 &\\rightarrow =j+7 \\ge 0\n\\end{align*}\n\\]\nWe can split off the constraints: \\[\nconstraints  = \\left\\{ \\vec{x} \\mid B\\vec{x} + \\vec{b} &gt;= 0\\right\\}\n\\]\nWhere: \\[\n\\begin{equation*}\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n0 & -1\n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n0 \\\\\n5  \\\\\n0   \\\\\n7\n\\end{bmatrix}\n\\vec{x} =\n\\begin{bmatrix}\ni \\\\\nj\n\\end{bmatrix}\n\\end{equation*}\n\\]\nThis also works if the loop bounds are symbolic ~~~ for i in [L.. U] for j from i to 7 a(i,j) = 0\n$$\n\\begin{equation*}\nB = \n\\begin{bmatrix} \\begin{array}{rr}\n 1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n 0 & -1\n \\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n L \\\\\n U\\\\\n0\\\\\n7\n\\end{bmatrix}\n\\end{equation*}\n$$\n\n\n## suppose we have complex loop bounds?\n\n```\nfor i=0; i &lt; 7, i++\n  for j =i, j &lt; min(7, i+4), j++\n    a(i,j) = 0\n```\n![alt text](plot1-7.png)\n\nshaded area is the polygon\nwhat are the loop bounds if we interchange the loops?\n\nWhat are the upper and lower bounds if we interchange the loops?\n\ninequalities\n$$\n\\begin{align*}\ni \\ge 0   & \\rightarrow  i  \\ge 0 \\\\\ni \\le 6   & \\rightarrow  -i+6 \\ge 0 \\\\\nj \\ge i   & \\rightarrow j-i \\ge 0 \\\\\nj \\le 6    & \\rightarrow  6  -j  \\ge 0 \\\\\nj \\le i+3 & \\rightarrow -j+i+3 \\ge 0 \n\\end{align*}\n$$\n\n```\nfor j  (must be constants)\n  for j (constants and j )\n\n```\n\nwe can get the j bounds by projecting onto the j axis,  next we want to remove j from the inequalities \n\n\nir constrants\n\n$$\n\\begin{align*}\n\\begin{equation*}\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n 1 & 0 \\\\\n-1 & 0 \\\\\n-1 & 1 \\\\\n0 & -1 \\\\\n 1 & -1 \n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n 0\\\\\n 6 \\\\\n0\\\\\n6\\\\\n3\n\\end{bmatrix}\n\\end{equation*}\n\\end{align*}\n$$\n\nwritten for i\n$$\n\\begin{align}\n0  \\le  & i & \\\\\n        & i &\\le 6 \\\\\n        & i & \\le j \\\\\n        & &  6  -j  \\ge 0 \\\\\nj -3 \\le & i &\n\\end{align}\n$$\n\n$ i \\le max(0, j-3) \\land  i \\le min(6,j) $\n\nwritten for j\n$$\n\\begin{align}\n       & & i \\ge 0 \\\\\n       & & i \\le 6  \\\\\ni \\le  &j & \\\\\n    &  j  & \\le 6 \\\\\n&j& \\le i+3 \n\\end{align}\n$$\n\n\nbounds for j depend on i -  We need to remove i \n\n\nmath thing #2 fourier-motzkin method\n\nhttps://people.math.carleton.ca/~kcheung/math/notes/MATH5801/02/2_1_fourier_motzkin.html\n\nGiven a set of inequalities remove one variable, (for higher dim d, need to do this multiple times)\n\nin general \nSuppose we want to remove $x_m$ we find a pair $L \\le c_1 * x_m $  and  upper bound $x_2 * x_m \\ge U$ and both c's are &gt;= 0\n\nremove x_m and add $c_2* L \\ge c_1 *U $\n\nWe start with each pair of constants\n$$\nc_1 * i &lt; U \\land\nc_2 *i &gt; L\n$$\n\nthere are 4 pairs (1,2), (1,3) , (2,5),  (3,5) \nall the c's are 1 \nfrom the ir column 1 (i column) ignore zeros, pair up plus and minus values \n\n\nWe need to eliminate i (to get the bounds for the outer loop in j)\n\nwe have 4 inequalities where i is not multiplied by zero $ j \\le 6$ \n\nwe consider each pair\n\n$$\n\\begin{align*}\n(1,2) \\rightarrow  0 &\\le 6 \\ done \\\\\n(1,3) \\rightarrow  0 &\\le j\\\\\n(2,5) \\rightarrow j-3  &\\le 6\\\\\n(3,5) \\rightarrow j-3  &\\le j \\ done \n\\end{align*}\n$$\n\nbounds for j are 0 to 6\n\n\n```\nfor j =0 ; j &lt;= 6 , j++\n    for i = max(j-3,6), i &lt; j; i++&gt;  \n       a[i,j] = 0\n```\n\n\n## suppose we want to run the an example  in parallel\nfor i in [1,2,3,4] for j in [1,2,3, 4] s: a(i,j) = a(i-1, j+1) ~~~\nreorder to run in parallel get new bounds, we want to run diagonally \\(k= i-j\\), we know the transformation that we want We replace $i = k+j $\nfor k = ?? for j = ?? s: a(j-k,j) = a(j-k-1, j+1)\n\\[\n\\begin{align*}\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 4 \\\\\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n1 \\le & k+j &\\le 4 \\\\\n1 \\le & j &\\le 4 \\\\\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n1-k \\le j \\le 4-k \\\\\n1 \\le j &lt;= 4\n\\end{align*}\n\\]\nnow for mf \\[\n\\begin{align*}\n1-k \\le  4-k \\\\\n1-k  \\le 4\\\\\n1 \\le 4-k \\\\\n1 \\le 4\n\\end{align*}\n\\]\ngiving k bounds -3 to 3 j bound are max(1,1,k) yo min(4, 4-k)",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "9 polyhedral analysis"
    ]
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html",
    "href": "lectures/08_classic_loop_ops.html",
    "title": "8 classic loop optimizations",
    "section": "",
    "text": "Loops optimizations are important because\nWhat are classic loop optimizations?\nLess classic loop optimizations\nFirst recall natural loops\ndef of loop invariant for an instruction d = op a,b\nin SSA form if we find a loop invariant instruction we can always move it into the pre-header, because the value it writes is never rewritten, and the values that it depends on come from outside the loop\nconditions when moving an instruction d = a op b is ok\ncan move d\nL0: d = 0 preheader L1: if (i&gt;=N) goto L2 i = i + 1 d = a ⊕ b = d goto L1 L2: x = d ```\nno good d used after the loop, would not be changed if the loop executes zero times\nno good d reassigned in the loop, do invar would be changed\nwhile (e) { j = loopinv // may never execute S }\nj = loopinv // always executes while (e) { S }\nif (e) { j = loopinv // may never execute while (e) { S }\n} ````",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "href": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "title": "8 classic loop optimizations",
    "section": "induction variable elimination",
    "text": "induction variable elimination\nfor (int i = 0; i &lt; 100; ++1){\n    f(a[i])\n}\ncalculate a[i] as: &a[0] + 4 * i in every loop iteration, but the values at each step only differ by 4\n\na_i = &a[0] before the loop\na_i = a_i + 4 (add the stride) in every iteration\nthe only remaining use of i is the test i &lt; 100, which could become a_i &lt; &a[0] + 4*100 (which is loop invariant)\n\nsteps\n1find basic induction variables i = i + e, where e is loop invariant\nwhat does this look like in ssa\nloop header:\n i1 = phi(i0, i2)\nloop body:\ni2 = i1 + e\nloop header:\n i1 = phi(i0, i2)\nloop body:\na0 = i1 + e\ni2 = a0 + e1\nfor each instruction d = c +- loop invariant see if there is a strongly connected graph in the ssa edges that only has adds and subtracts of loop invariant expressions\nStep 2 find auxiliary induction variables\nj = basic_ind * loop inv + loop invar\nfor (int i = 0; i &lt; n; i++) {\n     j = 2*i + 1;     // Y \n     k = -i;          // Y \n     l = 2*i*i + 1;   // N \n     c = c + 5;       // Y* \n}\nstep 3 replace auxiliary induction variables (derived ) by new variables without the multiply\nstep4 if the only remaining use of the induction variable is the termination test, change the test to use the new variable\nsum = 0\nfor (i = 1, i &lt; 100; i++) {\n  sum = sum + a[i -1]\n}\nin SSA form:\n   sum0 = 0\n   i0 = 1\nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t10 = i1 -1 \n   t20 = t10 * 4\n   t30 = t20 + &a\n   t40 = load t30\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   if (i2 &lt;= 100)go to l\n\ni is a basic induction variable\nt10 is a aux induction variable\nt20 is an aux induction variable\nt30 is an aux induction variable\n\nt3 has a use in the load\nt3 = t20 + &a ==&gt; t10 * 4 + &a ==&gt; (i1-1)* 4+ &a\nt3 = 4* i1 + &a - 4\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   t52 = t50 + 4\n   if (i2 &lt;= 100)go to l\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   // i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   //i2 = i1 + 1\n   t52 = t50 + 4\n   if (t52 &lt;= 396 + &a )go to l",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "href": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "title": "8 classic loop optimizations",
    "section": "loop un-switching",
    "text": "loop un-switching\nfor (int i = 0 ; i &lt; 100; ++1){\n    if (c) {  // c is loop invariant \n        f(i)\n    } else {\n        g(i)\n    }\n}\nlook for special patterns and replace\nif (c) {  // c is loop invariant \n   for (int i = 0 ; i &lt; 100; ++1){\n        f(i)\n    } \n}else {\n    for (int i = 0 ; i &lt; 100; ++1){\n        g(i)\n    }\n}\nThis is often done before vectorization\nloop fusion\nfor (i = 0; i &lt; 100 ; ++){\n s0:   b[i] = f(a[i])\n}\nfor (i = 0; i &lt; 100 ; ++){\n s1:   c[i] = f(b[i])\n}\n\nwhen is it legal to do this?\nWhen can we get rid of the b array?\n\nThere is also an optimization that goes the other way split a loop so that each statement becomes a separate loop incase we could run as vectors\nThese sort of loop optimizations would make good projects",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "8 classic loop optimizations"
    ]
  },
  {
    "objectID": "lectures/100_mlir.html",
    "href": "lectures/100_mlir.html",
    "title": "10 MLIR",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "10 MLIR"
    ]
  },
  {
    "objectID": "lectures/05_global.html",
    "href": "lectures/05_global.html",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs.\nIn data flow we talked about a matrix all_defs x all_uses which is very sparse and very slow to process. One way to speed it up, is use-def chains, for each use build a list of all defs that might reach that use. Or we could have def-use chains for each def calculate the set of all uses that the def might reach. Both of these are good, but we are going use a much better data structure that is both smaller and faster to process. We also want ways to talk about loops in programs, since optimizations that move instructions inside loops to a place outside loops often speed up programs\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a\n\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b\nA control flow graph\n\n\n\n\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\nThe dominator tree\n\n\n\n\n\ngraph TD;\nn0 --&gt; n1;\nn0 --&gt; n2;n0 --&gt; n3\nn1 --&gt; n4;\n\n\n\n\n\n\ndominators\n\nn0 dominates n0, n1, n2, n3 and n4\nn1 dominates n1, n2, n3 and n4\nn2 dominates n2\nn3 dominates n3\nn4 dominates n4\n\nimmediate dominators\n\nn0 idom n1\nn0 idom n1\nn3 idom n3\nn1 idom n4\n\na simple implementation\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]\nTo find the dominators of a node, first put the node itself in the dominators set. Then, take all the common (i.e. intersection) dominators of its predecessors and put them in the set.\nWhat order do we want to process the nodes?\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}\nHow do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, Which is the dominator\nlets look at a more complex example\n\n\n\n\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\nlets look at a more complex example\n\n\n\n\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\nsubproblem: find lowest common ancestor of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower the nodes in post order, nodes at the top of the cfg have higher numbers\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse (int i; postorder) {\n      BasicBlock *bb = &cfg[i];\n      int new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n      foreach (pred ; bb.preds[1..bb.preds.length]) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}\n\nint intersect(int b1, int b2, Array!int idoms, Array!int postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5’ dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6.\n## natural loops\n\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\nconditions for a natural loop:\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header\n\nHow about an example of a cycle that has a cycle and no header\n\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points.\ndefine a backedge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a backedge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B\n\nLets see what this means for nested loops\n\n\n\n\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\nBackedges B -&gt; H2, and B-&gt; H1\nfor B-&gt; H2, loop is H2, for B-&gt; H1, loop is H1, A, H2, B\n*** reducible control flow *** in a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A.\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations.\nloop has two entry p\nWhere did the name come from:\nT1 and T2 transforms\nT1: Let G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1 on node n is removal of this self-loop.\nT2: Let n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node. Then transformation T2 on node pair (n1,n2) is merging nodes n1 and n2 into one node, named n1/n2, and deleting the unique edge between them\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}\nsimplified control flow\n\n\n\n\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\n\n\n\n\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case1\n    switch --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; switch\n    dowhile --&gt; exit\n\n\n\n\n\n\nthe argument about no goto’s is really an argument about reducible control flow",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/05_global.html#all-kinds-of-graph-properties--",
    "href": "lectures/05_global.html#all-kinds-of-graph-properties--",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs.\nIn data flow we talked about a matrix all_defs x all_uses which is very sparse and very slow to process. One way to speed it up, is use-def chains, for each use build a list of all defs that might reach that use. Or we could have def-use chains for each def calculate the set of all uses that the def might reach. Both of these are good, but we are going use a much better data structure that is both smaller and faster to process. We also want ways to talk about loops in programs, since optimizations that move instructions inside loops to a place outside loops often speed up programs\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a\n\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b\nA control flow graph\n\n\n\n\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\nThe dominator tree\n\n\n\n\n\ngraph TD;\nn0 --&gt; n1;\nn0 --&gt; n2;n0 --&gt; n3\nn1 --&gt; n4;\n\n\n\n\n\n\ndominators\n\nn0 dominates n0, n1, n2, n3 and n4\nn1 dominates n1, n2, n3 and n4\nn2 dominates n2\nn3 dominates n3\nn4 dominates n4\n\nimmediate dominators\n\nn0 idom n1\nn0 idom n1\nn3 idom n3\nn1 idom n4\n\na simple implementation\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]\nTo find the dominators of a node, first put the node itself in the dominators set. Then, take all the common (i.e. intersection) dominators of its predecessors and put them in the set.\nWhat order do we want to process the nodes?\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}\nHow do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, Which is the dominator\nlets look at a more complex example\n\n\n\n\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\nlets look at a more complex example\n\n\n\n\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\nsubproblem: find lowest common ancestor of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower the nodes in post order, nodes at the top of the cfg have higher numbers\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse (int i; postorder) {\n      BasicBlock *bb = &cfg[i];\n      int new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n      foreach (pred ; bb.preds[1..bb.preds.length]) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}\n\nint intersect(int b1, int b2, Array!int idoms, Array!int postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5’ dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6.\n## natural loops\n\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\nconditions for a natural loop:\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header\n\nHow about an example of a cycle that has a cycle and no header\n\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points.\ndefine a backedge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a backedge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B\n\nLets see what this means for nested loops\n\n\n\n\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\nBackedges B -&gt; H2, and B-&gt; H1\nfor B-&gt; H2, loop is H2, for B-&gt; H1, loop is H1, A, H2, B\n*** reducible control flow *** in a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A.\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations.\nloop has two entry p\nWhere did the name come from:\nT1 and T2 transforms\nT1: Let G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1 on node n is removal of this self-loop.\nT2: Let n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node. Then transformation T2 on node pair (n1,n2) is merging nodes n1 and n2 into one node, named n1/n2, and deleting the unique edge between them\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}\nsimplified control flow\n\n\n\n\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\n\n\n\n\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case1\n    switch --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; switch\n    dowhile --&gt; exit\n\n\n\n\n\n\nthe argument about no goto’s is really an argument about reducible control flow",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "5 Global Analysis"
    ]
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html",
    "href": "lectures/03b_local_value_numbering.html",
    "title": "_ local value numbering",
    "section": "",
    "text": "Local Value Numbering\nValue numbering is a very powerful technique that removes redunancies, An instruction x + y is redundant inside a block if it has already been computed in the block, and no intervening operation redefines x or y. If the compiler finds a redundant expression, it can save that value at the first computation and replace any subsequent evaluations with references to the saved value.\nThe idea is simple - The algorithm executes the block, Each time it sees a new variable it gives it a value (reprented as a number) Each time it sees an instruction it forms a hash of the op code and t he value numbers of its operands and gives tha a new value number.\nTwo instructions are redundant if they have same op code and operands, which means the same value number\ne_i and e_j have the same value number if and only if e_i and e_j are provably equal for all possible operands of the expressions.\nlocal value numbering covers lot of optimizations\ndead code elimination\n\nmain {\n    a: int = const 100;\n    a: int = const 42;\n    print a;\n\n}\n\ncopy propagation\n\nmain{\n    x: int = const 4;\n    copy1: int = id x;\n    copy2: int = id copy1;\n    print copy2;\n}\n\ncommon sub-expression elimination cse \n\nmain {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}\nWe want to stop thinking about varaibles and think about values. Two instructions are redundant if they compute the same value.\n\n\nthis is a very deep idea that comes up multiple times.\nfor example in a JIT compiler we want computation to be fast so we can get rid of all the variables\nb: int const 1;\nc: int cont 2;\na:  int b c;  \nbecomes:\n[  int const 1\n   int const 2 \n   int 0 1\n]\nless storage, args are just pointers, instructions are smaller. faster because any use points to the corresponding def without any searching.\nPseudo code (similar to an interpreter)\nhash table constants and expressions of value numbers to value numbers and a variable holding the value\nreverse map from variable to value numbers\n  main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mult sum1 sum2;\n    print prod\n\n  }\ntable\n\n\n\nkey\nvalue\ncanonical name\n\n\n\n\nconst 4\n1\na\n\n\nconst 2\n2\nb\n\n\nadd 1 2\n3\nsum1\n\n\nmul 3 3\n4\nprod\n\n\n\nrevese map\n\n\n\nname\nvalue\n\n\n\n\na\n1\n\n\nb\n2\n\n\nsum1\n3\n\n\nsum2\n3\n\n\nprod\n4\n\n\n\nas we lookup each instruction - replace each arg with the canonical home\nif the value is already in the table replace with an id from canonical home\nextensions\n\na: int id b\n\na gets the value number of b. No copy required\n\n: int add a b; for add sort value numbers so add a b; and add b a; get the same value number\n\n\nconstant folding \n   a: int const 1;\n   b: int const 2;\n   c: add a b;\nif both value numbers are pointing to constants- actually do the add\n\n\npseudo code\n   table = mapping from value tuples to canonical variables,\n     with each row numbered\n   var2num = mapping from variable names to their current\n     value numbers (i.e., rows in table)\n\n   for instr in block:\n       value = (instr.op, var2num[instr.args[0]], ...)\n\n       if value in table:\n           # The value has been computed before; reuse it.\n           num, var = table[value]\n           replace instr with copy of var\n\n       else:\n           # A newly computed value.\n           num = fresh value number\n\n           dest = instr.dest\n           if instr.dest  will be overwritten later:\n                dest = fresh variable name\n                instr.dest = dest\n           else:\n                dest = instr.dest\n\n           table[value] = num, dest\n\n           for a in instr.args:\n               replace a with table[var2num[a]].var\n\n       var2num[instr.dest] = num\nproblem: canonical variables being overwritten\n``` x = a+b\nx = = a+b\n```\n\nLocal value numbering.\n\nYou can see my implementation in lvn.py in [the examples directory] in the Bril repository. But seriously, don’t be tempted! You want to write your implementation without looking at mine!\nexamples ### Testing Your Optimizations\nAs part of your tasks for this lesson, you will implement your first two optimizations. The two main things you want your optimizations to do are:\n\nNot break programs.\nMake programs faster, most of the time.\n\nAs with every task in this class, part of the work is checking that you have done what you set out to do—in this case, that your optimizations do those two things. Think carefully about how to make a convincing case for each of those criteria.\nOne tempting methodology might be to handwrite a few small test-case Bril programs (or, worse, borrow the woefully inadequate ones sitting around in the Bril git repository), run them through your optimizations, and look at them to check whether they look right. This does not amount to convincing evidence (maybe you can think of a few specific reasons why).\nWhile there are many ways to be convincing, a pretty good way might be to run your optimization on every single available Bril benchmark, systematically check that it still produces the right output for at least one input, and collect aggregate statistics about some metric you’re interested in. This is a nice way to check for unexpected behavior in programs that you didn’t carefully write yourself to test the cases you’re thinking of.\nIf this is the route you choose, you can do it however you like, I have made a simple tool that you can consider using, called [Brench][]. Brench is not very fancy; it does three things:\n\nIt makes it easy to run a long list of inputs through several different commands. (For example, you can run a long list of Bril benchmarks through an “interpret” command and an “optimize-and-then-interpret” command.)\nIt checks that all the commands agree on their output. (So, in our use case, it checks that optimizing the benchmark doesn’t change its output when interpreted.)\nIt can collect a statistic from each command for comparison. (Like the number of dynamic instructions the interpreter executed, which is a pretty good metric for standard optimizations.)\n\nThose three things are probably what you want to do to make a convincing case for an optimization’s correctness and effectiveness, whether or not you use Brench. It’s there if you want it, but feel free to go your own way!\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ local value numbering"
    ]
  },
  {
    "objectID": "lectures/12_memory.html",
    "href": "lectures/12_memory.html",
    "title": "12_memory.qmd",
    "section": "",
    "text": "Warning\n\n\n\nnot done\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "12_memory.qmd"
    ]
  },
  {
    "objectID": "lectures/02b_bril.html",
    "href": "lectures/02b_bril.html",
    "title": "_ Intro to Bril",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ Intro to Bril"
    ]
  },
  {
    "objectID": "lectures/05b_licm.html",
    "href": "lectures/05b_licm.html",
    "title": "_ loop invariant code motion",
    "section": "",
    "text": "Loop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop.\nA very common case for this is matrix addressing\na[i,j] might expand to to i4stride_a1 + j *4\nfor j \n  a[i,j] = f(a[i.j+1])\na = \nb = \nresult = 0\nfor (){\n    result += a*b\n}\nif we are going to move code we need a kind of landing pad called a pre-header create a new block b. change all the preds of the loop header to point to the preheader, add an edge from b to the loop header\nWe need two steps:\n\nfind loop invariant instructions,\nmove all the loop invariant instructions to the preheader\n\nAn instruction instr in a loop is loop invariant of:\nevery operand is:\n\nconstant or\nall reaching definitions of this operand are outside of the loop\nthere is exactly one def in loop reaching this operand and that def is loop invariant\n\niterate to convergence\n for each instr in  the loop\n  mark it at li iff \n     for all arguments x either\n         all reaching defs of x are outside of the loop (this covers constants)\n         or there is exactly one def of instr in the loop and that def is loop invar\nwhen is ok to move an instr? We call this safe to move.\nloop\n  = x\nx = a*b \n\nthe def must dom all the uses\nno other defs of the same variable\ndef dominates all the loop exits\n\n   loop {\n     if cond goto exit\n     x = a*b \n       = x\n   }\nFor cond 3\nif the loop runs zero times, a*b is never executed\nWe can remove this condition if the dest variable is dead after the loop or the instruction can cause a exception, this is called speculative exceptions.\nHow about an example:\n\n\n\n\n\n    graph TD;\nB1[\" B1:\n      1: b = 2\n      2: i = 1\"]\nB2[\"b2:\n   i &lt; 100\"]\nB3[\"B3:\n   3: a = b+1\n   4: c = 2\n   i mod 2 == 0\"]\nB4[\"b4: \n    5: d = a + d \n    6: e = 1 +d\"]\nB5[\"B5:\n    7: d= -c\n    8: f = 1+a\"]\nB6[\"B6:\n  9: i = i + 1\n     a &lt; 2\"]\nEntry --&gt; B1\nB1--&gt; B2\nB2 -- y --&gt;exit;\nB2 --n --&gt; B3\nB3 --y --&gt; B4\nB3 --n --&gt; B5\nB4--&gt; B6\nB5 --&gt; B6\nB6 --y --&gt; exit\nB6 --n --&gt; B2\n\n\n\n\n\n\n\nsteps:\n\ncreate pre header\nb2.1 not loop invar\nb3.1 loop inv\nb3.2 loop inv\nb3.3 not loop inv\nb4.1 not loop inv\nb4.2 not loop inv\nb5.1 not loop inv other def of d\nb5.2 loop invar\nb6.1 not loop inv\nb6.2 loop inv change = 2 repeat\n\n\n\n\n\n\n    graph TD;\nB1[\" B1:\n      1: b = 2\n      2: i = 1\"]\nB2[\"b2:\n   i &lt; 100\"]\nB3[\"B3:\n   i mod 2 == 0\"]\nB4[\"b4: \n    5: d = a + d \n    6: e = 1 +d\"]\nB5[\"B5:\n    7: d= -c\n\"]\nB6[\"B6:\n  9: i = i + 1\n     t\"]\npre[\"pre:\n   3: a = b+1\n      4: c = 2\n        8: f = 1+a\n        t = a &lt; 2\"]\nEntry --&gt; B1\nB1--&gt; pre\npre --&gt; B2\nB2 -- y --&gt;exit;\nB2 --n --&gt; B3\nB3 --y --&gt; B4\nB3 --n --&gt; B5\nB4--&gt; B6\nB5 --&gt; B6\nB6 --y --&gt; exit\nB6 --n --&gt; B2\n\n\n\n\n\n\n\nIf we forward propagate values we could find a = 3, f = 3, t = false, and since t is false there is no loop\nmoving the instructions out of the loop reduces the number of instructions which is good, but it also extends life times and therefore register pressure which is bad.\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "_ loop invariant code motion"
    ]
  },
  {
    "objectID": "lectures/junk.html",
    "href": "lectures/junk.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "junk file\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "Junk"
    ]
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#early-compilers",
    "href": "lectures/revealjs-compiler_overview.html#early-compilers",
    "title": "1 Compiler Overview",
    "section": "Early Compilers",
    "text": "Early Compilers\nOriginally, a compiler was a person doing calculations.\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n[]"
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#fortran",
    "href": "lectures/revealjs-compiler_overview.html#fortran",
    "title": "1 Compiler Overview",
    "section": "FORTRAN",
    "text": "FORTRAN\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\n2/3 of the cost and 90% of the time for solving a problem was coding\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters."
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#development-model",
    "href": "lectures/revealjs-compiler_overview.html#development-model",
    "title": "1 Compiler Overview",
    "section": "development model",
    "text": "development model\nIn these early years, the development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies."
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#gcc",
    "href": "lectures/revealjs-compiler_overview.html#gcc",
    "title": "1 Compiler Overview",
    "section": "gcc",
    "text": "gcc\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end."
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#llvm",
    "href": "lectures/revealjs-compiler_overview.html#llvm",
    "title": "1 Compiler Overview",
    "section": "LLVM",
    "text": "LLVM\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n\n\n\ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;"
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#bril",
    "href": "lectures/revealjs-compiler_overview.html#bril",
    "title": "1 Compiler Overview",
    "section": "bril",
    "text": "bril\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n\n\n\n\ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];"
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#cost-of-a-compiler.",
    "href": "lectures/revealjs-compiler_overview.html#cost-of-a-compiler.",
    "title": "1 Compiler Overview",
    "section": "Cost of a compiler.",
    "text": "Cost of a compiler.\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nFrom CGO 2022 keynote"
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#compiler-assumptions-lets-talk-about-how-many-are-still-true",
    "href": "lectures/revealjs-compiler_overview.html#compiler-assumptions-lets-talk-about-how-many-are-still-true",
    "title": "1 Compiler Overview",
    "section": "Compiler Assumptions (Let’s talk about how many are still true)",
    "text": "Compiler Assumptions (Let’s talk about how many are still true)\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like."
  },
  {
    "objectID": "lectures/revealjs-compiler_overview.html#how-well-do-compilers-do",
    "href": "lectures/revealjs-compiler_overview.html#how-well-do-compilers-do",
    "title": "1 Compiler Overview",
    "section": "How well do compilers do",
    "text": "How well do compilers do\nAt the scale of datacenters, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\nProebsting’s law\n\nreference to probsting’s law\n\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months\nHow would you prove this?"
  },
  {
    "objectID": "lectures/010_compiler_overview.html",
    "href": "lectures/010_compiler_overview.html",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "A compiler writer builds bridges between people and machines, and this task is each day more challenging.\n\nSoftware engineers want abstractions\n\nHardware engineers want efficiency\n\n\n\nOriginally, a compiler was a person doing calculations.\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n[]\n\n\n\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nWill only appear in HTML and not in Reveal.js\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters.\n\n\n\nIn these early years, the development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n\n\n\n\ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on part 2\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy\n\n\n\n\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks.\n\n\n\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n\n\n\ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments.\n\n\n\n\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n\n\n\n\ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n\n\n\n\n\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nFrom CGO 2022 keynote\n\nSome observations: 1) Production compilers are expensive. 1) IR does not change easily. 1) Much of compiler technology is old. 1) There is a vast difference between production and student projects.\n\n\n\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Doman specific languages for AI)\nMore kinds of hardware\n\n\n\n\nAt the scale of datacenters, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\n\n\n\nreference to probsting’s law\n\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months\nHow would you prove this?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#early-compilers",
    "href": "lectures/010_compiler_overview.html#early-compilers",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "Originally, a compiler was a person doing calculations.\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n[]",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#fortran",
    "href": "lectures/010_compiler_overview.html#fortran",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nWill only appear in HTML and not in Reveal.js\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#development-model",
    "href": "lectures/010_compiler_overview.html#development-model",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In these early years, the development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n\n\n\n\ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on part 2\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#gcc",
    "href": "lectures/010_compiler_overview.html#gcc",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#llvm",
    "href": "lectures/010_compiler_overview.html#llvm",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "in about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n\n\n\ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#bril",
    "href": "lectures/010_compiler_overview.html#bril",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n\n\n\n\ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "href": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "Compilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nFrom CGO 2022 keynote\n\nSome observations: 1) Production compilers are expensive. 1) IR does not change easily. 1) Much of compiler technology is old. 1) There is a vast difference between production and student projects.",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#compiler-assumptions-lets-talk-about-how-many-are-still-true",
    "href": "lectures/010_compiler_overview.html#compiler-assumptions-lets-talk-about-how-many-are-still-true",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "The time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Doman specific languages for AI)\nMore kinds of hardware",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "href": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "At the scale of datacenters, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\n\n\n\nreference to probsting’s law\n\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months\nHow would you prove this?",
    "crumbs": [
      "EECS 7398",
      "Lectures",
      "1 Compiler Overview"
    ]
  },
  {
    "objectID": "Class_Overview/schedule.html",
    "href": "Class_Overview/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Caution\n\n\n\nWhere do we discussions\nThis actually the syllabus - needs weekly dates for a schedule, and paper list\nwe also need to get the notebooks to show up in the lectures section\n\n\n\n\n\nWeek\nTopic\nlectures\nDiscussion\n\n\n\n\n1\nCompiler overview and structure\nlecture\n???\n\n\n\nPerformance Measurement\nlecture\n???\n\n\n2\nRepresenting programs\nlecture\n???\n\n\n\nOverview of Bril\nnotebook\n???\n\n\n3\nLocal analysis and optimization\nlecture\n???\n\n\n4\nData flow\nlecture\n???\n\n\n5\nGlobal analysis\nlecture\n???\n\n\n6\nStatic single assignment\nlecture\n???\n\n\n7\nLLVM\nlecture\n???\n\n\n8\nClassical loop optimizations\nlecture\n???\n\n\n9\nPolyhedral analysis\nlecture\n???\n\n\n10\nMLIR\nlecture\n???\n\n\n11\nInterprocedural Analysis\nlecture\n???\n\n\n12\nMemory Management\nlecture\n???\n\n\n13\nDynamic compilers\nlecture\n???\n\n\n14\nGPU Compilers\nlecture\n???\n\n\n\nPapers\n\n\n\n\n\n\nCaution\n\n\n\nlist of papers and dates for student presentations\n\n\n\n\n\n Back to top",
    "crumbs": [
      "EECS 7398",
      "Class Overview",
      "Schedule"
    ]
  }
]