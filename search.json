[
  {
    "objectID": "homework/project.html",
    "href": "homework/project.html",
    "title": "project",
    "section": "",
    "text": "Half way through the course, you should submit a project proposal, I’ll review it to make sure you are not tackling too big a challenge or going to far afield.\nAt the end of the course, you will complete a compiler research project. This is an open- ended project that can be on any topic in the field of compilers.\nThe final product is an experience report where you rigorously evaluate the success of your implementation. You can work individually or in groups of 2–3 students. When you finish an implementation, write it up. Your writeup should answer these questions in a good degree of detail: ● What was the goal? ● What did you do? (include both the design and the implementation) ● What were the hardest parts to get right? ● Were you successful? (report rigorously on your empirical evaluation)\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/1.hw.html",
    "href": "homework/1.hw.html",
    "title": "1 Homework",
    "section": "",
    "text": "Warning\n\n\n\n\nhow to add benchmark to repo pull request to where - add benchmark to docs?\nhow to ask questions on writing benchmark, discussion goes where (Canvas?)\nhow to write blog on what got done\nhow to submit blog url to canvas, what do they submit for grading\n\n\n\nYour goal is to get familiar with Bril.\nPart 1\nWrite a new benchmark.\nYou can write it by hand, use the TypeScript compiler, or generate it some other way. Try running it with brili.\nOpen a pull request to add your new benchmark. ??? Add your code to the the benchmarks directory.\nUse turnt –save yours.bril to create the test outputs for your new benchmark. (See the Turnt README for details.) Mention it in the docs.\npart 2 Write a program to analyze or transform Bril programs in some small way. Pick your favorite programming language—there is no “starter code,” so you can start from scratch.\nLoad up a JSON file. You can start with this tiny one! Read the docs.\nDo something unambitious with it: count the number of add instructions, or add a print instruction before every jump, or whatever. Pick something small and contrived! Use Turnt to test your new tool.\nAlong the way, you will run into problems! Ask questions on ???, and open issues and pull requests to describe or fix problems. For example, even super simple benchmarks you might imagine probably can’t be written easily because Bril is too simple. Mention this on ??? discussions, and consider pitching in to help add features.\nThink about how to write a good test, and finally write a post describing your work and submit it in Canvas\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/6_extra_credit.html",
    "href": "homework/6_extra_credit.html",
    "title": "6 Homework extra credit",
    "section": "",
    "text": "Task6: Implement and evaluate a loop optimization, either start with Bril or LLVM, you can use the ssa form of Bril if you want. If you use Bril you will have to find the natural loops, if you use LLVM you can call LoopPass but other parts of the implementation will be tricker, Pick an optimization (I’d suggest loop invariant code motion) but any of the others mentioned in class would be fine. Evaluate its performance, in Bril you can use the Bril benchmarks, in LLVM select an existing benchmark such as Embench and feel free to violate the sigplan guidelines SIGPLAN empirical evaluation guidelines by cherry-picking a convenient subset.\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/4_hw.html",
    "href": "homework/4_hw.html",
    "title": "4_homework",
    "section": "",
    "text": "Task4: Implement some of the dominance utilities- 1) Find dominators for a function, 2) construct the dominance tree, 3) compute the dominance frontier. Devise a way to test your implementations. Can you find a way to confirm that block A dominates blockB. When you code this, remember that computing these sets should be cheap while checking their output could use slow naive algorithms.\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/3_hw.html",
    "href": "homework/3_hw.html",
    "title": "3 Homework",
    "section": "",
    "text": "Task3: Implement one data flow analysis - For Bonus points make it generic so that the same code supports multiple analysis. As always, think about how to test it.\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html",
    "href": "lectures/13_dynamic_compilers.html",
    "title": "Dynamic Compilers",
    "section": "",
    "text": "a jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "href": "lectures/13_dynamic_compilers.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "title": "Dynamic Compilers",
    "section": "",
    "text": "a jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#can-jit-compiled-code-run-faster-then-aot-code",
    "href": "lectures/13_dynamic_compilers.html#can-jit-compiled-code-run-faster-then-aot-code",
    "title": "Dynamic Compilers",
    "section": "Can jit compiled code run faster then aot code?",
    "text": "Can jit compiled code run faster then aot code?"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#comparison",
    "href": "lectures/13_dynamic_compilers.html#comparison",
    "title": "Dynamic Compilers",
    "section": "Comparison",
    "text": "Comparison\n\n\n\naot\njit\n\n\n\n\ncannot inline libraries\ncan inline (even class methods)\n\n\nno runtime code gen\ncan use run time code gen\n\n\nno speculative opts\ncan use spec opts\n\n\nless information\nmore information\n\n\noverall performance lower\noverall performance often higher\n\n\nfull speed from the start\nrequires warmup\n\n\nno compile cost at run time\noverhead to run compiler"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tradeoffs",
    "href": "lectures/13_dynamic_compilers.html#tradeoffs",
    "title": "Dynamic Compilers",
    "section": "Tradeoffs",
    "text": "Tradeoffs\n\nThe time to compile is part of the total execution time\nmight run less optimizations to speed up execution time\nmight look at run time info\nsame code might be compiled many times\n\nWt would the same code be compiled more than once?"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tiered-compilers",
    "href": "lectures/13_dynamic_compilers.html#tiered-compilers",
    "title": "Dynamic Compilers",
    "section": "tiered compilers",
    "text": "tiered compilers\nSince compilation is costly, do not compile functions that are only called once and do not contain a long running loop\nwe have a series of compilers, each with more aggressive optimization and each allowed to take longer\n\nthe lowest tier is the interpreter\nthe next is the base line compiler\n\n\n\nstart interpreting the code\nif some part of the code takes a long time, compile it with the next higher tier\nis some runtime info changes, compile it again"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#magic-numbers",
    "href": "lectures/13_dynamic_compilers.html#magic-numbers",
    "title": "Dynamic Compilers",
    "section": "magic numbers",
    "text": "magic numbers\nassociate a counter with branches and functions if the counter reaches some magic number use one of the compilers\nif the counter for a backward branch, you recompile, but the code is executing in the middle of a loop, so how do you insert the newly compiled code?"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#questions-when-building-a-jit",
    "href": "lectures/13_dynamic_compilers.html#questions-when-building-a-jit",
    "title": "Dynamic Compilers",
    "section": "questions when building a JIT",
    "text": "questions when building a JIT\n\nwhat strategy do you use to invoke the jit\ndo you have to execute for a while before calling the jit\nhow much info do you need\nwhat is the price of wrong info\nare there easy and hard programs\ndo the easy programs match up with users common programs"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#speculation",
    "href": "lectures/13_dynamic_compilers.html#speculation",
    "title": "Dynamic Compilers",
    "section": "Speculation",
    "text": "Speculation\n\nassume some property is true, compile using that info this is always a gamble, so you need to recover if the assumption was wrong\nassume a variable is an int, and does not overflow\nassume properties of an object is fixed\nassume the target of call is always the same\nassume past behavior predicts future behavior"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#flow",
    "href": "lectures/13_dynamic_compilers.html#flow",
    "title": "Dynamic Compilers",
    "section": "flow",
    "text": "flow\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#boxed-values",
    "href": "lectures/13_dynamic_compilers.html#boxed-values",
    "title": "Dynamic Compilers",
    "section": "boxed values",
    "text": "boxed values\nMany languages do not use strong static typeing\nfor example in python\nx = x + 1\nx could be an int/float/object\nthe value of x needs to carry a type. Represent x as a pair (type, pointer or bits) The pair is called a boxed value\nthen to generate code for the plus we have to figure out what kind of add, based on the type"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches",
    "href": "lectures/13_dynamic_compilers.html#inline-caches",
    "title": "Dynamic Compilers",
    "section": "inline caches",
    "text": "inline caches\nin languages like python, calls to a method are more expensive then calls to a method in c++ why?\n. . .\nPython objects are implemented as hash tables. While C++ uses virtual tables\nhow does that effect the cost?"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#first-c-virtual-tables",
    "href": "lectures/13_dynamic_compilers.html#first-c-virtual-tables",
    "title": "Dynamic Compilers",
    "section": "first C++ virtual tables",
    "text": "first C++ virtual tables\nin C++ a method call takes two dereferences\n\nfirst find the v-table\nsecond used a fixed offset from the table start to find the address"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#what-do-we-need-to-keep-the-offset-fixed",
    "href": "lectures/13_dynamic_compilers.html#what-do-we-need-to-keep-the-offset-fixed",
    "title": "Dynamic Compilers",
    "section": "What do we need to keep the offset fixed?",
    "text": "What do we need to keep the offset fixed?\nif derived inherits from base, and both have a function f. the offset to f has to be the same.\nin languages where objects are hash tables, the c++ dereference becomes a hash table lookup, which is slower"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#tradeoffs-1",
    "href": "lectures/13_dynamic_compilers.html#tradeoffs-1",
    "title": "Dynamic Compilers",
    "section": "tradeoffs",
    "text": "tradeoffs\nIn a dynamically typed language like python we can add or remove methods easily\nbut method calls are expensive\nwe want to make these calls cheaper"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches-at-te-call-site",
    "href": "lectures/13_dynamic_compilers.html#inline-caches-at-te-call-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at te call site",
    "text": "inline caches at te call site\nthe first time we call a method, we know the type (because we are generating code at runtime)\n\n\ndef func(a,b,c):\n  for i in range(10):\n     foo(a,b,c)\n\ndef func(a,b,c):\n  for i in range(1):\n    if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in the hash\n      call other(a,b,c\n      )"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#inline-caches-at-the-function-site",
    "href": "lectures/13_dynamic_compilers.html#inline-caches-at-the-function-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at the function site",
    "text": "inline caches at the function site\n\n\ndef func(a,b,c):\n  for i in range(10):\n     _foo(a,b,c\n\ndef _foo(a,b,c)\n  if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in a\n      call other(a,b,c)\n\n\nis it better to do this at the call site or at the function site?"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#polymorphic-calls",
    "href": "lectures/13_dynamic_compilers.html#polymorphic-calls",
    "title": "Dynamic Compilers",
    "section": "polymorphic calls",
    "text": "polymorphic calls\nif the type changes at runtime (the call to other is taken) does the optimization help?\ncould invalidate the table and rebuild it with another case"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#what-are-the-costs",
    "href": "lectures/13_dynamic_compilers.html#what-are-the-costs",
    "title": "Dynamic Compilers",
    "section": "what are the costs",
    "text": "what are the costs\nfor example v8 compiler\nmonomorphic inline hit - 10 instructions\npolymorphic hit - 35 instructions for 10 types, 60 instructions for 20 types\ncache miss 1000-4000 instructions"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#value-specialization",
    "href": "lectures/13_dynamic_compilers.html#value-specialization",
    "title": "Dynamic Compilers",
    "section": "value specialization",
    "text": "value specialization\nOddly many functions are called with the same arguments"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#an-example",
    "href": "lectures/13_dynamic_compilers.html#an-example",
    "title": "Dynamic Compilers",
    "section": "an example",
    "text": "an example\ngiven a vector v of size n, and a parameter q find the element of v that is closest to q\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n        var i = 0;\n        var d = 0ffffffff;\n        while (i &lt; n) {\n           var nd = abs(v[i] - q);\n           if (nd &lt;= d) d = nd; \n           i++;\n        }    \n        return d;  \n      } \n}"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#the-cfg",
    "href": "lectures/13_dynamic_compilers.html#the-cfg",
    "title": "Dynamic Compilers",
    "section": "the cfg",
    "text": "the cfg\nwe want to recompile this for specific v,q, and n, where we restart at the while test\n\n\n\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n      var i = 0;\n      var d = 0ffffffff;\n      while (i &lt; n) {\n         var nd = abs(v[i] - q);\n         if (nd &lt;= d) d = nd; \n         i++;\n        }    \n        return d;  \n      } \n}\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#two-entries",
    "href": "lectures/13_dynamic_compilers.html#two-entries",
    "title": "Dynamic Compilers",
    "section": "two entries",
    "text": "two entries\nFirst entry is the regular starting point, second is the entry if we are currently running the loop in the interpreter\nSince we are compiling the function while in the loop we can ask the interpreter for values\n\nv == load[0]\nq = 42\nn = 100\ni = 40\nd = 0fffffff\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = param[0]\n              q = param[1]\n              n = param[2]\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = param[0]\n                  q = param[1]\n                  n = param[2]\n                  i3 = stack[0]\n                  d4 = stack[1]\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#dead-code-elimination",
    "href": "lectures/13_dynamic_compilers.html#dead-code-elimination",
    "title": "Dynamic Compilers",
    "section": "dead code elimination",
    "text": "dead code elimination\nAfter this the all calls to the function assume these arguments so no need to keep the regular entry\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#array-in-bounds-check",
    "href": "lectures/13_dynamic_compilers.html#array-in-bounds-check",
    "title": "Dynamic Compilers",
    "section": "array in bounds check",
    "text": "array in bounds check\nwe can pattern match loops with bounds checks if we know the limit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     \"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i0, i2, i3)\n    d1 = phi(d0, d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     \"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#loop-inversion",
    "href": "lectures/13_dynamic_compilers.html#loop-inversion",
    "title": "Dynamic Compilers",
    "section": "loop inversion",
    "text": "loop inversion\na general while loop\nwhile(cond){\n  ...\n}\ncan be changed into\nif (cond){\n  do {\n    ...\n  } while(cond)\n}\nfor this loop the first time around i = 40, n = 100 so the first condition is true"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#after-loop-inversion",
    "href": "lectures/13_dynamic_compilers.html#after-loop-inversion",
    "title": "Dynamic Compilers",
    "section": "after loop inversion",
    "text": "after loop inversion\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#results",
    "href": "lectures/13_dynamic_compilers.html#results",
    "title": "Dynamic Compilers",
    "section": "results",
    "text": "results\nspecialized code is shorter and compiles faster\nsince we know that the loop goes from 42 to 100, we could unroll the loop"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#trace-compilation",
    "href": "lectures/13_dynamic_compilers.html#trace-compilation",
    "title": "Dynamic Compilers",
    "section": "trace compilation",
    "text": "trace compilation\ntracing jit: extract a hot path (not a function)\nHot paths are compiled as a single basic block, but the path might go through a call\ngamble: next execution starting at this point, go the same way, no branches leave the path\ngenerate machine code for hot paths interpret the rest of the program\nunlike specialization, tracing assumes the same path but not the same values"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#an-example-x-42",
    "href": "lectures/13_dynamic_compilers.html#an-example-x-42",
    "title": "Dynamic Compilers",
    "section": "an example (x = 42)",
    "text": "an example (x = 42)\n\n\nfunction main(x){\n   y = x +1 \n   if x &lt;100 {\n      z = f(y)\n   } else {\n      z = g(y)\n   }\n   return z\n}\n\nfunction f(a){\n   return a -1 \n}\n\n\n\ny = x +1\nguard(x &lt; 100)\na = y\nz = a - 1\nreturn z\n\n\n\n\nguards at divergence, guards never return\noptimize assuming guards are true, ok to be slow if guard is false"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#move-guards-up",
    "href": "lectures/13_dynamic_compilers.html#move-guards-up",
    "title": "Dynamic Compilers",
    "section": "move guards up",
    "text": "move guards up\nwhy is this a good idea?\n. . .\n\nfail fast\nlonger region to optimize"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#use-local-value-numbering",
    "href": "lectures/13_dynamic_compilers.html#use-local-value-numbering",
    "title": "Dynamic Compilers",
    "section": "use local value numbering",
    "text": "use local value numbering\n\n\n\nguard(x &lt; 100)\ny = x + 1\na = y\nz = a - 1\nreturn z\n\n\n\nguard(x &lt; 100)\nreturn x"
  },
  {
    "objectID": "lectures/13_dynamic_compilers.html#how-do-this-in-bril",
    "href": "lectures/13_dynamic_compilers.html#how-do-this-in-bril",
    "title": "Dynamic Compilers",
    "section": "how do this in Bril?",
    "text": "how do this in Bril?\n3 new operations (sort of like out-of-order instructions)\n\nspeculate\ncommit\nguard\n\nspeculative execution extension\nyou can nest speculate\nit does not role back stores\nwe can approximate trace compilation by running the program twice\nHow to modify the reference interpreter (warning typescript!)\nbrili\nthere are two functions to consider\n\nevalFunc interprets a function by calling evalInstr on each instruction\nevalInstr interprets one instruction, large case statement for each instruction\n\nyou will need to print instructions as they execute\n\nfigure out when to start and when to stop\nhow to print instructions (modify evalInstr by printing instructions) console.log(instr)\n\nyou have to optimize the trace and put it back"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#jit-just-in-time-compilers-vs-aotahead-of-time-compilers",
    "title": "Dynamic Compilers",
    "section": "jit (just in time) compilers vs aot(ahead of time) compilers",
    "text": "jit (just in time) compilers vs aot(ahead of time) compilers\na jit compiler translates code into isa while the program executes\nsome options\n\ncompile a function the first time it is called\ncompile a function after it has been called a lot (needs an interpreter) We call these hot functions\nbuild a trace of instructions executed and compile the hot traces (a trace has no branches)\nA variation I used ran the program to completion using a tracing interpreter, recompile off line, future execution is a mix of interpreter and compiled code"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#can-jit-compiled-code-run-faster-then-aot-code",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#can-jit-compiled-code-run-faster-then-aot-code",
    "title": "Dynamic Compilers",
    "section": "Can jit compiled code run faster then aot code?",
    "text": "Can jit compiled code run faster then aot code?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#comparison",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#comparison",
    "title": "Dynamic Compilers",
    "section": "Comparison",
    "text": "Comparison\n\n\n\naot\njit\n\n\n\n\ncannot inline libraries\ncan inline (even class methods)\n\n\nno runtime code gen\ncan use run time code gen\n\n\nno speculative opts\ncan use spec opts\n\n\nless information\nmore information\n\n\noverall performance lower\noverall performance often higher\n\n\nfull speed from the start\nrequires warmup\n\n\nno compile cost at run time\noverhead to run compiler"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs",
    "title": "Dynamic Compilers",
    "section": "Tradeoffs",
    "text": "Tradeoffs\n\nThe time to compile is part of the total execution time\nmight run less optimizations to speed up execution time\nmight look at run time info\nsame code might be compiled many times\n\nWt would the same code be compiled more than once?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tiered-compilers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tiered-compilers",
    "title": "Dynamic Compilers",
    "section": "tiered compilers",
    "text": "tiered compilers\nSince compilation is costly, do not compile functions that are only called once and do not contain a long running loop\nwe have a series of compilers, each with more aggressive optimization and each allowed to take longer\n\nthe lowest tier is the interpreter\nthe next is the base line compiler"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#magic-numbers",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#magic-numbers",
    "title": "Dynamic Compilers",
    "section": "magic numbers",
    "text": "magic numbers\nassociate a counter with branches and functions if the counter reaches some magic number use one of the compilers\nif the counter for a backward branch, you recompile, but the code is executing in the middle of a loop, so how do you insert the newly compiled code?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#questions-when-building-a-jit",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#questions-when-building-a-jit",
    "title": "Dynamic Compilers",
    "section": "questions when building a JIT",
    "text": "questions when building a JIT\n\nwhat strategy do you use to invoke the jit\ndo you have to execute for a while before calling the jit\nhow much info do you need\nwhat is the price of wrong info\nare there easy and hard programs\ndo the easy programs match up with users common programs"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#speculation",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#speculation",
    "title": "Dynamic Compilers",
    "section": "Speculation",
    "text": "Speculation\n\nassume some property is true, compile using that info this is always a gamble, so you need to recover if the assumption was wrong\nassume a variable is an int, and does not overflow\nassume properties of an object is fixed\nassume the target of call is always the same\nassume past behavior predicts future behavior"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#flow",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#flow",
    "title": "Dynamic Compilers",
    "section": "flow",
    "text": "flow\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\ninterpreter -- hot? --&gt; profiling \nprofiling -- stats --&gt; optimizing_compiler\noptimizing_compiler --&gt; compiled_code\ncompiled_code -- deoptimze --&gt; interpreter\ninterpreter -- already_compiled --&gt; compiled_code"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#boxed-values",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#boxed-values",
    "title": "Dynamic Compilers",
    "section": "boxed values",
    "text": "boxed values\nMany languages do not use strong static typeing\nfor example in python\nx = x + 1\nx could be an int/float/object\nthe value of x needs to carry a type. Represent x as a pair (type, pointer or bits) The pair is called a boxed value\nthen to generate code for the plus we have to figure out what kind of add, based on the type"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches",
    "title": "Dynamic Compilers",
    "section": "inline caches",
    "text": "inline caches\nin languages like python, calls to a method are more expensive then calls to a method in c++ why?\n\nPython objects are implemented as hash tables. While C++ uses virtual tables\nhow does that effect the cost?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#first-c-virtual-tables",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#first-c-virtual-tables",
    "title": "Dynamic Compilers",
    "section": "first C++ virtual tables",
    "text": "first C++ virtual tables\nin C++ a method call takes two dereferences\n\nfirst find the v-table\nsecond used a fixed offset from the table start to find the address"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-do-we-need-to-keep-the-offset-fixed",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-do-we-need-to-keep-the-offset-fixed",
    "title": "Dynamic Compilers",
    "section": "What do we need to keep the offset fixed?",
    "text": "What do we need to keep the offset fixed?\nif derived inherits from base, and both have a function f. the offset to f has to be the same.\nin languages where objects are hash tables, the c++ dereference becomes a hash table lookup, which is slower"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs-1",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#tradeoffs-1",
    "title": "Dynamic Compilers",
    "section": "tradeoffs",
    "text": "tradeoffs\nIn a dynamically typed language like python we can add or remove methods easily\nbut method calls are expensive\nwe want to make these calls cheaper"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-te-call-site",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-te-call-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at te call site",
    "text": "inline caches at te call site\nthe first time we call a method, we know the type (because we are generating code at runtime)\n\n\ndef func(a,b,c):\n  for i in range(10):\n     foo(a,b,c)\n\ndef func(a,b,c):\n  for i in range(1):\n    if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in the hash\n      call other(a,b,c\n      )"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-the-function-site",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#inline-caches-at-the-function-site",
    "title": "Dynamic Compilers",
    "section": "inline caches at the function site",
    "text": "inline caches at the function site\n\n\ndef func(a,b,c):\n  for i in range(10):\n     _foo(a,b,c\n\ndef _foo(a,b,c)\n  if isinstance(a, type1)\n      body of foo  \n    else:\n      other = lookup 'foo' in a\n      call other(a,b,c)\n\nis it better to do this at the call site or at the function site?"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#polymorphic-calls",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#polymorphic-calls",
    "title": "Dynamic Compilers",
    "section": "polymorphic calls",
    "text": "polymorphic calls\nif the type changes at runtime (the call to other is taken) does the optimization help?\ncould invalidate the table and rebuild it with another case"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-are-the-costs",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#what-are-the-costs",
    "title": "Dynamic Compilers",
    "section": "what are the costs",
    "text": "what are the costs\nfor example v8 compiler\nmonomorphic inline hit - 10 instructions\npolymorphic hit - 35 instructions for 10 types, 60 instructions for 20 types\ncache miss 1000-4000 instructions"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#value-specialization",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#value-specialization",
    "title": "Dynamic Compilers",
    "section": "value specialization",
    "text": "value specialization\nOddly many functions are called with the same arguments"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example",
    "title": "Dynamic Compilers",
    "section": "an example",
    "text": "an example\ngiven a vector v of size n, and a parameter q find the element of v that is closest to q\n function closest(v, q, n) {\n    if (n == 0) {\n          throw \"Error\";\n    } else {\n        var i = 0;\n        var d = 0ffffffff;\n        while (i &lt; n) {\n           var nd = abs(v[i] - q);\n           if (nd &lt;= d) d = nd; \n           i++;\n        }    \n        return d;  \n      } \n}"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#the-cfg",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#the-cfg",
    "title": "Dynamic Compilers",
    "section": "the cfg",
    "text": "the cfg\nwe want to recompile this for specific v,q, and n, where we restart at the while test"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#two-entries",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#two-entries",
    "title": "Dynamic Compilers",
    "section": "two entries",
    "text": "two entries\nFirst entry is the regular starting point, second is the entry if we are currently running the loop in the interpreter\nSince we are compiling the function while in the loop we can ask the interpreter for values\n\nv == load[0]\nq = 42\nn = 100\ni = 40\nd = 0fffffff"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#dead-code-elimination",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#dead-code-elimination",
    "title": "Dynamic Compilers",
    "section": "dead code elimination",
    "text": "dead code elimination\nAfter this the all calls to the function assume these arguments so no need to keep the regular entry\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nnormal_entry[\"function entry\n              v = load[0]\n              q = q = 42 \n              n = 100\n              if (n ==0) goto l1\"]\n\nl1[\"l1: throw error\"]\nl2[\" l2: i0 = 0\n     d = 0fffffff\"]\nnormal_entry --&gt; l1\nnormal_entry--&gt; l2\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nl2--&gt; l3\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(dd3, d4)\n    if (i1 &lt; n) go to l5\"  ]\nentry_on_stack_rep[\"start replace\n                   v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl5[\"l5: t0 = 4* i\n     t1 = v[t0]\n     notinbounds(t1, n) go to l8\"]\n\nl3 --&gt; l5 \nl3--&gt; l4\nl4[\"l4: return d1\"]\nl5--&gt; l7\nl7[\" l7: nd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   goto l3\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl8[\"l8: throw boundsError\"]\nl5 --&gt; l8\nl9--&gt; l3"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#array-in-bounds-check",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#array-in-bounds-check",
    "title": "Dynamic Compilers",
    "section": "array in bounds check",
    "text": "array in bounds check\nwe can pattern match loops with bounds checks if we know the limit"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#loop-inversion",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#loop-inversion",
    "title": "Dynamic Compilers",
    "section": "loop inversion",
    "text": "loop inversion\na general while loop\nwhile(cond){\n  ...\n}\ncan be changed into\nif (cond){\n  do {\n    ...\n  } while(cond)\n}\nfor this loop the first time around i = 40, n = 100 so the first condition is true"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#after-loop-inversion",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#after-loop-inversion",
    "title": "Dynamic Compilers",
    "section": "after loop inversion",
    "text": "after loop inversion\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nl3[\"l3: i1 = phi(i2, i3)\n    d1 = phi(d3, d4)\" ]\nentry_on_stack_rep[\"v = load [0]\n                  q = 42\n                  n = 100\n                  i3 = 40\n                  d4 = offfffff\"]\nentry_on_stack_rep --&gt; l3\nl3 --&gt; l7\n\n\nl4[\"l4: return d1\"]\nl7[\" l7: l5: t0 = 4* i\nt1 = v[t0]\nnd = abs(t1, q)\n   if (nd &gt; d1) go to l9\"]\n\nl9[\"l9: d3 = phi(d1, d2)\n   i2 = i1 + 1\n   if (i2 &gt; n) goto l4\"]\nl7--&gt; l9\nl7--&gt; l6[\"l6: d2 = nd\"]\nl6--&gt; l9\nl9--&gt; l3\nl9--&gt; l4"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#results",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#results",
    "title": "Dynamic Compilers",
    "section": "results",
    "text": "results\nspecialized code is shorter and compiles faster\nsince we know that the loop goes from 42 to 100, we could unroll the loop"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#trace-compilation",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#trace-compilation",
    "title": "Dynamic Compilers",
    "section": "trace compilation",
    "text": "trace compilation\ntracing jit: extract a hot path (not a function)\nHot paths are compiled as a single basic block, but the path might go through a call\ngamble: next execution starting at this point, go the same way, no branches leave the path\ngenerate machine code for hot paths interpret the rest of the program\nunlike specialization, tracing assumes the same path but not the same values"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example-x-42",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#an-example-x-42",
    "title": "Dynamic Compilers",
    "section": "an example (x = 42)",
    "text": "an example (x = 42)\n\n\nfunction main(x){\n   y = x +1 \n   if x &lt;100 {\n      z = f(y)\n   } else {\n      z = g(y)\n   }\n   return z\n}\n\nfunction f(a){\n   return a -1 \n}\n\n\n\ny = x +1\nguard(x &lt; 100)\na = y\nz = a - 1\nreturn z\n\n\n\nguards at divergence, guards never return\noptimize assuming guards are true, ok to be slow if guard is false"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#move-guards-up",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#move-guards-up",
    "title": "Dynamic Compilers",
    "section": "move guards up",
    "text": "move guards up\nwhy is this a good idea?\n\n\nfail fast\nlonger region to optimize"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#use-local-value-numbering",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#use-local-value-numbering",
    "title": "Dynamic Compilers",
    "section": "use local value numbering",
    "text": "use local value numbering\n\n\n\nguard(x &lt; 100)\ny = x + 1\na = y\nz = a - 1\nreturn z\n\n\n\nguard(x &lt; 100)\nreturn x"
  },
  {
    "objectID": "lectures/revealjs_13_dynamic_compilers.qmd.html#how-do-this-in-bril",
    "href": "lectures/revealjs_13_dynamic_compilers.qmd.html#how-do-this-in-bril",
    "title": "Dynamic Compilers",
    "section": "how do this in Bril?",
    "text": "how do this in Bril?\n3 new operations (sort of like out-of-order instructions)\n\nspeculate\ncommit\nguard\n\nspeculative execution extension\nyou can nest speculate\nit does not role back stores\nwe can approximate trace compilation by running the program twice\nHow to modify the reference interpreter (warning typescript!)\nbrili\nthere are two functions to consider\n\nevalFunc interprets a function by calling evalInstr on each instruction\nevalInstr interprets one instruction, large case statement for each instruction\n\nyou will need to print instructions as they execute\n\nfigure out when to start and when to stop\nhow to print instructions (modify evalInstr by printing instructions) console.log(instr)\n\nyou have to optimize the trace and put it back"
  },
  {
    "objectID": "lectures/05_global.html",
    "href": "lectures/05_global.html",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs."
  },
  {
    "objectID": "lectures/05_global.html#graph-properties",
    "href": "lectures/05_global.html#graph-properties",
    "title": "5 Global Analysis",
    "section": "",
    "text": "We are going to define assorted graph properties, that can be calculated on cfgs."
  },
  {
    "objectID": "lectures/05_global.html#dominators",
    "href": "lectures/05_global.html#dominators",
    "title": "5 Global Analysis",
    "section": "dominators",
    "text": "dominators\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a"
  },
  {
    "objectID": "lectures/05_global.html#dominator-trees",
    "href": "lectures/05_global.html#dominator-trees",
    "title": "5 Global Analysis",
    "section": "dominator trees",
    "text": "dominator trees\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b"
  },
  {
    "objectID": "lectures/05_global.html#an-example",
    "href": "lectures/05_global.html#an-example",
    "title": "5 Global Analysis",
    "section": "an example",
    "text": "an example\n\n\nA control flow graph\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\n\nThe dominator tree\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;"
  },
  {
    "objectID": "lectures/05_global.html#simple-implementation-dominators",
    "href": "lectures/05_global.html#simple-implementation-dominators",
    "title": "5 Global Analysis",
    "section": "simple implementation dominators",
    "text": "simple implementation dominators\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]\n\nTo find the dominators of a node, first put the node itself in the dominators set. Then, take all the common (i.e. intersection) dominators of its predecessors and put them in the set.\nWhat order do we want to process the nodes?"
  },
  {
    "objectID": "lectures/05_global.html#pseudo-code",
    "href": "lectures/05_global.html#pseudo-code",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nassume nodes start at 0,\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/05_global.html#how-do-we-implement-this",
    "href": "lectures/05_global.html#how-do-we-implement-this",
    "title": "5 Global Analysis",
    "section": "How do we implement this",
    "text": "How do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order"
  },
  {
    "objectID": "lectures/05_global.html#a-faster-way",
    "href": "lectures/05_global.html#a-faster-way",
    "title": "5 Global Analysis",
    "section": "a faster way",
    "text": "a faster way\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, (the dominator)"
  },
  {
    "objectID": "lectures/05_global.html#a-more-complex-example",
    "href": "lectures/05_global.html#a-more-complex-example",
    "title": "5 Global Analysis",
    "section": "a more complex example",
    "text": "a more complex example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n\nneed n4 and n8\n\nboth are dominated by n0"
  },
  {
    "objectID": "lectures/05_global.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "href": "lectures/05_global.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "title": "5 Global Analysis",
    "section": "subproblem: find lowest common ancestor in dt of two nodes a and b",
    "text": "subproblem: find lowest common ancestor in dt of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower keep the nodes in post order, nodes at the top of the cfg have higher numbers"
  },
  {
    "objectID": "lectures/05_global.html#part1",
    "href": "lectures/05_global.html#part1",
    "title": "5 Global Analysis",
    "section": "part1",
    "text": "part1\nintersect(b1, b2, idoms,postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;"
  },
  {
    "objectID": "lectures/05_global.html#pseudo-code-1",
    "href": "lectures/05_global.html#pseudo-code-1",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse i in postorder) {\n      bb = cffg block i \n      new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n\n      for pred in preds (bb)) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/05_global.html#dominator-frontiers",
    "href": "lectures/05_global.html#dominator-frontiers",
    "title": "5 Global Analysis",
    "section": "dominator frontiers",
    "text": "dominator frontiers\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5 dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6."
  },
  {
    "objectID": "lectures/05_global.html#natural-loops",
    "href": "lectures/05_global.html#natural-loops",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\n\ngraph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header"
  },
  {
    "objectID": "lectures/05_global.html#cycle-but-not-header",
    "href": "lectures/05_global.html#cycle-but-not-header",
    "title": "5 Global Analysis",
    "section": "cycle but not header",
    "text": "cycle but not header\nHow about an example that has a cycle and no header\n\ngraph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points."
  },
  {
    "objectID": "lectures/05_global.html#natural-loops-1",
    "href": "lectures/05_global.html#natural-loops-1",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\nA back-edge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a back-edge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B"
  },
  {
    "objectID": "lectures/05_global.html#example",
    "href": "lectures/05_global.html#example",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\n\n\nBackedges B -&gt; H2,\nB-&gt; H1\n\nfor B-&gt; H2, loop is H2,\nfor B-&gt; H1, loop is H1, A, H2, B"
  },
  {
    "objectID": "lectures/05_global.html#reducible-control-flow",
    "href": "lectures/05_global.html#reducible-control-flow",
    "title": "5 Global Analysis",
    "section": "reducible control flow",
    "text": "reducible control flow\nin a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A."
  },
  {
    "objectID": "lectures/05_global.html#what-is-the-surface-version",
    "href": "lectures/05_global.html#what-is-the-surface-version",
    "title": "5 Global Analysis",
    "section": "what is the surface version",
    "text": "what is the surface version\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations."
  },
  {
    "objectID": "lectures/05_global.html#t1-and-t2-transforms",
    "href": "lectures/05_global.html#t1-and-t2-transforms",
    "title": "5 Global Analysis",
    "section": "t1 and t2 transforms",
    "text": "t1 and t2 transforms\nLet G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1: on node n is removal of this self-loop.\nLet n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node.\ntransformation T2: on node pair (n1,n2) is merging nodes n1 and n2 into one node,"
  },
  {
    "objectID": "lectures/05_global.html#t1-t2",
    "href": "lectures/05_global.html#t1-t2",
    "title": "5 Global Analysis",
    "section": "t1 / t2",
    "text": "t1 / t2\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]"
  },
  {
    "objectID": "lectures/05_global.html#example-1",
    "href": "lectures/05_global.html#example-1",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}"
  },
  {
    "objectID": "lectures/05_global.html#simplified-control-flow",
    "href": "lectures/05_global.html#simplified-control-flow",
    "title": "5 Global Analysis",
    "section": "simplified control flow",
    "text": "simplified control flow\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\nnot reducible"
  },
  {
    "objectID": "lectures/05_global.html#other-optimizations-interactions",
    "href": "lectures/05_global.html#other-optimizations-interactions",
    "title": "5 Global Analysis",
    "section": "other optimizations interactions",
    "text": "other optimizations interactions\nloop: if (cond) goto past_loop\n    s1\n    call bar()\n    goto loop\npastloop:\n\nfunction bar()\n    b1 \n    if () return\n    b2"
  },
  {
    "objectID": "lectures/05_global.html#inline-the-function-combine-jmps-to-jmps",
    "href": "lectures/05_global.html#inline-the-function-combine-jmps-to-jmps",
    "title": "5 Global Analysis",
    "section": "inline the function, combine jmps to jmps",
    "text": "inline the function, combine jmps to jmps\n\n\nloop: if (cond) goto past_loop\n    s1\n    b1\n    if () go to next\n    b2\n    next:\ngoto loop\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n\nNow we have two back edges so two loops"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#graph-properties",
    "href": "lectures/revealjs_05_global.qmd.html#graph-properties",
    "title": "5 Global Analysis",
    "section": "Graph Properties",
    "text": "Graph Properties\nWe are going to define assorted graph properties, that can be calculated on cfgs."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominators",
    "href": "lectures/revealjs_05_global.qmd.html#dominators",
    "title": "5 Global Analysis",
    "section": "dominators",
    "text": "dominators\nWe first define a binary relation on cfg nodes, called dominance. a node d dominates a node i (d dom i) if every possible execution path in the cfg that goes from the entry to i goes through d. \n\nDom is reflexive, so a dom a for all nodes a.\nDom is transitive, a dom b, b dom c ==&gt; a dom c\nDom is anti-symmetric if a dom b, and b dom a then b = a"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominator-trees",
    "href": "lectures/revealjs_05_global.qmd.html#dominator-trees",
    "title": "5 Global Analysis",
    "section": "dominator trees",
    "text": "dominator trees\nWe next define immediate dominators a idom b, a != b and there is no c != a and c != b where a dom c and c dom b.\n\nidom is unique\nidom forms a tree called the dominator tree, root is the entry of the cfg\n\nA strict dominator a sdom b if a dom b and a != b"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#an-example",
    "href": "lectures/revealjs_05_global.qmd.html#an-example",
    "title": "5 Global Analysis",
    "section": "an example",
    "text": "an example\n\n\nA control flow graph\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;\nn1 --&gt; n3;\nn2 --&gt; n4;\nn3 --&gt; n4;\n\n\n\n\n\n\n\nThe dominator tree\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n1;\nn1 --&gt; n2;n1 --&gt; n3\nn1 --&gt; n4;"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#simple-implementation-dominators",
    "href": "lectures/revealjs_05_global.qmd.html#simple-implementation-dominators",
    "title": "5 Global Analysis",
    "section": "simple implementation dominators",
    "text": "simple implementation dominators\n\\[\n\\begin{gathered}\n\\operatorname{Dom}\\left(n_o\\right)=\\left\\{n_o\\right\\} \\\\\n\\operatorname{Dom}(n)=\\{n\\} \\cup\\left(\\bigcap_{p \\in \\operatorname{preds}(n)} \\operatorname{Dom}(p)\\right)\n\\end{gathered}\n\\]"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#pseudo-code",
    "href": "lectures/revealjs_05_global.qmd.html#pseudo-code",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nassume nodes start at 0,\ncompute_dominators(CFG cfg) {\n  cfg[0].dominators = {0}\n  for (bb in cfg except 0) {\n    b.dominators = {all nodes in cfg}\n  }\n\n  do {\n    change = false;\n    for (bb in cfg except 0) {\n      temp = {all nodes in cfg}\n      for (pred in bb.predecessors) {\n        temp = intersect(temp, pred.dominators)\n      }\n      temp = union(temp, {bb})\n      if (temp != bb.dominators) {\n        change = true\n        bb.dominators = temp\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#how-do-we-implement-this",
    "href": "lectures/revealjs_05_global.qmd.html#how-do-we-implement-this",
    "title": "5 Global Analysis",
    "section": "How do we implement this",
    "text": "How do we implement this\nnumber the vertices starting at 0, vertices are 0,1,2, number_of_vertices -1 so we could use a bit-vector for the set, and we should process vertices in reverse post order"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#a-faster-way",
    "href": "lectures/revealjs_05_global.qmd.html#a-faster-way",
    "title": "5 Global Analysis",
    "section": "a faster way",
    "text": "a faster way\nCooper, Harvey, Kennedy Algorithm\nif we have the dominator tree, finding immediate dominators is easy, its the parent of the node Finding dominators is also easy, its all the parents on the path from the entry to the node\nsuppose we have a node in the cfg with two parents, like n4, if we takes paths backward in the dominator tree the first common ancestor is n1, (the dominator)"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#a-more-complex-example",
    "href": "lectures/revealjs_05_global.qmd.html#a-more-complex-example",
    "title": "5 Global Analysis",
    "section": "a more complex example",
    "text": "a more complex example\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0 --&gt; n5;\nn0 --&gt; n1;\nn5 --&gt; n7;\nn5 --&gt; n6;\nn1 --&gt; n2 ;\nn1 --&gt; n3;\nn7 --&gt; n8;\nn6 --&gt; n4;\nn2 --&gt; n4;\nn4 --&gt; n8 ;\nn3 --&gt; n8;\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD;\nn0--&gt; n5\nn0 --&gt; n1\nn5--&gt; n7\nn5--&gt; n6\nn1--&gt; n2\nn1 --&gt; n3\n\n\n\n\n\n\nneed n4 and n8\n\nboth are dominated by n0"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "href": "lectures/revealjs_05_global.qmd.html#subproblem-find-lowest-common-ancestor-in-dt-of-two-nodes-a-and-b",
    "title": "5 Global Analysis",
    "section": "subproblem: find lowest common ancestor in dt of two nodes a and b",
    "text": "subproblem: find lowest common ancestor in dt of two nodes a and b\nfor each node in the dom tree we have the depth, how far from the root, so if a and b have the same parent, that is the dominator, otherwise move the node with the higher depth up one\na fast way to determine which node is lower keep the nodes in post order, nodes at the top of the cfg have higher numbers"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#part1",
    "href": "lectures/revealjs_05_global.qmd.html#part1",
    "title": "5 Global Analysis",
    "section": "part1",
    "text": "part1\nintersect(b1, b2, idoms,postorder_map) {\n  while (b1 != b2) {\n    if (postorder_map[b1] &lt; postorder_map[b2]) {\n      b1 = idoms[b1];\n    } else {\n      b2 = idoms[b2];\n    }\n  }\n  return b1;"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#pseudo-code-1",
    "href": "lectures/revealjs_05_global.qmd.html#pseudo-code-1",
    "title": "5 Global Analysis",
    "section": "pseudo code",
    "text": "pseudo code\nvoid compute_dominators(CFG cfg) {\n  // Some initialization steps and e.g. get postorder.\n\n  // Map its basic block to its postorder traversal.\n  foreach (p ; postorder) {\n    postorder_map[p] = counter;\n    ++counter;\n  }\n\n  bool change;\n  do {\n    change = false;\n    foreach_reverse i in postorder) {\n      bb = cffg block i \n      new_idom = bb.preds[0];  // Arbitrarily choose the first predecessor\n\n      for pred in preds (bb)) {\n        if (cfg.idoms[pred] != CFG.UNDEFINED_IDOM) {\n          new_idom = intersect(new_idom, pred, cfg.idoms, postorder_map);\n        }\n      }\n      if (cfg.idoms[i] != new_idom) {\n        cfg.idoms[i] = new_idom;\n        change = true;\n      }\n    }\n  } while (change);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#dominator-frontiers",
    "href": "lectures/revealjs_05_global.qmd.html#dominator-frontiers",
    "title": "5 Global Analysis",
    "section": "dominator frontiers",
    "text": "dominator frontiers\nA node A has a dominance frontier which are set of nodes b where A does not dominate b but A dominates a pred of b. Lets see n5 dominance frontier\nFinally we have a post dominates b if all paths from b to the exit go through a. for instance n4 post dominates n6."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#natural-loops",
    "href": "lectures/revealjs_05_global.qmd.html#natural-loops",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\n\n\n\n\n\n  graph TD;\n  entry --&gt; loop\n  loop --&gt; if \n  if --&gt; then\n  if --&gt; else\n  then --&gt; endif\n  else --&gt; endif\n  endif --&gt; loop\n  loop --&gt; exit\n\n\n\n\n\n\n\nhas to have a cycle in cfg (strongly connected)\nsingle entry point (called the header ) header"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#cycle-but-not-header",
    "href": "lectures/revealjs_05_global.qmd.html#cycle-but-not-header",
    "title": "5 Global Analysis",
    "section": "cycle but not header",
    "text": "cycle but not header\nHow about an example that has a cycle and no header\n\n\n\n\n\n    graph TD;\n    entry --&gt; if;\n    if --&gt; loop1\n    if --&gt; loop2\n    loop2 --&gt; loop1\nloop1 --&gt; loop2\n\n\n\n\n\n\nThis loop has two entry points."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#natural-loops-1",
    "href": "lectures/revealjs_05_global.qmd.html#natural-loops-1",
    "title": "5 Global Analysis",
    "section": "natural loops",
    "text": "natural loops\nA back-edge is an edge A-&gt;B, where B dominates A\nother edges are forward edges\nNatural loops:\n\nfor a back-edge A-&gt;B, B is the header of the loop\nthe smallest set of vertices L including A and B, such that for all v in L either preds(v) are in L or v == B"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#example",
    "href": "lectures/revealjs_05_global.qmd.html#example",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; H1\n    H1 --&gt; A\n    A --&gt; H2\n    H2 --&gt; B\n    B --&gt; H2\n    B --&gt; H1\n    H1 --&gt; exit\n\n\n\n\n\n\n\n\nBackedges B -&gt; H2,\nB-&gt; H1\n\nfor B-&gt; H2, loop is H2,\nfor B-&gt; H1, loop is H1, A, H2, B"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#reducible-control-flow",
    "href": "lectures/revealjs_05_global.qmd.html#reducible-control-flow",
    "title": "5 Global Analysis",
    "section": "reducible control flow",
    "text": "reducible control flow\nin a reducible cfg every back edge has a natural loop.\nA reducible CFG is one with edges that can be partitioned into two disjoint sets: forward edges, and back edges, such that:\nForward edges form a directed acyclic graph with all nodes reachable from the entry node.\nFor all back edges (A, B), node B dominates node A."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#what-is-the-surface-version",
    "href": "lectures/revealjs_05_global.qmd.html#what-is-the-surface-version",
    "title": "5 Global Analysis",
    "section": "what is the surface version",
    "text": "what is the surface version\nStructured programming languages are often designed such that all CFGs they produce are reducible, and common structured programming statements such as IF, FOR, WHILE, BREAK, and CONTINUE produce reducible graphs. To produce irreducible graphs, statements such as GOTO are needed. Irreducible graphs may also be produced by some compiler optimizations."
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#t1-and-t2-transforms",
    "href": "lectures/revealjs_05_global.qmd.html#t1-and-t2-transforms",
    "title": "5 Global Analysis",
    "section": "t1 and t2 transforms",
    "text": "t1 and t2 transforms\nLet G be a CFG. Suppose n is a node in G with a self-loop, that is, an edge from n to itself.\nTransformation T1: on node n is removal of this self-loop.\nLet n1 and n2 be nodes in G such that n2 has the unique direct ancestor n1, and n2 is not the initial node.\ntransformation T2: on node pair (n1,n2) is merging nodes n1 and n2 into one node,"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#t1-t2",
    "href": "lectures/revealjs_05_global.qmd.html#t1-t2",
    "title": "5 Global Analysis",
    "section": "t1 / t2",
    "text": "t1 / t2\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\nn --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1\na1[\" \"] --&gt; n1\nn1 --&gt; n2\nn2--&gt; n1\n n2 --&gt; b[\" \"]\nn2 --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n\na1[\" \"] --&gt; n\n n --&gt; b[\" \"]\nn --&gt; b1[\" \"]\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    a0[\" \"] --&gt; n1[\"n1_n2\"]\na1[\" \"] --&gt; n1\n n1 --&gt; b[\" \"]\nn1 --&gt; b1[\" \"]"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#example-1",
    "href": "lectures/revealjs_05_global.qmd.html#example-1",
    "title": "5 Global Analysis",
    "section": "example",
    "text": "example\nint  n = (count + 7) / 8;\nswitch (count % 8) {\ncase 0: do { *to = *from++;\ncase 7:      *to = *from++;\ncase 6:      *to = *from++;\ncase 5:      *to = *from++;\ncase 4:      *to = *from++;\ncase 3:      *to = *from++;\ncase 2:      *to = *from++;\ncase 1:      *to = *from++;\n        } while (--n &gt; 0);\n}"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#simplified-control-flow",
    "href": "lectures/revealjs_05_global.qmd.html#simplified-control-flow",
    "title": "5 Global Analysis",
    "section": "simplified control flow",
    "text": "simplified control flow\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    entry --&gt; switch;\n    switch --&gt; case0-7\n    switch --&gt; case1\n    switch --&gt; case2\n    case0-7 --&gt; case2\n    case2--&gt; case1\n    case1 --&gt; dowhile\n    dowhile --&gt; case0-7\n    dowhile --&gt; exit\n\n\n\n\n\n\nnot reducible"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#other-optimizations-interactions",
    "href": "lectures/revealjs_05_global.qmd.html#other-optimizations-interactions",
    "title": "5 Global Analysis",
    "section": "other optimizations interactions",
    "text": "other optimizations interactions\nloop: if (cond) goto past_loop\n    s1\n    call bar()\n    goto loop\npastloop:\n\nfunction bar()\n    b1 \n    if () return\n    b2"
  },
  {
    "objectID": "lectures/revealjs_05_global.qmd.html#inline-the-function-combine-jmps-to-jmps",
    "href": "lectures/revealjs_05_global.qmd.html#inline-the-function-combine-jmps-to-jmps",
    "title": "5 Global Analysis",
    "section": "inline the function, combine jmps to jmps",
    "text": "inline the function, combine jmps to jmps\n\n\nloop: if (cond) goto past_loop\n    s1\n    b1\n    if () go to next\n    b2\n    next:\ngoto loop\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n    graph TD;\n    loop--&gt; s1\n    loop---&gt; past_loop\n    s1--&gt; b1\n    b1 --&gt;inline_if\n    inline_if --&gt; b2\n    b2 --&gt; next_goto\n    inline_if --&gt; loop\n    next_goto --&gt; loop\n\n\n\n\n\n\nNow we have two back edges so two loops"
  },
  {
    "objectID": "lectures/01a_performance_measurement.html",
    "href": "lectures/01a_performance_measurement.html",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog\n\n\n\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines\n\n\n\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability."
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#example-1",
    "href": "lectures/01a_performance_measurement.html#example-1",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references\n\n\nMeasurement bias is significant\nChanging aspects of an experimental setup can introduce measurement bias. ​ Measurement bias is unpredictable and there are no obvious ways to avoid it. ​ Prior work in computer system evaluation does not adequately consider measurement bias. ​\nThe paper discusses two techniques for dealing with measurement bias: experimental setup randomization and causal analysis. ​\nMeasurement bias occurs for all benchmarks and architectures. ​\nMeasurement bias due to link order can significantly fluctuate conclusions. ​\nMeasurement bias due to UNIX environment size can lead to conflicting conclusions. ​\nTo avoid measurement bias, it is important to use diverse evaluation workloads, randomize the experimental setup, conduct causal analysis, and collect more information from hardware manufacturers. ​ —\n\n\nA sample blog post about this paper blog"
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#another-example",
    "href": "lectures/01a_performance_measurement.html#another-example",
    "title": "Performance and Measurement",
    "section": "",
    "text": "Strangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines"
  },
  {
    "objectID": "lectures/01a_performance_measurement.html#violin-plots",
    "href": "lectures/01a_performance_measurement.html#violin-plots",
    "title": "Performance and Measurement",
    "section": "",
    "text": "data\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n# library & dataset\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('images/chip_dataset.csv')\nprint(df.head())\n\nsns.set_palette(\"pastel\")\n\nsns.violinplot(x=df[\"Vendor\"], y=np.log(df[\"Freq (MHz)\"]), hue=df['Type'])\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots\n\nA violin plot shows density curves. The width is the approximate frequency of data points at that value\nBest for comparing distributions\nconsider ordering the groups\nThe details\n\nthe white dot represents the median\nthe thick gray bar in the center represents the inter-quartile range\nthe thin gray line represents the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range.\nOn each side of the gray line is a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the skinnier sections represent a lower probability."
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#example-1",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#example-1",
    "title": "Performance and Measurement",
    "section": "example 1",
    "text": "example 1\nProducing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\n445 references"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#another-example",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#another-example",
    "title": "Performance and Measurement",
    "section": "another example",
    "text": "another example\nStrangely, Matrix Multiplications on GPUs Run Faster When Given “Predictable” Data!\nSIGPLAN Empirical Evaluation Guidelines"
  },
  {
    "objectID": "lectures/revealjs_01a_performance_measurement.qmd.html#violin-plots",
    "href": "lectures/revealjs_01a_performance_measurement.qmd.html#violin-plots",
    "title": "Performance and Measurement",
    "section": "violin plots",
    "text": "violin plots\ndata\nA dataset with 2,185 CPUs and 2,668 GPUs to help researchers understand the development trend of CPUs and GPUs. Setup by Kaggle\n\n\n   Unnamed: 0                  Product Type Release Date  Process Size (nm)  \\\n0           0      AMD Athlon 64 3500+  CPU   2007-02-20               65.0   \n1           1         AMD Athlon 200GE  CPU   2018-09-06               14.0   \n2           2     Intel Core i5-1145G7  CPU   2020-09-02               10.0   \n3           3    Intel Xeon E5-2603 v2  CPU   2013-09-01               22.0   \n4           4  AMD Phenom II X4 980 BE  CPU   2011-05-03               45.0   \n\n   TDP (W)  Die Size (mm^2)  Transistors (million)  Freq (MHz)  Foundry  \\\n0     45.0             77.0                  122.0      2200.0  Unknown   \n1     35.0            192.0                 4800.0      3200.0  Unknown   \n2     28.0              NaN                    NaN      2600.0    Intel   \n3     80.0            160.0                 1400.0      1800.0    Intel   \n4    125.0            258.0                  758.0      3700.0  Unknown   \n\n  Vendor  FP16 GFLOPS  FP32 GFLOPS  FP64 GFLOPS  \n0    AMD          NaN          NaN          NaN  \n1    AMD          NaN          NaN          NaN  \n2  Intel          NaN          NaN          NaN  \n3  Intel          NaN          NaN          NaN  \n4    AMD          NaN          NaN          NaN  \n\n\n\n\n\n\n\n\n\napply np.log to the Freq (MHz) column. Because of wide range of values\nSet a pastel palette with sns.set_palette(“pastel”). These colors make it easier to see the parts of the violin plot\nHue Parameter: I’m using the hue parameter to differentiate between types of chips. Hue sets a color within the palette\nData Source and Preparation: Include a brief note on where the data comes from (you’ve provided a link, but a sentence or two summarizing the dataset would be helpful) and any preprocessing steps taken before visualization.\nI might want to take date into account in these plots"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html",
    "href": "lectures/14_gpu_compilers.html",
    "title": "GPU Compilers",
    "section": "",
    "text": "Architectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc."
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#challenges-in-learning-about-gpus",
    "href": "lectures/14_gpu_compilers.html#challenges-in-learning-about-gpus",
    "title": "GPU Compilers",
    "section": "",
    "text": "Architectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc."
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware-styles-nvidia-model",
    "href": "lectures/14_gpu_compilers.html#hardware-styles-nvidia-model",
    "title": "GPU Compilers",
    "section": "hardware styles NVIDIA model",
    "text": "hardware styles NVIDIA model\n\ncompute and graphics parts have same programmable parts, compute leaves out non-programmable features\ngraphics customers pay a tax for the compute instructions\nmore transistors for compute instructions\none big die"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware-styles-amd-model",
    "href": "lectures/14_gpu_compilers.html#hardware-styles-amd-model",
    "title": "GPU Compilers",
    "section": "hardware styles AMD model",
    "text": "hardware styles AMD model\n\ncompute has extra instructions (no tax on graphics customers to support compute)\nchiplet model (great engineering!)\nR series is graphics, C series is compute"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#programming-model",
    "href": "lectures/14_gpu_compilers.html#programming-model",
    "title": "GPU Compilers",
    "section": "programming model",
    "text": "programming model\nboth vendors use the CUDA programming model. AMD supports a variation of the CUDA language\nmachines have multiple SIMD processors, each SIMD can be running a different instruction but each lane of a SIMD runs the same instruction\na lane of a SIMD is called a thread\n\nthe programming model is SIMT (single instruction multiple threads)\nUser writes a scalar program, compiler maps that program to a lane of a SIMD, many instances of the program run at once, hardware combines copies of the scalar program into warps, hardware schedules warps into the SIMD engines\nprograms are called kernels"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#threading-model",
    "href": "lectures/14_gpu_compilers.html#threading-model",
    "title": "GPU Compilers",
    "section": "threading model",
    "text": "threading model"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#warps-waveswavefronts",
    "href": "lectures/14_gpu_compilers.html#warps-waveswavefronts",
    "title": "GPU Compilers",
    "section": "warps/ waves/wavefronts",
    "text": "warps/ waves/wavefronts\n\nthreads are grouped together into warps.\nSize is fixed by hardware (usually 32), programmers know this and often make data set sizes a multiple of 32.\nsince all threads in a warp are running the same instruction, there is no need for explicit synchronization\nthere are a few instructions that work across a warp, - which break the model and give the compiler problems"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#thread-blocks-groups-of-warps",
    "href": "lectures/14_gpu_compilers.html#thread-blocks-groups-of-warps",
    "title": "GPU Compilers",
    "section": "thread blocks groups of warps,",
    "text": "thread blocks groups of warps,\n\nthreads within a block can access a fast scratchpad memory (called shared or LDS) - Violates the C memory model.\n\nthreads are identified by a 3d index inside a block\nthread blocks need synchronization operations.\n\nhardware schedules each block into execution units. Max block size is limited by the size of a execution unit."
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#grid-groups-of-blocks",
    "href": "lectures/14_gpu_compilers.html#grid-groups-of-blocks",
    "title": "GPU Compilers",
    "section": "grid groups of blocks,",
    "text": "grid groups of blocks,\n\n3d collection of blocks,\nusually hardware limits mean that all the threads in a grid do not run at the same time\nprogrammers need to make grids big enough to fill the hardware\nsoftware launches a grid and a program\nthreads within a grid but in different blocks do not have sync operations"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#heterogeneous-programming",
    "href": "lectures/14_gpu_compilers.html#heterogeneous-programming",
    "title": "GPU Compilers",
    "section": "Heterogeneous programming",
    "text": "Heterogeneous programming\nthe cpu is called the host\nthe gpu is called the device\ncpu launches grids and kernels to gpu\nComputations launched on the device execute asynchronously with respect to the host, and it is the user’s responsibility to synchronize"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#memory-spaces",
    "href": "lectures/14_gpu_compilers.html#memory-spaces",
    "title": "GPU Compilers",
    "section": "memory spaces",
    "text": "memory spaces\n\ncpu and gpu have different memory spaces (cpu can copy from one to the other). Some amount of combined memory (slower the not combined)\ngpu has shared/lds memory which can be accessed by threads within a block, passing an address to a different block does not work\nmain gpu memory is called global accessible by all threads\ngpu has per thread memory called local or scratch ot private memory - unlike C, passing an address in local memory to another thread does not work. (under some restrictions AMD implements part of the C memory model)\na few special gpu memory types: constant, texture, surface (left over from graphics)\ngpu can treat registers as fast memory"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#hardware",
    "href": "lectures/14_gpu_compilers.html#hardware",
    "title": "GPU Compilers",
    "section": "Hardware",
    "text": "Hardware\nNVIDIA\n\n\n\nnv image level 0\n\n\nEach box here is hardware, an int32/fp32/fp64 can perform one operation, so here we have 32 fp32 units which can do 32 float operations in parallel as well as 16 int32 and 16 fp64 units , there are also 8 units can do loads or stores and a final special function unit that can do transcendental operations like sin/cos\nunder some conditions two instructions (a float and an int) from the same warp can execute at the same time\nI’m not going to talk much about the tensor cores\nall these units execute the same instruction (SIMT) Simple instruction multiple thread (not the same as SIMD but related )"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#one-instruction-does-vector-work",
    "href": "lectures/14_gpu_compilers.html#one-instruction-does-vector-work",
    "title": "GPU Compilers",
    "section": "one instruction does vector work",
    "text": "one instruction does vector work\nadd 32 float32 values (all coming from registers) and store the result in 32 other registers\nNotice no branch prediction, no out of order execution\ngreat at switching a warp holds the instruction, it knows which registers it owns (continuous set, so it just needs a start and length) switching to a different warp, means changing these two numbers and the pc (this is done by the dispatch unt )\nWhen we do a load, we need to wait for the result. CPU might do some kind of out of order execution, a gpu switches to another warp\nfinally we need to pick the warp to switch to, this is done by the warp scheduler (half of the hardware scheduler)"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#streaming-multiprocessors-sm",
    "href": "lectures/14_gpu_compilers.html#streaming-multiprocessors-sm",
    "title": "GPU Compilers",
    "section": "streaming multiprocessors (SM)",
    "text": "streaming multiprocessors (SM)\nnvidia packs 4 execution engines into a SM (streaming multi-processor) ands an L1 instruction cache, a special memory accelerator for tensors and 256kb l1 data cache/ shared memory block"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#pack-sms-together",
    "href": "lectures/14_gpu_compilers.html#pack-sms-together",
    "title": "GPU Compilers",
    "section": "pack sm’s together",
    "text": "pack sm’s together"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#amd",
    "href": "lectures/14_gpu_compilers.html#amd",
    "title": "GPU Compilers",
    "section": "AMD",
    "text": "AMD"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#and",
    "href": "lectures/14_gpu_compilers.html#and",
    "title": "GPU Compilers",
    "section": "and",
    "text": "and\n\nAMD has a similar block with some important differences\n\nAt the bottom of a compute core there are 4 general purpose simd engines each of length 16 and one scalar engine\n\nGiven 5 waves, this compute core can execute 4 vector instructions and one scalar instruction per clock Two instructions from the same wave never execute at the same time\nThe SIMD engines can execute different instructions\nThe simd sizes vary over different chips"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#amd-cdna",
    "href": "lectures/14_gpu_compilers.html#amd-cdna",
    "title": "GPU Compilers",
    "section": "amd CDNA",
    "text": "amd CDNA"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#packing-sms",
    "href": "lectures/14_gpu_compilers.html#packing-sms",
    "title": "GPU Compilers",
    "section": "packing sms",
    "text": "packing sms"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#simd-and-control-flow",
    "href": "lectures/14_gpu_compilers.html#simd-and-control-flow",
    "title": "GPU Compilers",
    "section": "simd and control flow",
    "text": "simd and control flow\nto execute an if then else\n\ncompute the if condition\nturn off the lanes where the condition is false\nexecute the if side\nflip the lanes\nexecute the else side\n\ntime is the sum of the times for then and the else"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#number-of-warps-in-flight",
    "href": "lectures/14_gpu_compilers.html#number-of-warps-in-flight",
    "title": "GPU Compilers",
    "section": "number of warps in flight",
    "text": "number of warps in flight\nsince an entire block has to fit on one compute unit/sm, the resources used in the block limit the number of warps on a sm,\nif a warp needs 100 registers and there are 256 vector registers on the compute unit, then two warps can run at once, compiler controls number of registers"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#latency",
    "href": "lectures/14_gpu_compilers.html#latency",
    "title": "GPU Compilers",
    "section": "latency",
    "text": "latency\ngpu is a throughput machine- how many threads finish in a unit of time not how long a single thread takes to finish\nunlike the cpu, gpu can have lots of loads in flight, time for these loads overlap so compiler tries to group loads together, but this needs extra registers\n\na warp issues a group of loads\nwarp issues a wait for loads to finish (hardware in cpu, software in gpu)\nhardware switches to another warp (if there is on), good to have a lot of warps 1, if all warps waiting for memory, alu units are idle"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#compiler-model",
    "href": "lectures/14_gpu_compilers.html#compiler-model",
    "title": "GPU Compilers",
    "section": "compiler model",
    "text": "compiler model\n\nlike a regular compiler for a scalar machine\nnew problem: registers used in warp limits number of warps in flight, so ra is different\nnew problem: control flow is more critical\nnew problem: latency means grouping loads but not to much\nnew problem: arch keeps changing"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#thread-coarsening",
    "href": "lectures/14_gpu_compilers.html#thread-coarsening",
    "title": "GPU Compilers",
    "section": "thread coarsening",
    "text": "thread coarsening\nSuppose we are computing a matrix multiply\nwe could say each thread writes one result so a 32 x 32 matrix would need 32 * 32 threads each thread reads one column and one row of the input,\nwe have a lot of reuse (redundant loads of data )\nwe could say each thread writes 4 results, so we need 1/4 of the threads each thread reads a raw and 4 columns"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#technique",
    "href": "lectures/14_gpu_compilers.html#technique",
    "title": "GPU Compilers",
    "section": "technique",
    "text": "technique\n\nmerge multiple threads so each resulting thread writes multiple outputs\ndo the redundant work once and save in registers\nuse the registers for computing all the outputs\n\nBut\n\nneeds extra registers\nincreased efficiency but reduced parallelism\n\nAfter thread coarsening, computation from merged threads can see each others results"
  },
  {
    "objectID": "lectures/14_gpu_compilers.html#doing-this-by-hand",
    "href": "lectures/14_gpu_compilers.html#doing-this-by-hand",
    "title": "GPU Compilers",
    "section": "doing this by hand",
    "text": "doing this by hand\nfor (atomid=0; atomid&lt;numatoms; atomid++) { \n  float dy = coory - atominfo[atomid].y; \n  float dysqpdzsq = (dy * dy) + atominfo[atomid].z; \n  float dx1 = coorx1 - atominfo[atomid].x; \n  float dx2 = coorx2 - atominfo[atomid].x; \n  float dx3 = coorx3 - atominfo[atomid].x; \n  float dx4 = coorx4 - atominfo[atomid].x; \n  energyvalx1 += atominfo[atomid].w * (1.0f / sqrtf(dx1*dx1 + dysqpdzsq));\n  energyvalx2 += atominfo[atomid].w * (1.0f / sqrtf(dx2*dx2 + dysqpdzsq)); \n  energyvalx3 += atominfo[atomid].w * (1.0f / sqrtf(dx3*dx3 + dysqpdzsq)); \n  energyvalx4 += atominfo[atomid].w * (1.0f / sqrtf(dx4*dx4 + dysqpdzsq)); } …"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#challenges-in-learning-about-gpus",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#challenges-in-learning-about-gpus",
    "title": "GPU Compilers",
    "section": "Challenges in Learning About GPUs",
    "text": "Challenges in Learning About GPUs\n\nArchitectural Variations\n\nAll the vendors keep changing the architecture. Different vendors build different hardware. Graphics programs run on all vendors’ hardware because vendors ship their own drivers and do finalization on the device.\n\nInconsistent Terminology\n\nVendors use different terms for the same features and reuse CPU terms somewhat differently. For instance, a “Cuda core” is not the same as a ‘CPU core’.\n\nLegacy Terminology\n\nSome terms come from the GPU’s history of graphics. For example, a shader is a program.\n\nSoftware Abstractions\n\nBig frameworks hide the details.\n\nCUDA’s Market Dominance\n\nMost explanations use CUDA terms since CUDA is the market leader. For instance, AMD uses ‘wave’ to mean more or less the same as a CUDA ‘warp’, but lots of AMD documentation uses ‘warps’.\n\nCUDA: Language and Model\n\nCUDA is both a programming language and a programming model, so you can have CUDA Fortran, CUDA Python, etc."
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-nvidia-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-nvidia-model",
    "title": "GPU Compilers",
    "section": "hardware styles NVIDIA model",
    "text": "hardware styles NVIDIA model\n\ncompute and graphics parts have same programmable parts, compute leaves out non-programmable features\ngraphics customers pay a tax for the compute instructions\nmore transistors for compute instructions\none big die"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-amd-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware-styles-amd-model",
    "title": "GPU Compilers",
    "section": "hardware styles AMD model",
    "text": "hardware styles AMD model\n\ncompute has extra instructions (no tax on graphics customers to support compute)\nchiplet model (great engineering!)\nR series is graphics, C series is compute"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#programming-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#programming-model",
    "title": "GPU Compilers",
    "section": "programming model",
    "text": "programming model\nboth vendors use the CUDA programming model. AMD supports a variation of the CUDA language\nmachines have multiple SIMD processors, each SIMD can be running a different instruction but each lane of a SIMD runs the same instruction\na lane of a SIMD is called a thread"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#threading-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#threading-model",
    "title": "GPU Compilers",
    "section": "threading model",
    "text": "threading model"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#warps-waveswavefronts",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#warps-waveswavefronts",
    "title": "GPU Compilers",
    "section": "warps/ waves/wavefronts",
    "text": "warps/ waves/wavefronts\n\nthreads are grouped together into warps.\nSize is fixed by hardware (usually 32), programmers know this and often make data set sizes a multiple of 32.\nsince all threads in a warp are running the same instruction, there is no need for explicit synchronization\nthere are a few instructions that work across a warp, - which break the model and give the compiler problems"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-blocks-groups-of-warps",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-blocks-groups-of-warps",
    "title": "GPU Compilers",
    "section": "thread blocks groups of warps,",
    "text": "thread blocks groups of warps,\n\nthreads within a block can access a fast scratchpad memory (called shared or LDS) - Violates the C memory model.\n\nthreads are identified by a 3d index inside a block\nthread blocks need synchronization operations.\n\nhardware schedules each block into execution units. Max block size is limited by the size of a execution unit."
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#grid-groups-of-blocks",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#grid-groups-of-blocks",
    "title": "GPU Compilers",
    "section": "grid groups of blocks,",
    "text": "grid groups of blocks,\n\n3d collection of blocks,\nusually hardware limits mean that all the threads in a grid do not run at the same time\nprogrammers need to make grids big enough to fill the hardware\nsoftware launches a grid and a program\nthreads within a grid but in different blocks do not have sync operations"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#heterogeneous-programming",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#heterogeneous-programming",
    "title": "GPU Compilers",
    "section": "Heterogeneous programming",
    "text": "Heterogeneous programming\nthe cpu is called the host\nthe gpu is called the device\ncpu launches grids and kernels to gpu\nComputations launched on the device execute asynchronously with respect to the host, and it is the user’s responsibility to synchronize"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#memory-spaces",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#memory-spaces",
    "title": "GPU Compilers",
    "section": "memory spaces",
    "text": "memory spaces\n\ncpu and gpu have different memory spaces (cpu can copy from one to the other). Some amount of combined memory (slower the not combined)\ngpu has shared/lds memory which can be accessed by threads within a block, passing an address to a different block does not work\nmain gpu memory is called global accessible by all threads\ngpu has per thread memory called local or scratch ot private memory - unlike C, passing an address in local memory to another thread does not work. (under some restrictions AMD implements part of the C memory model)\na few special gpu memory types: constant, texture, surface (left over from graphics)\ngpu can treat registers as fast memory"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#hardware",
    "title": "GPU Compilers",
    "section": "Hardware",
    "text": "Hardware\nNVIDIA\n\nnv image level 0Each box here is hardware, an int32/fp32/fp64 can perform one operation, so here we have 32 fp32 units which can do 32 float operations in parallel as well as 16 int32 and 16 fp64 units , there are also 8 units can do loads or stores and a final special function unit that can do transcendental operations like sin/cos\nunder some conditions two instructions (a float and an int) from the same warp can execute at the same time\nI’m not going to talk much about the tensor cores\nall these units execute the same instruction (SIMT) Simple instruction multiple thread (not the same as SIMD but related )"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#one-instruction-does-vector-work",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#one-instruction-does-vector-work",
    "title": "GPU Compilers",
    "section": "one instruction does vector work",
    "text": "one instruction does vector work\nadd 32 float32 values (all coming from registers) and store the result in 32 other registers\nNotice no branch prediction, no out of order execution\ngreat at switching a warp holds the instruction, it knows which registers it owns (continuous set, so it just needs a start and length) switching to a different warp, means changing these two numbers and the pc (this is done by the dispatch unt )\nWhen we do a load, we need to wait for the result. CPU might do some kind of out of order execution, a gpu switches to another warp\nfinally we need to pick the warp to switch to, this is done by the warp scheduler (half of the hardware scheduler)"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#streaming-multiprocessors-sm",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#streaming-multiprocessors-sm",
    "title": "GPU Compilers",
    "section": "streaming multiprocessors (SM)",
    "text": "streaming multiprocessors (SM)\nnvidia packs 4 execution engines into a SM (streaming multi-processor) ands an L1 instruction cache, a special memory accelerator for tensors and 256kb l1 data cache/ shared memory block"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#pack-sms-together",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#pack-sms-together",
    "title": "GPU Compilers",
    "section": "pack sm’s together",
    "text": "pack sm’s together"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#amd",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#amd",
    "title": "GPU Compilers",
    "section": "AMD",
    "text": "AMD"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#and",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#and",
    "title": "GPU Compilers",
    "section": "and",
    "text": "and\n\nAMD has a similar block with some important differences\n\nAt the bottom of a compute core there are 4 general purpose simd engines each of length 16 and one scalar engine\n\nGiven 5 waves, this compute core can execute 4 vector instructions and one scalar instruction per clock Two instructions from the same wave never execute at the same time\nThe SIMD engines can execute different instructions\nThe simd sizes vary over different chips"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#amd-cdna",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#amd-cdna",
    "title": "GPU Compilers",
    "section": "amd CDNA",
    "text": "amd CDNA"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#packing-sms",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#packing-sms",
    "title": "GPU Compilers",
    "section": "packing sms",
    "text": "packing sms"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#simd-and-control-flow",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#simd-and-control-flow",
    "title": "GPU Compilers",
    "section": "simd and control flow",
    "text": "simd and control flow\nto execute an if then else\n\ncompute the if condition\nturn off the lanes where the condition is false\nexecute the if side\nflip the lanes\nexecute the else side\n\ntime is the sum of the times for then and the else"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#number-of-warps-in-flight",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#number-of-warps-in-flight",
    "title": "GPU Compilers",
    "section": "number of warps in flight",
    "text": "number of warps in flight\nsince an entire block has to fit on one compute unit/sm, the resources used in the block limit the number of warps on a sm,\nif a warp needs 100 registers and there are 256 vector registers on the compute unit, then two warps can run at once, compiler controls number of registers"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#latency",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#latency",
    "title": "GPU Compilers",
    "section": "latency",
    "text": "latency\ngpu is a throughput machine- how many threads finish in a unit of time not how long a single thread takes to finish\nunlike the cpu, gpu can have lots of loads in flight, time for these loads overlap so compiler tries to group loads together, but this needs extra registers\n\na warp issues a group of loads\nwarp issues a wait for loads to finish (hardware in cpu, software in gpu)\nhardware switches to another warp (if there is on), good to have a lot of warps 1, if all warps waiting for memory, alu units are idle"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#compiler-model",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#compiler-model",
    "title": "GPU Compilers",
    "section": "compiler model",
    "text": "compiler model\n\nlike a regular compiler for a scalar machine\nnew problem: registers used in warp limits number of warps in flight, so ra is different\nnew problem: control flow is more critical\nnew problem: latency means grouping loads but not to much\nnew problem: arch keeps changing"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-coarsening",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#thread-coarsening",
    "title": "GPU Compilers",
    "section": "thread coarsening",
    "text": "thread coarsening\nSuppose we are computing a matrix multiply\nwe could say each thread writes one result so a 32 x 32 matrix would need 32 * 32 threads each thread reads one column and one row of the input,\nwe have a lot of reuse (redundant loads of data )\nwe could say each thread writes 4 results, so we need 1/4 of the threads each thread reads a raw and 4 columns"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#technique",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#technique",
    "title": "GPU Compilers",
    "section": "technique",
    "text": "technique\n\nmerge multiple threads so each resulting thread writes multiple outputs\ndo the redundant work once and save in registers\nuse the registers for computing all the outputs\n\nBut\n\nneeds extra registers\nincreased efficiency but reduced parallelism\n\nAfter thread coarsening, computation from merged threads can see each others results"
  },
  {
    "objectID": "lectures/revealjs_14_gpu_compilers.qmd.html#doing-this-by-hand",
    "href": "lectures/revealjs_14_gpu_compilers.qmd.html#doing-this-by-hand",
    "title": "GPU Compilers",
    "section": "doing this by hand",
    "text": "doing this by hand\nfor (atomid=0; atomid&lt;numatoms; atomid++) { \n  float dy = coory - atominfo[atomid].y; \n  float dysqpdzsq = (dy * dy) + atominfo[atomid].z; \n  float dx1 = coorx1 - atominfo[atomid].x; \n  float dx2 = coorx2 - atominfo[atomid].x; \n  float dx3 = coorx3 - atominfo[atomid].x; \n  float dx4 = coorx4 - atominfo[atomid].x; \n  energyvalx1 += atominfo[atomid].w * (1.0f / sqrtf(dx1*dx1 + dysqpdzsq));\n  energyvalx2 += atominfo[atomid].w * (1.0f / sqrtf(dx2*dx2 + dysqpdzsq)); \n  energyvalx3 += atominfo[atomid].w * (1.0f / sqrtf(dx3*dx3 + dysqpdzsq)); \n  energyvalx4 += atominfo[atomid].w * (1.0f / sqrtf(dx4*dx4 + dysqpdzsq)); } …"
  },
  {
    "objectID": "lectures/03_local.html",
    "href": "lectures/03_local.html",
    "title": "Local Analysis & Optimization",
    "section": "",
    "text": "I want to separate 3 flavors of optimization.\nUsually an optimization takes time that is more then linear in some property, For example a local optimization might take time \\(n^2\\) in the number of instructions in the block. a global optimization might take much longer, and an inter-procedural longer still. To keep compile time reasonable many compilers limit the number of global optimizations and skip inter-procedural optimizations. As a consequence many more optimizations get published but not used in production.\nWhen would running an optimization speedup compilation?\nFor a local optimization, instructions within a block are ordered, so it makes sense to talk about instructions coming before or after others.\nFor a global optimization, two instructions are ordered by a path from one block to another and different paths through the program give different orders.\nOne special case is JIT (just in time) compilers, where programs get compiled at the start of execution. GPU compilers (and java compilers) look like this. They may use run-time information to decide of recompiling a function is a good idea. This is called Hotspot compiling. Some JIT compilers use hot/cold compiling, where they only run the fancy compiler on basic blocks that are hot , i.e., execute a lot.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart LR\nA[application] -- offline --&gt; B[byte code/ptx]\nB --&gt; C[quick run time compiler/ finalizer]\nC --&gt; D[isa]\nB --&gt; C1[fancy compiler - only run on long running functions];\nC1 --&gt; D;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart LR\nA[application] -- offline --&gt; B[byte code/ptx]\nB --&gt; C[quick run time compiler/ finalizer]\nC --&gt; D[isa]\nB --&gt; C1[fancy compiler - only run on long running functions];\nC1 --&gt; D;\nWe are going to consider several versions of trivial dead code elimination. Trivial because we are going to hold off on control flow related optimizations till later. Sometimes people call this DCE or trivial DCE.\nFor each case, we start by defining what we mean by dead code.\nexample 1\nWhat instruction is dead? (meaning get the same answer if we delete the instruction) What is your definition? Is this meaning of dead code local or global?\nWhy would you ever have dead code in a program? One reason is that have DCE as a separate pass means other optimizations do not have to clean up."
  },
  {
    "objectID": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "href": "lectures/03_local.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 1- Dead if instruction writes a variable and the variable is never used.",
    "text": "Definition 1- Dead if instruction writes a variable and the variable is never used.\nAn instruction that has side-effects, like a print statement does not write a variable so it never gets deleted. Labels do not write a variable so they do not get deleted as well.\n\nWhat is the pseudo code to find dead instructions using this definition?\n. . .\nused = empty set \nfor instr in func \n   used += instr.args \nfor instd in func\n    if instr has a dest and dest in not in used \n       delete instr\n\nexample 2\n@main {\n  a: int = const 4;\n  b: int = const 2;\n  c: int = const 1;  \n  d: int = add a b;\n  e: int = add c d; \n  print d;\n}\n. . .\nThe code so far only deletes one instruction, but we would like to get rid of two. Instruction c should also be dead. How do we change the definition"
  },
  {
    "objectID": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "href": "lectures/03_local.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "text": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions."
  },
  {
    "objectID": "lectures/03_local.html#iterating-till-convergence",
    "href": "lectures/03_local.html#iterating-till-convergence",
    "title": "Local Analysis & Optimization",
    "section": "iterating till convergence",
    "text": "iterating till convergence\nwhile changes:\n       run one pass of tdce above"
  },
  {
    "objectID": "lectures/03_local.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "href": "lectures/03_local.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "title": "Local Analysis & Optimization",
    "section": "what would be faster? What is some pseudo code for the change",
    "text": "what would be faster? What is some pseudo code for the change\n. . .\n  find all the variables that are used in more then one block\n  for each block b \n     used = all variables used in more then one block\n     walk backwards over the instruction in the block\n     for each instruction is dest in used?\n        yes - remove dest from used, add arguments to used \n        no  - instruction is dead \n\nfinding all the variables used in more then one block might be expensive\n\nexample 3\n@main {\n  a: int = const 4;\n  a: int = const 200;\n  print a;\n}"
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "title": "Local Analysis & Optimization",
    "section": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v",
    "text": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v\nthis talks about paths (control flow paths)\n@main {\n  a: int = const 4;\n     br input .then .else \n  .then\n  a: int = const 200;\n  .else \n  print a;\n}"
  },
  {
    "objectID": "lectures/03_local.html#for-now-we-want-to-skip-control-flow",
    "href": "lectures/03_local.html#for-now-we-want-to-skip-control-flow",
    "title": "Local Analysis & Optimization",
    "section": "for now we want to skip control flow",
    "text": "for now we want to skip control flow"
  },
  {
    "objectID": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "href": "lectures/03_local.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "title": "Local Analysis & Optimization",
    "section": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block\n\ncands are the variables that are defined but not used \nlast_def = {}  variables -&gt; instructions \nthis is a mapping variables that have been defined but not used\n\n   for instr in block:\n      each arg (use) removes arg from last def \n      if the instr has a dest \n          if the dest is in last_def, \n      add dest-&gt;instr to last def\n  \nand as you might expect, we need to iterate this till convergence\n\nCompilers often run dce more then once- why?\n\ntesting out dce\n\nprogram should get the same answer\nprogram should run less instructions\n\n\nSome test cases:\n\nsimple.bril,\nreassign.bril,\nother examples in the DCE test directory"
  },
  {
    "objectID": "lectures/03_local.html#testing",
    "href": "lectures/03_local.html#testing",
    "title": "Local Analysis & Optimization",
    "section": "testing",
    "text": "testing\nbril2json &lt; bench.bril | python3 tdce.py | bril2txt\nNext, try using wc to check static code size differences:\nbril2json &lt; bench.bril | wc -l\nbril2json &lt; bench.bril | python3 tdce.py | wc -l\nThen profiling to measure dynamic instruction count: The bril interpreter has a flag -p which prints the number of dynamically executed instructions.\nHow good a measure is this for real programs?"
  },
  {
    "objectID": "lectures/03_local.html#using-trunt-golden-images",
    "href": "lectures/03_local.html#using-trunt-golden-images",
    "title": "Local Analysis & Optimization",
    "section": "using trunt (golden images)",
    "text": "using trunt (golden images)\n\nConfigure. Decide what command you want to test. Make a turnt.toml config file and put command = “mycmd {filename}” in it to pass each test file as an argument to mycmd.\nTake a snapshot. Run turnt –save foo.bril. Execute mycmd foo.bril and save the standard output into foo.out.\n\nYou might want to take a look at this output to make sure it’s what you expect\n\nTest your work. Now that you have a test in place, keep working. Use turnt *.bril to run all your tests and confirm that the output still matches.\n\nIf there’s a mismatch, you can do turnt –diff to see the changes."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "href": "lectures/revealjs_03_local.qmd.html#definition-1--dead-if-instruction-writes-a-variable-and-the-variable-is-never-used.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 1- Dead if instruction writes a variable and the variable is never used.",
    "text": "Definition 1- Dead if instruction writes a variable and the variable is never used.\nAn instruction that has side-effects, like a print statement does not write a variable so it never gets deleted. Labels do not write a variable so they do not get deleted as well."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "href": "lectures/revealjs_03_local.qmd.html#definition-2--dead-if-instruction-writes-a-variable-and-the-variable-is-either-never-used-or-only-used-in-dead-instructions.",
    "title": "Local Analysis & Optimization",
    "section": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions.",
    "text": "Definition 2- Dead if instruction writes a variable and the variable is either never used or only used in dead instructions."
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#iterating-till-convergence",
    "href": "lectures/revealjs_03_local.qmd.html#iterating-till-convergence",
    "title": "Local Analysis & Optimization",
    "section": "iterating till convergence",
    "text": "iterating till convergence\nwhile changes:\n       run one pass of tdce above"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "href": "lectures/revealjs_03_local.qmd.html#what-would-be-faster-what-is-some-pseudo-code-for-the-change",
    "title": "Local Analysis & Optimization",
    "section": "what would be faster? What is some pseudo code for the change",
    "text": "what would be faster? What is some pseudo code for the change\n\n  find all the variables that are used in more then one block\n  for each block b \n     used = all variables used in more then one block\n     walk backwards over the instruction in the block\n     for each instruction is dest in used?\n        yes - remove dest from used, add arguments to used \n        no  - instruction is dead \n\nfinding all the variables used in more then one block might be expensive"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "href": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-starting-at-that-instruction-reaches-a-use-of-v",
    "title": "Local Analysis & Optimization",
    "section": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v",
    "text": "Definition? An instruction is dead if that instruction writes a variable v and no path starting at that instruction reaches a use of v\nthis talks about paths (control flow paths)\n@main {\n  a: int = const 4;\n     br input .then .else \n  .then\n  a: int = const 200;\n  .else \n  print a;\n}"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#for-now-we-want-to-skip-control-flow",
    "href": "lectures/revealjs_03_local.qmd.html#for-now-we-want-to-skip-control-flow",
    "title": "Local Analysis & Optimization",
    "section": "for now we want to skip control flow",
    "text": "for now we want to skip control flow"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "href": "lectures/revealjs_03_local.qmd.html#definition-an-instruction-is-dead-if-that-instruction-writes-a-variable-v-and-no-path-within-the-block-starting-at-that-instruction-reaches-a-use-of-v-in-the-same-block-or-reaches-the-exit-of-the-block",
    "title": "Local Analysis & Optimization",
    "section": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block",
    "text": "Definition: An instruction is dead if that instruction writes a variable v and no path within the block starting at that instruction reaches a use of v in the same block or reaches the exit of the block"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#testing",
    "href": "lectures/revealjs_03_local.qmd.html#testing",
    "title": "Local Analysis & Optimization",
    "section": "testing",
    "text": "testing\nbril2json &lt; bench.bril | python3 tdce.py | bril2txt\nNext, try using wc to check static code size differences:\nbril2json &lt; bench.bril | wc -l\nbril2json &lt; bench.bril | python3 tdce.py | wc -l\nThen profiling to measure dynamic instruction count: The bril interpreter has a flag -p which prints the number of dynamically executed instructions.\nHow good a measure is this for real programs?"
  },
  {
    "objectID": "lectures/revealjs_03_local.qmd.html#using-trunt-golden-images",
    "href": "lectures/revealjs_03_local.qmd.html#using-trunt-golden-images",
    "title": "Local Analysis & Optimization",
    "section": "using trunt (golden images)",
    "text": "using trunt (golden images)\n\nConfigure. Decide what command you want to test. Make a turnt.toml config file and put command = “mycmd {filename}” in it to pass each test file as an argument to mycmd.\nTake a snapshot. Run turnt –save foo.bril. Execute mycmd foo.bril and save the standard output into foo.out.\n\nYou might want to take a look at this output to make sure it’s what you expect\n\nTest your work. Now that you have a test in place, keep working. Use turnt *.bril to run all your tests and confirm that the output still matches.\n\nIf there’s a mismatch, you can do turnt –diff to see the changes."
  },
  {
    "objectID": "lectures/100_mlir.html",
    "href": "lectures/100_mlir.html",
    "title": "10 MLIR",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/010_compiler_overview.html",
    "href": "lectures/010_compiler_overview.html",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "A compiler writer builds bridges between people and machines, and this task is each day more challenging.\n\nSoftware engineers want abstractions\n\nHardware engineers want efficiency\n\n\n\nOriginally, a compiler was a person doing calculations.\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n[]\n\n\n\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters.\n\n\n\nIn these early years, the development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on stage 2 (The middle end)\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy\n\n\n\n\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks.\n\n\n\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments.\n\n\n\n\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n\n\n\n\n\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nFrom CGO 2022 keynote\n\nSome observations: 1) Production compilers are expensive. 1) IR does not change easily. 1) Much of compiler technology is old. 1) There is a vast difference between production and student projects.\n\n\n\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Doman specific languages for AI)\nMore kinds of hardware\n\n\n\n\nAt the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\nproebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt\n\n\n\nTalk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write.\n\n\n\nRemove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types\n\n\nOver time hardware has become more of a challenge for compilers, for example caches are not predictable at compile time. So compilers have to guess\nAnd hardware can ignore features of the compiler can deal with them - for example interlock"
  },
  {
    "objectID": "lectures/010_compiler_overview.html#early-compilers",
    "href": "lectures/010_compiler_overview.html#early-compilers",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "Originally, a compiler was a person doing calculations.\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n[]"
  },
  {
    "objectID": "lectures/010_compiler_overview.html#fortran",
    "href": "lectures/010_compiler_overview.html#fortran",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\nTheir paper is located at https://dl.acm.org/doi/10.1145/1455567.1455599.\nThe name stands for formula translation. It’s in upper case because at that time, compilers did not support lower case.\nThe FORTRAN project was begun in the summer of 1954. Its purpose was to reduce by a large factor the task of preparing scientific problems for IBM’s next large computer, the 704. If it were possible for the 704 to code problems for itself and produce as good programs as human coders (but without the errors), it was clear that large benefits could be achieved. For it was known that about two-thirds of the cost of solving most scientific and engineering problems on large computers was that of problem preparation. Furthermore, more than 90 per cent of the elapsed time for a problem was usually devoted to planning, writing, and debugging the program. In many cases the development of a general plan for solving a problem was a small job in comparison to the task of devising and coding machine procedures to carry out the plan.\nThe goal of the FORTRAN project was to enable the programmer to specify a numerical procedure using a concise language like that of mathematics and obtain automatically from this specification an efficient 704 program to carry out the procedure. It was expected that such a system would reduce the coding and debugging task to less than one-fifth of the job it had been.\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters."
  },
  {
    "objectID": "lectures/010_compiler_overview.html#compiler-development-model",
    "href": "lectures/010_compiler_overview.html#compiler-development-model",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In these early years, the development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies.\n\nCompilers stabilized on a classic structure (using an ir intermediate language). IR is machine independent.\n\nFront end - parse the program into IR\nMiddle end - machine independent optimizations and analyses\nBack end - machine specific stuff where machine code is generated\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B[Middle end];\nB--IR--&gt; C[Back end];\nA--IR--&gt; C;\n\n\n\n\n\n\n\nThis course focuses on stage 2 (The middle end)\nA goal of this course is to explain how to transform a program automatically, while preserving its semantics, in such a way that the new program is more efficient according to a well-defined metric.\n There are many ways to compare the performance of programs:\n\nTime\nSpace\nEnergy"
  },
  {
    "objectID": "lectures/010_compiler_overview.html#gcc",
    "href": "lectures/010_compiler_overview.html#gcc",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end.\n\nThis ended almost all the compiler startups. Free front end, middle end.\nIn gcc the IR is somewhat C based, for instance there are pointers but there is no simple way to talk about garbage collection without hacks."
  },
  {
    "objectID": "lectures/010_compiler_overview.html#llvm",
    "href": "lectures/010_compiler_overview.html#llvm",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "in about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;\n\n\n\n\n\n\n\nOptimizations form passes. A user could mix and match – run some optimizations but not others to compile a specific program. It became easy for people to add a pass. Lots of academic research, lots of experiments."
  },
  {
    "objectID": "lectures/010_compiler_overview.html#bril",
    "href": "lectures/010_compiler_overview.html#bril",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "In this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];"
  },
  {
    "objectID": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "href": "lectures/010_compiler_overview.html#cost-of-a-compiler.",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "Compilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nFrom CGO 2022 keynote\n\nSome observations: 1) Production compilers are expensive. 1) IR does not change easily. 1) Much of compiler technology is old. 1) There is a vast difference between production and student projects."
  },
  {
    "objectID": "lectures/010_compiler_overview.html#compiler-assumptions-how-many-are-still-true",
    "href": "lectures/010_compiler_overview.html#compiler-assumptions-how-many-are-still-true",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "The time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like.\n\n\nSome changes since early 2000’s:\n\nIntegrated development environments. When you type a.b what has to happen?\nDSL (Doman specific languages for AI)\nMore kinds of hardware"
  },
  {
    "objectID": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "href": "lectures/010_compiler_overview.html#how-well-do-compilers-do",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "At the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\nproebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt"
  },
  {
    "objectID": "lectures/010_compiler_overview.html#why-compilers-are-not-better",
    "href": "lectures/010_compiler_overview.html#why-compilers-are-not-better",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "Talk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write."
  },
  {
    "objectID": "lectures/010_compiler_overview.html#effects-of-optimization",
    "href": "lectures/010_compiler_overview.html#effects-of-optimization",
    "title": "1 Compiler Overview",
    "section": "",
    "text": "Remove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types\n\n\nOver time hardware has become more of a challenge for compilers, for example caches are not predictable at compile time. So compilers have to guess\nAnd hardware can ignore features of the compiler can deal with them - for example interlock"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#early-compilers",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#early-compilers",
    "title": "1 Compiler Overview",
    "section": "Early Compilers",
    "text": "Early Compilers\nOriginally, a compiler was a person doing calculations.\nIn 1952, Grace Hopper an operational link-loader, which she called a compiler. She later said, “Nobody believed that,” and that she “had a running compiler and nobody would touch it. They told me computers could only do arithmetic.”\n[]"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#fortran",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#fortran",
    "title": "1 Compiler Overview",
    "section": "FORTRAN",
    "text": "FORTRAN\nIn 1957, John Backus created the first commercial compiler, FORTRAN (14 people worked on it for about 4 years).\n2/3 of the cost and 90% of the time for solving a problem was coding\nFORTRAN was provided for the IBM 1401 computer by an innovative 63-phase compiler that ran entirely in its core memory of only 8000 (six-bit) characters."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-development-model",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-development-model",
    "title": "1 Compiler Overview",
    "section": "Compiler Development Model",
    "text": "Compiler Development Model\nIn these early years, the development model was:\n\nbuild a new machine\ndesign a new language\nimplement the compiler\n\nVendors sometimes built compilers but often used small startup compiler companies."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#gcc",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#gcc",
    "title": "1 Compiler Overview",
    "section": "gcc",
    "text": "gcc\nIn 1987, GCC was released. It formalized the IR, and was more or less open source. Within the stages, compiler writers could use any data structures but at the edges they had to use the single IR. Adding an optimization or reordering optimizations is quite hard.\nVendors could use one front end, one middle end and only need to write a new back end."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#llvm",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#llvm",
    "title": "1 Compiler Overview",
    "section": "LLVM",
    "text": "LLVM\nin about 2006 LLVM (originally low level virtual machine) appeared. This changed the model to look like a library.\nThe core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computer (RISC) instruction set which abstracts away most details of the target.\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph LR;\nA[Front end]--IR--&gt; B0[OP0] --IR--&gt; B1[OP1] --IR--&gt; B2[OPT2]--IR --&gt; BN[OPTn]--IR --&gt;C{Back end};\nA--IR--&gt; C;"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#bril",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#bril",
    "title": "1 Compiler Overview",
    "section": "bril",
    "text": "bril\nIn this course we are going to an IR call BRIL, which is a very simplified version of LLVM IR, and we are going to string passes together by using UNIX pipes.\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| echo: false \ngraph TB;\nA[TEXT_Version of BRIL]--&gt; B0[BRIL in JSON] --&gt; B1[\"new pass\"] --&gt; B2[BRIL interpreter];"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#cost-of-a-compiler.",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#cost-of-a-compiler.",
    "title": "1 Compiler Overview",
    "section": "Cost of a compiler.",
    "text": "Cost of a compiler.\nCompilers are massive and expensive to build.\n\n\n\nCompiler\nYear Started\nDevelopers\nLines Of Code\nEst Cost $\n\n\n\n\nGCC 9.2.0\n1988\n617\n5,591,759\n425,747,279\n\n\nLLVM 8.0.1\n2001\n1,210\n6,877,489\n529,894,190\n\n\nOpenJDK 14+10\n2007\n883\n7,955,827\n616,517,789\n\n\nv8 7.8.112\n2008\n736\n3,043,793\n225,195,832\n\n\nRust 1.37.0\n2010\n2,737\n852,877\n59,109,425\n\n\nSwift\n2010\n857\n665,238\n45,535,689\n\n\nIntel Graphics 1.0.10\n2018\n149\n694,688\n46,934,626\n\n\n\nFrom CGO 2022 keynote"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-assumptions-how-many-are-still-true",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#compiler-assumptions-how-many-are-still-true",
    "title": "1 Compiler Overview",
    "section": "Compiler Assumptions (How many are still true)",
    "text": "Compiler Assumptions (How many are still true)\n\nThe time to compile a program should be roughly linear. So, non-linear algorithms can only be used if they work on a small part of a program.\nUsers are ok with large programs taking minutes to compile\nCompilers run on machines that are memory-limited.\nCompilers run on single-threaded machines.\nMost targets are C-like."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#how-well-do-compilers-do",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#how-well-do-compilers-do",
    "title": "1 Compiler Overview",
    "section": "How well do compilers do",
    "text": "How well do compilers do\nAt the scale of data-centers, every single performance percent matters! Just take a look at Google’s (and other’s) publicly available numbers on expenditures on datacenters. We are talking about billions of dollars. A single percent improvement can mean millions of dollars from more program features or improved utilization.\nproebsting’s law\nCompiler Advances Double Computing Power Every 18 Years.\nwhile hardware computing horsepower doubles every 18 months. How would you prove this?\none attempt"
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#why-compilers-are-not-better",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#why-compilers-are-not-better",
    "title": "1 Compiler Overview",
    "section": "why compilers are not better",
    "text": "why compilers are not better\nTalk given by KAI’s Arch Robison\nCompile-time program optimizations are similar to poetry: more are written than actually published in commercial compilers. Hard economic reality is that many interesting optimizations have too narrow an audience to justify their cost in a general-purpose compiler and custom compilers are too expensive to write."
  },
  {
    "objectID": "lectures/revealjs_010_compiler_overview.qmd.html#effects-of-optimization",
    "href": "lectures/revealjs_010_compiler_overview.qmd.html#effects-of-optimization",
    "title": "1 Compiler Overview",
    "section": "effects of optimization",
    "text": "effects of optimization\nRemove performance penalty for:\n\nusing higher level constructs\nsafety checks (e.g., array bounds checks)\nwriting clean, simple code (no benefit to applying loop unrolling by hand)\nEncourage ADT’s that are as efficient as primitive types"
  },
  {
    "objectID": "lectures/02b_bril.html",
    "href": "lectures/02b_bril.html",
    "title": "Overview of Bril",
    "section": "",
    "text": "Bril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy"
  },
  {
    "objectID": "lectures/02b_bril.html#how-to-use-bril-with-real-code",
    "href": "lectures/02b_bril.html#how-to-use-bril-with-real-code",
    "title": "Overview of Bril",
    "section": "",
    "text": "Bril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy"
  },
  {
    "objectID": "lectures/02b_bril.html#lets-look-at-a-bril-program.",
    "href": "lectures/02b_bril.html#lets-look-at-a-bril-program.",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\nBril is written in JSON format. Almost all programming languages have a way to read json.\n\nimport json\nimport subprocess\nimport os \n\n# read from a file \nwith open(\"images/add.json\",\"r\") as f:\n    bril_program = json.load(f)\n\n# read from a pipe\n# bril_program = json.load(sys.stdin)\n    \nprint(json.dumps(bril_program, \n    indent=2))\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/02b_bril.html#formatted",
    "href": "lectures/02b_bril.html#formatted",
    "title": "Overview of Bril",
    "section": "Formatted",
    "text": "Formatted\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\"dest\": \"v0\", \"op\": \"const\",\"type\": \"int\",\"value\": 1},\n        {\"dest\": \"v1\", \"op\": \"const\",\"type\": \"int\",\"value\": 2},\n        {\"dest\": \"v2\", \"op\": \"add\",  \"type\": \"int\",\"args\": [\"v0\",\"v1\"],},\n                       \"op\": \"print\",\"args\": [ \"v2\"],}],\n      \"name\": \"main\",\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/02b_bril.html#getting-started",
    "href": "lectures/02b_bril.html#getting-started",
    "title": "Overview of Bril",
    "section": "getting started",
    "text": "getting started\nlinks:\n\nLanguage specification\ngithub site"
  },
  {
    "objectID": "lectures/02b_bril.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "href": "lectures/02b_bril.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "title": "Overview of Bril",
    "section": "step 1 clone the bril repo on a linux or wsl machine",
    "text": "step 1 clone the bril repo on a linux or wsl machine\ngit clone https://github.com/sampsyo/bril.git"
  },
  {
    "objectID": "lectures/02b_bril.html#step-2-support-packages",
    "href": "lectures/02b_bril.html#step-2-support-packages",
    "title": "Overview of Bril",
    "section": "step 2 support packages",
    "text": "step 2 support packages\n\ndeno is the runtime for typescript/javascript\n\ncurl -fsSL https://deno.land/install.sh | sh\non my ubuntu machine ‘sudo snap install deno’ also worked\nyou may need to add $HOME/.deno/bin to your $PATH.\n\nflit a python package manager\n\npython3 -m pip install flit"
  },
  {
    "objectID": "lectures/02b_bril.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "href": "lectures/02b_bril.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "title": "Overview of Bril",
    "section": "step 3 install the bril interpreter, and the typescript to bril compiler",
    "text": "step 3 install the bril interpreter, and the typescript to bril compiler\ncd bril\ndeno install brili.ts \ndeno install --allow-env --allow-read ts2bril.ts"
  },
  {
    "objectID": "lectures/02b_bril.html#running-the-interpreter",
    "href": "lectures/02b_bril.html#running-the-interpreter",
    "title": "Overview of Bril",
    "section": "running the interpreter",
    "text": "running the interpreter\nbrili &lt;images/add.json\nbrili -p &lt;images/add.json\nthe -p flag turns on profiling"
  },
  {
    "objectID": "lectures/02b_bril.html#text-to-json-and-back",
    "href": "lectures/02b_bril.html#text-to-json-and-back",
    "title": "Overview of Bril",
    "section": "text to json and back",
    "text": "text to json and back\nThere are programs bril2txt and bril2json that make it easy to convert. Keep in mind that the json format is Bril and thats where you will do all the work.\ninstall text tools\ncd bril-txt\nflit install --symlink --user\nrun json to text\nbril2txt &lt; images/add.json"
  },
  {
    "objectID": "lectures/02b_bril.html#connect-tools-via-pipes",
    "href": "lectures/02b_bril.html#connect-tools-via-pipes",
    "title": "Overview of Bril",
    "section": "connect tools via pipes",
    "text": "connect tools via pipes\ncat images/add.json'\nbril2txt &lt; images/add.json | bril2json"
  },
  {
    "objectID": "lectures/02b_bril.html#other-tools",
    "href": "lectures/02b_bril.html#other-tools",
    "title": "Overview of Bril",
    "section": "Other tools",
    "text": "Other tools\nThere is also a fast interpreter written in Rust see docs for installation"
  },
  {
    "objectID": "lectures/02b_bril.html#turnt-tiny-unified-runner-and-tester",
    "href": "lectures/02b_bril.html#turnt-tiny-unified-runner-and-tester",
    "title": "Overview of Bril",
    "section": "turnt Tiny unified runner and tester",
    "text": "turnt Tiny unified runner and tester\nBril uses turnt as a test tool\nTurnt is a simple snapshot testing tool inspired by LLVM’s lit. It’s good for testing things that translate text files to other text files, like compilers. The idea is that each test is one input file, and you want to run a command and check that it still matches the saved output file.\npip install –user turnt\nAs you think about your projects, you might consider adding a new tool. you can setup Bril on your local linux (can be wsl) machine"
  },
  {
    "objectID": "lectures/02b_bril.html#gen-cfg",
    "href": "lectures/02b_bril.html#gen-cfg",
    "title": "Overview of Bril",
    "section": "Gen CFG",
    "text": "Gen CFG\nLets write a sample program - that generates the cfg\nHow would you do that?\n. . .\nI’ll do this in two steps\n\nfind all the basic blocks\nadd all the cfg edges\n\nYou can also do this in a single step, adding cfg edges as soon as you reach the successor node."
  },
  {
    "objectID": "lectures/02b_bril.html#basic-blocks-from-a-list-of-instructions-",
    "href": "lectures/02b_bril.html#basic-blocks-from-a-list-of-instructions-",
    "title": "Overview of Bril",
    "section": "basic blocks from a list of instructions-",
    "text": "basic blocks from a list of instructions-\nkeep adding instructions till we get to a terminator or a label (do we add labels?)\n. . .\nin: list of instrs \nout: list of lists of instrs \n \nblocks = []\ncurr_block = []\nfor each instr in list \n    if the instruction is not a label put it on curr_block\n    if instr is a label or terminator \n       put curr_block on blocks\n       curr_block = []\n \n if curr_block is not empty add it to blocks\n return blocks \ntwo labels in a row do not need another block"
  },
  {
    "objectID": "lectures/02b_bril.html#step-2-add-edges",
    "href": "lectures/02b_bril.html#step-2-add-edges",
    "title": "Overview of Bril",
    "section": "step 2 add edges",
    "text": "step 2 add edges\nfind cfg: in: is bril program in json \nfor each function find the list of basic blocks\nfor each basic block\n   get last_instr \n   if it is a terminator  br/jmp/ret \n     add edge from current block to successor  \n    --- what do we want to do with call? \n   else it is a fall through\n      add edge to next block\n. . .\nwe need a map (block_map) label-&gt;block so we can add edges for blocks that end in br/jmp - can build this while getting the blocks or we can put the label as the first instruction\nhow do we handle fall through?\nwhat about a return\nif every block ends with a terminator, and every block has a label, then no fall through case\nwhat happens if try to delete the terminator (because the block never executes)"
  },
  {
    "objectID": "lectures/02b_bril.html#code",
    "href": "lectures/02b_bril.html#code",
    "title": "Overview of Bril",
    "section": "code",
    "text": "code\nI’ll use a python data structure called OrderedDict, when you iterate over the items in a ordered dict, they come back in the order that they were installed.\n\nGitHub Copilot says:\nOrderedDict in Python is a dictionary subclass that maintains the order in which keys are inserted. When iterating over an OrderedDict, the items are returned in the order they were added. This behavior contrasts with a standard dictionary in Python 3.6 and earlier, where the iteration order was not guaranteed. However, starting from Python 3.7, the built-in dict type also maintains insertion order by default, making OrderedDict less necessary for most applications. OrderedDict still provides additional functionality, such as the move_to_end method, which allows moving an existing key to either end of the dictionary."
  },
  {
    "objectID": "lectures/02b_bril.html#ill-use-a-generator",
    "href": "lectures/02b_bril.html#ill-use-a-generator",
    "title": "Overview of Bril",
    "section": "I’ll use a generator",
    "text": "I’ll use a generator\nIn Python, a generator is an iterator that is defined with a function using the yield statement.\n\nProduce items only once\nDo not store all the items in memory\nWhen items from the generator are requested, the function executes until it reaches a yield statement, which produces the next value. Execution then pauses, preserving the function’s state, until the next item is requested.\n\n\nGiven a list of Bril instructions, generate a sequence of instruction lists representing the basic blocks in the program.\nEvery instruction in instr will show up in exactly one block. Jump and branch instructions may only appear at the end of a block, and control can transfer only to the top of a basic block—so labels can only appear at the start of a basic block. Basic blocks may not be empty.\n\n\n    #Instructions that terminate a basic block.\n    TERMINATORS = 'br', 'jmp', 'ret'\n\n    def form_blocks(instrs):\n        # Start with an empty block.\n        cur_block = []\n\n        for instr in instrs:\n            if 'op' in instr:  # It's an instruction.\n                # Add the instruction to the currently-being-formed block.\n                cur_block.append(instr)\n\n                # If this is a terminator (branching instruction), it's the\n                # last instruction in the block. Finish this block and\n                # start a new one.\n                if instr['op'] in TERMINATORS:\n                    yield cur_block\n                    cur_block = []\n            \n            else:  # It's a label.\n                # End the block here (if it contains anything).\n                if cur_block:\n                    yield cur_block\n\n                # Start a new block with the label.\n                cur_block = [instr]\n\n        # Produce the final block, if any.\n        if cur_block:\n            yield cur_block"
  },
  {
    "objectID": "lectures/02b_bril.html#as-a-test-lets-print-out-the-blocks",
    "href": "lectures/02b_bril.html#as-a-test-lets-print-out-the-blocks",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\ndef print_blocks(bril):\n    \"\"\"Given a Bril program, print out its basic blocks.\n    \"\"\"\n\n\n    func = bril['functions'][0]  # We only process one function.\n    for block in form_blocks(func['instrs']):\n        # Mark the block.\n        leader = block[0]\n        if 'label' in leader:\n            print( f\"block {leader['label']}\")\n            block = block[1:]  # Hide the label\n        else:\n            print('anonymous block:')\n\n        # Print the instructions.\n        for instr in block:\n            print(instr)\n\nprint_blocks(bril_program)\n\nanonymous block:\n{'op': 'const', 'type': 'int', 'dest': 'v0', 'value': 1}\n{'op': 'const', 'type': 'int', 'dest': 'v1', 'value': 2}\n{'op': 'add', 'type': 'int', 'dest': 'v2', 'args': ['v0', 'v1']}\n{'op': 'print', 'args': ['v2']}\n\n\nthis test program has one block so pretty easy"
  },
  {
    "objectID": "lectures/02b_bril.html#lets-try-a-second-example-with-a-jmp",
    "href": "lectures/02b_bril.html#lets-try-a-second-example-with-a-jmp",
    "title": "Overview of Bril",
    "section": "lets try a second example with a jmp",
    "text": "lets try a second example with a jmp\n@main {\n  v: int = const 4;\n  jmp .somewhere;\n  v: int = const 2;\n.somewhere:\n  print v;\n}"
  },
  {
    "objectID": "lectures/02b_bril.html#running-commands-inside-python",
    "href": "lectures/02b_bril.html#running-commands-inside-python",
    "title": "Overview of Bril",
    "section": "running commands inside python",
    "text": "running commands inside python\nGitHub Copilot: subprocess.check_output is a function in Python’s subprocess module that runs a command with arguments and returns its output as a byte string. If the command exits with a non-zero exit status, it raises a CalledProcessError, which includes the exit status and output of the command. This function is useful for capturing the output of a command for further processing in Python.\n\n\nimport subprocess\n\n# Run a command and capture its output\noutput = subprocess.check_output(['ls', '-l'])\n\n# Convert the byte string to a regular string (assuming UTF-8 encoding)\noutput_str = output.decode('utf-8')\n\nprint(output_str)\n\ntotal 708\n-rw-r--r-- 1 runner docker  8468 Jul 25 16:51 010_compiler_overview.qmd\n-rw-r--r-- 1 runner docker  3632 Jul 25 16:51 01a_performance_measurement.qmd\n-rw-r--r-- 1 runner docker 39165 Jul 25 16:52 02a_representation.html\n-rw-r--r-- 1 runner docker  7445 Jul 25 16:51 02a_representation.qmd\n-rw-r--r-- 1 runner docker 11870 Jul 25 16:51 02b_bril.qmd\n-rw-r--r-- 1 runner docker 20635 Jul 25 16:52 02b_bril.quarto_ipynb\n-rw-r--r-- 1 runner docker  6970 Jul 25 16:51 03_local.qmd\n-rw-r--r-- 1 runner docker  7883 Jul 25 16:51 03b_local_value_numbering.qmd\n-rw-r--r-- 1 runner docker 43947 Jul 25 16:52 04_data_flow.html\n-rw-r--r-- 1 runner docker 10538 Jul 25 16:51 04_data_flow.qmd\n-rw-r--r-- 1 runner docker  9950 Jul 25 16:51 05_global.qmd\n-rw-r--r-- 1 runner docker  4856 Jul 25 16:51 05b_licm.qmd\n-rw-r--r-- 1 runner docker  3129 Jul 25 16:51 05c_pre.qmd\n-rw-r--r-- 1 runner docker 76433 Jul 25 16:52 06_ssa.html\n-rw-r--r-- 1 runner docker 16394 Jul 25 16:51 06_ssa.qmd\n-rwxr-xr-x 1 runner docker 29710 Jul 25 16:51 07_llvm.ipynb\n-rw-r--r-- 1 runner docker  5672 Jul 25 16:51 08_classic_loop_ops.qmd\n-rwxr-xr-x 1 runner docker 14017 Jul 25 16:51 09_poly.qmd\n-rw-r--r-- 1 runner docker   283 Jul 25 16:51 100_mlir.qmd\n-rw-r--r-- 1 runner docker 20103 Jul 25 16:52 110_whole_program.html\n-rw-r--r-- 1 runner docker   301 Jul 25 16:51 110_whole_program.qmd\n-rw-r--r-- 1 runner docker   297 Jul 25 16:51 12_memory.qmd\n-rw-r--r-- 1 runner docker 16058 Jul 25 16:51 13_dynamic_compilers.qmd\n-rw-r--r-- 1 runner docker 10097 Jul 25 16:51 14_gpu_compilers.qmd\n-rw-r--r-- 1 runner docker  4595 Jul 25 16:51 errors\ndrwxr-xr-x 2 runner docker  4096 Jul 25 16:51 images\ndrwxr-xr-x 2 runner docker  4096 Jul 25 16:51 papers\n-rw-r--r-- 1 runner docker 38227 Jul 25 16:52 ra-checking.html\n-rw-r--r-- 1 runner docker  8207 Jul 25 16:51 ra-checking.qmd\n-rw-r--r-- 1 runner docker 46253 Jul 25 16:52 revealjs_02a_representation.qmd.html\n-rw-r--r-- 1 runner docker 46472 Jul 25 16:52 revealjs_04_data_flow.qmd.html\n-rw-r--r-- 1 runner docker 56558 Jul 25 16:52 revealjs_06_ssa.qmd.html\n-rw-r--r-- 1 runner docker 33153 Jul 25 16:52 revealjs_110_whole_program.qmd.html\n-rw-r--r-- 1 runner docker 43792 Jul 25 16:52 revealjs_ra-checking.qmd.html"
  },
  {
    "objectID": "lectures/02b_bril.html#print-the-blocks",
    "href": "lectures/02b_bril.html#print-the-blocks",
    "title": "Overview of Bril",
    "section": "print the blocks",
    "text": "print the blocks\n\nimport json \nimport os\nimport subprocess\n\nresult =  subprocess.check_output('bril2json &lt; images/jmp.bril', shell=True)\ntest2json = json.loads(result)\nprint_blocks(test2json)\n\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}\n{'labels': ['somewhere'], 'op': 'jmp'}\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}\nblock somewhere\n{'args': ['v'], 'op': 'print'}"
  },
  {
    "objectID": "lectures/02b_bril.html#the-map-label-names-to-blocks",
    "href": "lectures/02b_bril.html#the-map-label-names-to-blocks",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\nfrom collections import OrderedDict\n\n\ndef block_map(blocks):\n    \"\"\"Given a sequence of basic blocks, which are lists of instructions,\n    produce a `OrderedDict` mapping names to blocks.\n\n    The name of the block comes from the label it starts with, if any.\n    Anonymous blocks, which don't start with a label, get an\n    automatically generated name. Blocks in the mapping have their\n    labels removed.\n    \"\"\"\n    by_name = OrderedDict()\n\n    for block in blocks:\n        # Generate a name for the block.\n        if 'label' in block[0]:\n            # The block has a label. Remove the label but use it for the\n            # block's name.\n            name = block[0]['label']\n            block = block[1:]\n        else:\n            # Make up a new name for this anonymous block.\n            name = f'gen_bk_{len(by_name)}'\n\n        # Add the block to the mapping.\n        by_name[name] = block\n\n    return by_name\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\nfor (name, instrs) in od.items():\n    print (name, instrs)\n\ngen_bk_0 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}]\ngen_bk_1 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}]\nsomewhere [{'args': ['v'], 'op': 'print'}]"
  },
  {
    "objectID": "lectures/02b_bril.html#the-cfg-given-the-block-map-pseudo-code",
    "href": "lectures/02b_bril.html#the-cfg-given-the-block-map-pseudo-code",
    "title": "Overview of Bril",
    "section": "the cfg given the block map (pseudo code)",
    "text": "the cfg given the block map (pseudo code)\nout cfg = {} \n# map label -&gt; list of labels the successors of the block\n\nfor i,block in enumerate(blocks)  # blocks is a ordereddict \n    last = block[i]  # last instruction\n    if last is jmp:\n        cfg[block_name] = jmp.dest\n    elif last is br:\n        cfg[block.name] = [ last.if_label, last.else_label]\n    else\n        # fall through\n        cfg[block_name] = blocks[i+1].name  ## special case for last block"
  },
  {
    "objectID": "lectures/02b_bril.html#cfg",
    "href": "lectures/02b_bril.html#cfg",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\ndef get_cfg(ordered_blocks):\n    cfg = {}\n\n    labels = list(ordered_blocks.keys())\n\n    for i, (block_name, block) in enumerate(ordered_blocks.items()):\n        last = block[-1]\n        op = last['op']\n\n        if op == 'jmp':\n            cfg[block_name] = last['labels']\n        elif op == 'br':\n            cfg[block_name] = last['labels']\n        else:\n            if i+1 &lt; len(labels):  # last block does not fall through\n                cfg[block_name] = [labels[i+1]]\n            else:\n                cfg[block_name] = []\n    return cfg\n\n\nblks = form_blocks(test2json['functions'][0]['instrs'])\nod = block_map(blks)\ncfg = get_cfg(od)\n\nprint(cfg)\n\n{'gen_bk_0': ['somewhere'], 'gen_bk_1': ['somewhere'], 'somewhere': []}"
  },
  {
    "objectID": "lectures/02b_bril.html#graph",
    "href": "lectures/02b_bril.html#graph",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#how-to-use-bril-with-real-code",
    "href": "lectures/revealjs_02b_bril.qmd.html#how-to-use-bril-with-real-code",
    "title": "Overview of Bril",
    "section": "How to use Bril with real code",
    "text": "How to use Bril with real code\n\nBril is very simple, very regular, ir.\nBril can be extended easily.\nBril has lots of tools and examples.\nBril tools are written in lots of languages so setup can be messy"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\nBril is written in JSON format. Almost all programming languages have a way to read json.\n\nimport json\nimport subprocess\nimport os \n\n# read from a file \nwith open(\"images/add.json\",\"r\") as f:\n    bril_program = json.load(f)\n\n# read from a pipe\n# bril_program = json.load(sys.stdin)\n    \nprint(json.dumps(bril_program, \n    indent=2))"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.-output",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-look-at-a-bril-program.-output",
    "title": "Overview of Bril",
    "section": "Lets look at a bril program.",
    "text": "Lets look at a bril program.\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v0\",\n          \"value\": 1\n        },\n        {\n          \"op\": \"const\",\n          \"type\": \"int\",\n          \"dest\": \"v1\",\n          \"value\": 2\n        },\n        {\n          \"op\": \"add\",\n          \"type\": \"int\",\n          \"dest\": \"v2\",\n          \"args\": [\n            \"v0\",\n            \"v1\"\n          ]\n        },\n        {\n          \"op\": \"print\",\n          \"args\": [\n            \"v2\"\n          ]\n        }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#formatted",
    "href": "lectures/revealjs_02b_bril.qmd.html#formatted",
    "title": "Overview of Bril",
    "section": "Formatted",
    "text": "Formatted\n{\n  \"functions\": [\n    {\n      \"instrs\": [\n        {\"dest\": \"v0\", \"op\": \"const\",\"type\": \"int\",\"value\": 1},\n        {\"dest\": \"v1\", \"op\": \"const\",\"type\": \"int\",\"value\": 2},\n        {\"dest\": \"v2\", \"op\": \"add\",  \"type\": \"int\",\"args\": [\"v0\",\"v1\"],},\n                       \"op\": \"print\",\"args\": [ \"v2\"],}],\n      \"name\": \"main\",\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#getting-started",
    "href": "lectures/revealjs_02b_bril.qmd.html#getting-started",
    "title": "Overview of Bril",
    "section": "getting started",
    "text": "getting started\nlinks:\n\nLanguage specification\ngithub site"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-1-clone-the-bril-repo-on-a-linux-or-wsl-machine",
    "title": "Overview of Bril",
    "section": "step 1 clone the bril repo on a linux or wsl machine",
    "text": "step 1 clone the bril repo on a linux or wsl machine\ngit clone https://github.com/sampsyo/bril.git"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-2-support-packages",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-2-support-packages",
    "title": "Overview of Bril",
    "section": "step 2 support packages",
    "text": "step 2 support packages\n\ndeno is the runtime for typescript/javascript\n\ncurl -fsSL https://deno.land/install.sh | sh\non my ubuntu machine ‘sudo snap install deno’ also worked\nyou may need to add $HOME/.deno/bin to your $PATH.\n\nflit a python package manager\n\npython3 -m pip install flit"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-3-install-the-bril-interpreter-and-the-typescript-to-bril-compiler",
    "title": "Overview of Bril",
    "section": "step 3 install the bril interpreter, and the typescript to bril compiler",
    "text": "step 3 install the bril interpreter, and the typescript to bril compiler\ncd bril\ndeno install brili.ts \ndeno install --allow-env --allow-read ts2bril.ts"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#running-the-interpreter",
    "href": "lectures/revealjs_02b_bril.qmd.html#running-the-interpreter",
    "title": "Overview of Bril",
    "section": "running the interpreter",
    "text": "running the interpreter\nbrili &lt;images/add.json\nbrili -p &lt;images/add.json\nthe -p flag turns on profiling"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#text-to-json-and-back",
    "href": "lectures/revealjs_02b_bril.qmd.html#text-to-json-and-back",
    "title": "Overview of Bril",
    "section": "text to json and back",
    "text": "text to json and back\nThere are programs bril2txt and bril2json that make it easy to convert. Keep in mind that the json format is Bril and thats where you will do all the work.\ninstall text tools\ncd bril-txt\nflit install --symlink --user\nrun json to text\nbril2txt &lt; images/add.json"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#connect-tools-via-pipes",
    "href": "lectures/revealjs_02b_bril.qmd.html#connect-tools-via-pipes",
    "title": "Overview of Bril",
    "section": "connect tools via pipes",
    "text": "connect tools via pipes\ncat images/add.json'\nbril2txt &lt; images/add.json | bril2json"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#other-tools",
    "href": "lectures/revealjs_02b_bril.qmd.html#other-tools",
    "title": "Overview of Bril",
    "section": "Other tools",
    "text": "Other tools\nThere is also a fast interpreter written in Rust see docs for installation"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#turnt-tiny-unified-runner-and-tester",
    "href": "lectures/revealjs_02b_bril.qmd.html#turnt-tiny-unified-runner-and-tester",
    "title": "Overview of Bril",
    "section": "turnt Tiny unified runner and tester",
    "text": "turnt Tiny unified runner and tester\nBril uses turnt as a test tool\nTurnt is a simple snapshot testing tool inspired by LLVM’s lit. It’s good for testing things that translate text files to other text files, like compilers. The idea is that each test is one input file, and you want to run a command and check that it still matches the saved output file.\npip install –user turnt\nAs you think about your projects, you might consider adding a new tool. you can setup Bril on your local linux (can be wsl) machine"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#gen-cfg",
    "href": "lectures/revealjs_02b_bril.qmd.html#gen-cfg",
    "title": "Overview of Bril",
    "section": "Gen CFG",
    "text": "Gen CFG\nLets write a sample program - that generates the cfg\nHow would you do that?\n\nI’ll do this in two steps\n\nfind all the basic blocks\nadd all the cfg edges\n\nYou can also do this in a single step, adding cfg edges as soon as you reach the successor node."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#basic-blocks-from-a-list-of-instructions-",
    "href": "lectures/revealjs_02b_bril.qmd.html#basic-blocks-from-a-list-of-instructions-",
    "title": "Overview of Bril",
    "section": "basic blocks from a list of instructions-",
    "text": "basic blocks from a list of instructions-\nkeep adding instructions till we get to a terminator or a label (do we add labels?)\n\nin: list of instrs \nout: list of lists of instrs \n \nblocks = []\ncurr_block = []\nfor each instr in list \n    if the instruction is not a label put it on curr_block\n    if instr is a label or terminator \n       put curr_block on blocks\n       curr_block = []\n \n if curr_block is not empty add it to blocks\n return blocks \ntwo labels in a row do not need another block"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#step-2-add-edges",
    "href": "lectures/revealjs_02b_bril.qmd.html#step-2-add-edges",
    "title": "Overview of Bril",
    "section": "step 2 add edges",
    "text": "step 2 add edges\nfind cfg: in: is bril program in json \nfor each function find the list of basic blocks\nfor each basic block\n   get last_instr \n   if it is a terminator  br/jmp/ret \n     add edge from current block to successor  \n    --- what do we want to do with call? \n   else it is a fall through\n      add edge to next block\n\nwe need a map (block_map) label-&gt;block so we can add edges for blocks that end in br/jmp - can build this while getting the blocks or we can put the label as the first instruction\nhow do we handle fall through?\nwhat about a return\nif every block ends with a terminator, and every block has a label, then no fall through case\nwhat happens if try to delete the terminator (because the block never executes)"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#code",
    "href": "lectures/revealjs_02b_bril.qmd.html#code",
    "title": "Overview of Bril",
    "section": "code",
    "text": "code\nI’ll use a python data structure called OrderedDict, when you iterate over the items in a ordered dict, they come back in the order that they were installed."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#ill-use-a-generator",
    "href": "lectures/revealjs_02b_bril.qmd.html#ill-use-a-generator",
    "title": "Overview of Bril",
    "section": "I’ll use a generator",
    "text": "I’ll use a generator\nIn Python, a generator is an iterator that is defined with a function using the yield statement.\n\nProduce items only once\nDo not store all the items in memory\nWhen items from the generator are requested, the function executes until it reaches a yield statement, which produces the next value. Execution then pauses, preserving the function’s state, until the next item is requested."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#as-a-test-lets-print-out-the-blocks",
    "title": "Overview of Bril",
    "section": "as a test, lets print out the blocks",
    "text": "as a test, lets print out the blocks\n\n\nanonymous block:\n{'op': 'const', 'type': 'int', 'dest': 'v0', 'value': 1}\n{'op': 'const', 'type': 'int', 'dest': 'v1', 'value': 2}\n{'op': 'add', 'type': 'int', 'dest': 'v2', 'args': ['v0', 'v1']}\n{'op': 'print', 'args': ['v2']}\n\n\nthis test program has one block so pretty easy"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#lets-try-a-second-example-with-a-jmp",
    "href": "lectures/revealjs_02b_bril.qmd.html#lets-try-a-second-example-with-a-jmp",
    "title": "Overview of Bril",
    "section": "lets try a second example with a jmp",
    "text": "lets try a second example with a jmp\n@main {\n  v: int = const 4;\n  jmp .somewhere;\n  v: int = const 2;\n.somewhere:\n  print v;\n}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#running-commands-inside-python",
    "href": "lectures/revealjs_02b_bril.qmd.html#running-commands-inside-python",
    "title": "Overview of Bril",
    "section": "running commands inside python",
    "text": "running commands inside python\nGitHub Copilot: subprocess.check_output is a function in Python’s subprocess module that runs a command with arguments and returns its output as a byte string. If the command exits with a non-zero exit status, it raises a CalledProcessError, which includes the exit status and output of the command. This function is useful for capturing the output of a command for further processing in Python."
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#print-the-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#print-the-blocks",
    "title": "Overview of Bril",
    "section": "print the blocks",
    "text": "print the blocks\n\n\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}\n{'labels': ['somewhere'], 'op': 'jmp'}\nanonymous block:\n{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}\nblock somewhere\n{'args': ['v'], 'op': 'print'}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-map-label-names-to-blocks",
    "title": "Overview of Bril",
    "section": "the map (label names to blocks)",
    "text": "the map (label names to blocks)\n\n\ngen_bk_0 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 4}, {'labels': ['somewhere'], 'op': 'jmp'}]\ngen_bk_1 [{'dest': 'v', 'op': 'const', 'type': 'int', 'value': 2}]\nsomewhere [{'args': ['v'], 'op': 'print'}]"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#the-cfg-given-the-block-map-pseudo-code",
    "href": "lectures/revealjs_02b_bril.qmd.html#the-cfg-given-the-block-map-pseudo-code",
    "title": "Overview of Bril",
    "section": "the cfg given the block map (pseudo code)",
    "text": "the cfg given the block map (pseudo code)\nout cfg = {} \n# map label -&gt; list of labels the successors of the block\n\nfor i,block in enumerate(blocks)  # blocks is a ordereddict \n    last = block[i]  # last instruction\n    if last is jmp:\n        cfg[block_name] = jmp.dest\n    elif last is br:\n        cfg[block.name] = [ last.if_label, last.else_label]\n    else\n        # fall through\n        cfg[block_name] = blocks[i+1].name  ## special case for last block"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#cfg",
    "href": "lectures/revealjs_02b_bril.qmd.html#cfg",
    "title": "Overview of Bril",
    "section": "cfg",
    "text": "cfg\n\n\n{'gen_bk_0': ['somewhere'], 'gen_bk_1': ['somewhere'], 'somewhere': []}"
  },
  {
    "objectID": "lectures/revealjs_02b_bril.qmd.html#graph",
    "href": "lectures/revealjs_02b_bril.qmd.html#graph",
    "title": "Overview of Bril",
    "section": "graph",
    "text": "graph\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\ngen_bk_0--&gt; somewhere\ngen_bk_1 --&gt; somewhere"
  },
  {
    "objectID": "lectures/02a_representation.html",
    "href": "lectures/02a_representation.html",
    "title": "Representation of programs",
    "section": "",
    "text": "The representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot"
  },
  {
    "objectID": "lectures/02a_representation.html#how-do-we-represent-programs",
    "href": "lectures/02a_representation.html#how-do-we-represent-programs",
    "title": "Representation of programs",
    "section": "",
    "text": "The representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications.\n\nfrom graphviz import Digraph\nimport ast\nimport os \n\ndef cmd(x):\n  os.system(x)\n  \ndef ast_syntax(line):\n  return ast.dump(ast.parse(line).body[0], indent=4)\n\n  \n# Define a function to recursively add nodes to the Digraph\ndef add_node(dot, node, parent=None):\n  node_name = str(node.__class__.__name__)\n  dot.node(str(id(node)), node_name)\n  if parent:\n    dot.edge(str(id(parent)), str(id(node)))\n  for child in ast.iter_child_nodes(node):\n    add_node(dot, child, node)\n\n# Add nodes to the Digraph\n\ndef graph(line):\n  dot = Digraph()\n  add_node(dot, ast.parse(line).body[0])\n  return dot"
  },
  {
    "objectID": "lectures/02a_representation.html#concrete-syntax",
    "href": "lectures/02a_representation.html#concrete-syntax",
    "title": "Representation of programs",
    "section": "Concrete Syntax",
    "text": "Concrete Syntax\nConcrete syntax, or surface syntax, represents programs as they are written\nPrograms are text or surface syntax- just what you would type into an editor.\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction?\nHow do you understand the semantics."
  },
  {
    "objectID": "lectures/02a_representation.html#abstract-syntax",
    "href": "lectures/02a_representation.html#abstract-syntax",
    "title": "Representation of programs",
    "section": "Abstract syntax",
    "text": "Abstract syntax\nAbstract syntax represents programs as tree structures, focusing on the nodes and their connections.\n\nNodes are parts of the program,\nEdges show how they are connected.\n\nWe can write this as a list or a graph\n\n\ndef pgm():\n    value = 8\n    result = 1\n    for i in range(value):\n        result = result * i\n    print(result)"
  },
  {
    "objectID": "lectures/02a_representation.html#ast-tree-representation",
    "href": "lectures/02a_representation.html#ast-tree-representation",
    "title": "Representation of programs",
    "section": "AST tree representation",
    "text": "AST tree representation\nAn AST is a tree structure, nodes like ‘if’, ‘test’, ‘body’, assign’.\nEach node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter.\nSimple (non optimizing) compilers often use this format."
  },
  {
    "objectID": "lectures/02a_representation.html#a-more-regular-representation",
    "href": "lectures/02a_representation.html#a-more-regular-representation",
    "title": "Representation of programs",
    "section": "A more regular representation",
    "text": "A more regular representation\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\nts2bril images/toy.ts | bril2txt\n\n\n    //typescript program \n    let value = 8\n    let result = 1\n    for (let i = 0; i &lt; value;\n         i = i+1)\n    {\n        result = result * i\n    }\n    console.log(result)\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}"
  },
  {
    "objectID": "lectures/02a_representation.html#bril",
    "href": "lectures/02a_representation.html#bril",
    "title": "Representation of programs",
    "section": "bril",
    "text": "bril\n\nLooks like assembly\nno limit on registers,\nno condition codes.\nfully typed,\nno complex addressing modes.\neasy to extend"
  },
  {
    "objectID": "lectures/02a_representation.html#bril-syntax",
    "href": "lectures/02a_representation.html#bril-syntax",
    "title": "Representation of programs",
    "section": "Bril syntax",
    "text": "Bril syntax\nDeclare functions, labels, instructions\ninstruction:\n\nvariable type = opcode arguments\nopcode list of arguments\n\nForm 1, variable is the destination, like a: int = add b, c\nForm 2, no destination, like print a\nwhat is good and what is about this representation?"
  },
  {
    "objectID": "lectures/02a_representation.html#control-flow-graph-cfg-version-1",
    "href": "lectures/02a_representation.html#control-flow-graph-cfg-version-1",
    "title": "Representation of programs",
    "section": "control flow graph (CFG) (version 1)",
    "text": "control flow graph (CFG) (version 1)\nRepresentation is a directed graph.\n\nNodes are instructions,\nedges indicate possible flow of control,\none entry and one exit node."
  },
  {
    "objectID": "lectures/02a_representation.html#example-one",
    "href": "lectures/02a_representation.html#example-one",
    "title": "Representation of programs",
    "section": "Example one",
    "text": "Example one\n@main {\n    v: int = const 5;\n    print v;\n}\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]"
  },
  {
    "objectID": "lectures/02a_representation.html#second-example",
    "href": "lectures/02a_representation.html#second-example",
    "title": "Representation of programs",
    "section": "second example",
    "text": "second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\n. . .\nnotice label does not produce a node\nEasy to see a dead instruction."
  },
  {
    "objectID": "lectures/02a_representation.html#third-example",
    "href": "lectures/02a_representation.html#third-example",
    "title": "Representation of programs",
    "section": "Third example:",
    "text": "Third example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n. . .\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\n. . .\nwhich is the true edge and which is the false edge , could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside."
  },
  {
    "objectID": "lectures/02a_representation.html#cfg-cfg-form-2",
    "href": "lectures/02a_representation.html#cfg-cfg-form-2",
    "title": "Representation of programs",
    "section": "CFG (cfg form 2)",
    "text": "CFG (cfg form 2)\n\nnodes ares sequences of instructions.\njumps and branches can only be at the end of a sequence\nonly label has to be at the start\nevery instruction in the sequence executes the same number of times"
  },
  {
    "objectID": "lectures/02a_representation.html#construct-cfg",
    "href": "lectures/02a_representation.html#construct-cfg",
    "title": "Representation of programs",
    "section": "construct cfg",
    "text": "construct cfg\nwalk over the instructions:\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of \\(b\\) are the blocks \\(b_{in}\\) where there is an edge \\(b_{in}-&gt;b\\). And the successors of \\(b\\) are the \\(b_{out}\\) where \\(b-&gt;b_{out}\\) is an edge."
  },
  {
    "objectID": "lectures/02a_representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "lectures/02a_representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation of programs",
    "section": "What is an algorithm that forms a cfg",
    "text": "What is an algorithm that forms a cfg\n. . .\n\njust find all the basic blocks\nadd the control flow edges"
  },
  {
    "objectID": "lectures/02a_representation.html#pseudo-code-to-construct-cfg",
    "href": "lectures/02a_representation.html#pseudo-code-to-construct-cfg",
    "title": "Representation of programs",
    "section": "pseudo code to construct cfg",
    "text": "pseudo code to construct cfg\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#how-do-we-represent-programs",
    "href": "lectures/revealjs_02a_representation.qmd.html#how-do-we-represent-programs",
    "title": "Representation of programs",
    "section": "How do we represent programs",
    "text": "How do we represent programs\nThe representation of a program\nWhat we read in and read out when transforming a program.\nWhat kind of properties make a good representation?\nThis lecture explores different representations and their implications."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#concrete-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#concrete-syntax",
    "title": "Representation of programs",
    "section": "Concrete Syntax",
    "text": "Concrete Syntax\nConcrete syntax, or surface syntax, represents programs as they are written\nPrograms are text or surface syntax- just what you would type into an editor.\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction?\nHow do you understand the semantics."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#abstract-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#abstract-syntax",
    "title": "Representation of programs",
    "section": "Abstract syntax",
    "text": "Abstract syntax\nAbstract syntax represents programs as tree structures, focusing on the nodes and their connections.\n\nNodes are parts of the program,\nEdges show how they are connected.\n\nWe can write this as a list or a graph\n\n\ndef pgm():\n    value = 8\n    result = 1\n    for i in range(value):\n        result = result * i\n    print(result)"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#ast-tree-representation",
    "href": "lectures/revealjs_02a_representation.qmd.html#ast-tree-representation",
    "title": "Representation of programs",
    "section": "AST tree representation",
    "text": "AST tree representation\nAn AST is a tree structure, nodes like ‘if’, ‘test’, ‘body’, assign’.\nEach node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter.\nSimple (non optimizing) compilers often use this format."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#a-more-regular-representation",
    "href": "lectures/revealjs_02a_representation.qmd.html#a-more-regular-representation",
    "title": "Representation of programs",
    "section": "A more regular representation",
    "text": "A more regular representation\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\nts2bril images/toy.ts | bril2txt\n\n\n    //typescript program \n    let value = 8\n    let result = 1\n    for (let i = 0; i &lt; value;\n         i = i+1)\n    {\n        result = result * i\n    }\n    console.log(result)\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#bril",
    "href": "lectures/revealjs_02a_representation.qmd.html#bril",
    "title": "Representation of programs",
    "section": "bril",
    "text": "bril\n\nLooks like assembly\nno limit on registers,\nno condition codes.\nfully typed,\nno complex addressing modes.\neasy to extend"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#bril-syntax",
    "href": "lectures/revealjs_02a_representation.qmd.html#bril-syntax",
    "title": "Representation of programs",
    "section": "Bril syntax",
    "text": "Bril syntax\nDeclare functions, labels, instructions\ninstruction:\n\nvariable type = opcode arguments\nopcode list of arguments\n\nForm 1, variable is the destination, like a: int = add b, c\nForm 2, no destination, like print a\nwhat is good and what is about this representation?"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#control-flow-graph-cfg-version-1",
    "href": "lectures/revealjs_02a_representation.qmd.html#control-flow-graph-cfg-version-1",
    "title": "Representation of programs",
    "section": "control flow graph (CFG) (version 1)",
    "text": "control flow graph (CFG) (version 1)\nRepresentation is a directed graph.\n\nNodes are instructions,\nedges indicate possible flow of control,\none entry and one exit node."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#example-one",
    "href": "lectures/revealjs_02a_representation.qmd.html#example-one",
    "title": "Representation of programs",
    "section": "Example one",
    "text": "Example one\n@main {\n    v: int = const 5;\n    print v;\n}\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 10\n%%| fig-height: 9\n\nflowchart LR\nA[const] --&gt; B[print]"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#second-example",
    "href": "lectures/revealjs_02a_representation.qmd.html#second-example",
    "title": "Representation of programs",
    "section": "second example",
    "text": "second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#third-example",
    "href": "lectures/revealjs_02a_representation.qmd.html#third-example",
    "title": "Representation of programs",
    "section": "Third example:",
    "text": "Third example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n%%| fig-width: 6.5\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\n\n\nwhich is the true edge and which is the false edge , could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#cfg-cfg-form-2",
    "href": "lectures/revealjs_02a_representation.qmd.html#cfg-cfg-form-2",
    "title": "Representation of programs",
    "section": "CFG (cfg form 2)",
    "text": "CFG (cfg form 2)\n\nnodes ares sequences of instructions.\njumps and branches can only be at the end of a sequence\nonly label has to be at the start\nevery instruction in the sequence executes the same number of times"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#construct-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#construct-cfg",
    "title": "Representation of programs",
    "section": "construct cfg",
    "text": "construct cfg\nwalk over the instructions:\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of \\(b\\) are the blocks \\(b_{in}\\) where there is an edge \\(b_{in}-&gt;b\\). And the successors of \\(b\\) are the \\(b_{out}\\) where \\(b-&gt;b_{out}\\) is an edge."
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation of programs",
    "section": "What is an algorithm that forms a cfg",
    "text": "What is an algorithm that forms a cfg\n\n\njust find all the basic blocks\nadd the control flow edges"
  },
  {
    "objectID": "lectures/revealjs_02a_representation.qmd.html#pseudo-code-to-construct-cfg",
    "href": "lectures/revealjs_02a_representation.qmd.html#pseudo-code-to-construct-cfg",
    "title": "Representation of programs",
    "section": "pseudo code to construct cfg",
    "text": "pseudo code to construct cfg\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []"
  },
  {
    "objectID": "lectures/06_ssa.html",
    "href": "lectures/06_ssa.html",
    "title": "Static Single Assignment",
    "section": "",
    "text": "A variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program"
  },
  {
    "objectID": "lectures/06_ssa.html#static-single-assignment-ssa",
    "href": "lectures/06_ssa.html#static-single-assignment-ssa",
    "title": "Static Single Assignment",
    "section": "",
    "text": "A variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program"
  },
  {
    "objectID": "lectures/06_ssa.html#ssa",
    "href": "lectures/06_ssa.html#ssa",
    "title": "Static Single Assignment",
    "section": "ssa",
    "text": "ssa\nin SSA we change our IR so that every variable has exactly one definition in the program (each variable is assigned only once). The name SSA means statically there is only a single assignment per variable."
  },
  {
    "objectID": "lectures/06_ssa.html#the-ssa-philosophy",
    "href": "lectures/06_ssa.html#the-ssa-philosophy",
    "title": "Static Single Assignment",
    "section": "The SSA Philosophy",
    "text": "The SSA Philosophy\nIn addition to a language form, SSA is also a philosophy! It can fundamentally change the way you think about programs. In the SSA philosophy:\n\ndefinitions == variables\ninstructions == values\narguments == data flow graph edges\n\n\nIn LLVM, for example, instructions do not refer to argument variables by name—an argument is a pointer to defining instruction.\nStatic means in the text, not in the execution."
  },
  {
    "objectID": "lectures/06_ssa.html#an-example",
    "href": "lectures/06_ssa.html#an-example",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n\nvariable i has two static assignments 0 and 4, so this program is not in SSA\nVariable s has two static assignments, x has one static assignment but x has lots of dynamic assignments (when the program executes)"
  },
  {
    "objectID": "lectures/06_ssa.html#straight-line-code",
    "href": "lectures/06_ssa.html#straight-line-code",
    "title": "Static Single Assignment",
    "section": "straight line code",
    "text": "straight line code\nWe call a program without branches a piece of straight line code.\n    @main {\n      a: int = const 4;\n      b: int = const 2;\n      a: int = add a b;\n      b: int = add a b;\n      print b;\n    }\n. . .\nIts easy to see how to convert straight line code into ssa\n    @main {\n      a.1: int = const 4;\n      b.1: int = const 2;\n      a.2: int = add a.1 b.1;\n      b.2: int = add a.2 b.1;\n      print b.2;\n    }"
  },
  {
    "objectID": "lectures/06_ssa.html#pseudo-code-for-one-basic-block",
    "href": "lectures/06_ssa.html#pseudo-code-for-one-basic-block",
    "title": "Static Single Assignment",
    "section": "pseudo code for one basic block",
    "text": "pseudo code for one basic block\nfor each variable a: \n    Count[a] = 0 \n    Stack[a] = [0]\n\nrename_basic_block(B): \n    for each instruction S in block B:\n        for each use of a argument x in S: \n            i = top(Stack[x]) \n            replace the use of x with $x_i$\n            \n        for each variable a that S defines (a dest)\n            count[a] = Count[a] + 1 \n            i = Count[a]             \n            push i onto Stack[a]             \n            replace definition of a with $a_i$ \nWe don’t need the stack here but we will need it later.\n\nOf course, things will get a little more complicated when there is control flow. And because real machines are not SSA, using separate variables (i.e., memory locations and registers) for everything is bound to be inefficient.\nThe idea in SSA is to convert general programs into SSA form, do all our optimization there, and then convert back to a standard mutating form before we generate backend code."
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes",
    "href": "lectures/06_ssa.html#phi-nodes",
    "title": "Static Single Assignment",
    "section": "phi-Nodes",
    "text": "phi-Nodes\nJust renaming assignments will quickly run into problems. Consider this program:\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\nWhich “version” of a should we use in the print statement?"
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes-1",
    "href": "lectures/06_ssa.html#phi-nodes-1",
    "title": "Static Single Assignment",
    "section": "phi nodes",
    "text": "phi nodes\nTo match the expressiveness of unrestricted programs, SSA adds a new kind of instruction: a phi-node.\nphi-nodes are flow-sensitive copy instructions: they get a value from one of several variables, depending on which incoming CFG edge was most recently taken to get to them."
  },
  {
    "objectID": "lectures/06_ssa.html#phi-nodes-in-bril",
    "href": "lectures/06_ssa.html#phi-nodes-in-bril",
    "title": "Static Single Assignment",
    "section": "phi nodes in Bril",
    "text": "phi nodes in Bril\nIn Bril, a phi-node appears as a phi instruction:\na.4: int = phi .left a.2 .right a.3;\nThe phi instruction chooses between any number of variables, and it picks between them based on labels. If the program most recently executed a basic block with the given label, then the phi instruction takes its value from the corresponding variable."
  },
  {
    "objectID": "lectures/06_ssa.html#back-to-the-example",
    "href": "lectures/06_ssa.html#back-to-the-example",
    "title": "Static Single Assignment",
    "section": "back to the example",
    "text": "back to the example\nYou can write the above program in SSA like this:\n    @main(cond: bool) {\n    .entry:\n        a.1: int = const 47;\n        br cond .left .right;\n    .left:\n        a.2: int = add a.1 a.1;\n        jmp .exit;\n    .right:\n        a.3: int = mul a.1 a.1;\n        jmp .exit;\n    .exit:\n        a.4: int = phi .left a.2 .right a.3;\n        print a.4;\n    }"
  },
  {
    "objectID": "lectures/06_ssa.html#bril-in-ssa",
    "href": "lectures/06_ssa.html#bril-in-ssa",
    "title": "Static Single Assignment",
    "section": "Bril in SSA",
    "text": "Bril in SSA\nBril has an SSA extension It adds support for a phi instruction. Beyond that, SSA form is just a restriction on the normal expressiveness of Bril—if you solemnly promise never to assign statically to the same variable twice, you are writing “SSA Bril.”\nThe reference interpreter has built-in support for phi, so you can execute your SSA-form Bril programs without fuss."
  },
  {
    "objectID": "lectures/06_ssa.html#getting-out-of-ssa",
    "href": "lectures/06_ssa.html#getting-out-of-ssa",
    "title": "Static Single Assignment",
    "section": "Getting out of ssa",
    "text": "Getting out of ssa\nCompilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies."
  },
  {
    "objectID": "lectures/06_ssa.html#an-example-1",
    "href": "lectures/06_ssa.html#an-example-1",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n\n\n\nwe cannot put instructions on edges, but we can add to prev block"
  },
  {
    "objectID": "lectures/06_ssa.html#critical-edges",
    "href": "lectures/06_ssa.html#critical-edges",
    "title": "Static Single Assignment",
    "section": "critical edges",
    "text": "critical edges\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\n\nb2 = b0?\n\n\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors. This should remind you of adding a preheader to a loop"
  },
  {
    "objectID": "lectures/06_ssa.html#critical-edge-splitting",
    "href": "lectures/06_ssa.html#critical-edge-splitting",
    "title": "Static Single Assignment",
    "section": "critical edge splitting",
    "text": "critical edge splitting\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge."
  },
  {
    "objectID": "lectures/06_ssa.html#converting-to-ssa---very-simple-scheme",
    "href": "lectures/06_ssa.html#converting-to-ssa---very-simple-scheme",
    "title": "Static Single Assignment",
    "section": "Converting to SSA - Very simple scheme",
    "text": "Converting to SSA - Very simple scheme\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nWhere do we need phi-functions?\nWhich variables\n. . .\nAt the merge (join) node\nb"
  },
  {
    "objectID": "lectures/06_ssa.html#scheme",
    "href": "lectures/06_ssa.html#scheme",
    "title": "Static Single Assignment",
    "section": "scheme",
    "text": "scheme\nconditions: phi-function for variable b at node z\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other."
  },
  {
    "objectID": "lectures/06_ssa.html#scheme-part-2",
    "href": "lectures/06_ssa.html#scheme-part-2",
    "title": "Static Single Assignment",
    "section": "scheme part 2",
    "text": "scheme part 2\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work"
  },
  {
    "objectID": "lectures/06_ssa.html#fast-methods",
    "href": "lectures/06_ssa.html#fast-methods",
    "title": "Static Single Assignment",
    "section": "fast methods",
    "text": "fast methods\nTo convert to SSA, we want to insert phi-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need phi-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition?\nThe dominance frontier!"
  },
  {
    "objectID": "lectures/06_ssa.html#an-almost-linear-method",
    "href": "lectures/06_ssa.html#an-almost-linear-method",
    "title": "Static Single Assignment",
    "section": "an almost linear method",
    "text": "an almost linear method\nWe do it in two steps.\n\ninsert phi-nodes:\nrename variables:\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\na[x=]\na--&gt;b\na--&gt; e\na--&gt; i\n\nb--&gt;c\nc--- c\nc--&gt; d\ne--&gt; f[\"f\n  x = \"]\ne--&gt; g\ng--&gt; h\nf--&gt; h\nh--&gt;l\nf--&gt; d\nh--&gt; e\ni--&gt; k\ni--&gt; j\nj--&gt; k\nk--&gt; l\nd--&gt; l\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\na[x=]\na--&gt;b\na--&gt; e\na--&gt; i\n\nb--&gt;c\nc--- c\nc--&gt; d\ne--&gt; f[\"f\n  x = \"]\ne--&gt; g\ng--&gt; h\nf--&gt; h\nh--&gt;l\nf--&gt; d\nh--&gt; e\ni--&gt; k\ni--&gt; j\nj--&gt; k\nk--&gt; l\nd--&gt; l\n\n\n\n\n\n\n\n\nWe need phi functions for this def of x in d and h, where else? 3 more\n\n\n. . .\nwe need to iterate and keep adding phi nodes\n\nfor each node in the cfg \n   for each variable with a dest in node\n     add node to Defs[v]   # Blocks where v is assigned.\n\nfor each v in vars:\n    W = Defs[v]\n    while W is not empty\n      remove a node n from w\n         for block in DF[n]:  # Dominance frontier.\n           Add a phi-node to block,\n             unless we have done so already.\n           Add block to W (because it now writes to v),\n             unless it's already in there.\n. . .\nSince we keep adding nodes to W how do we know this terminates?"
  },
  {
    "objectID": "lectures/06_ssa.html#rename-variables",
    "href": "lectures/06_ssa.html#rename-variables",
    "title": "Static Single Assignment",
    "section": "rename variables:",
    "text": "rename variables:\nrename(n):\n  rename_basic_block(n)  # from before \n  for each successor Y of n, where n is the jth pred of Y\n    for each phi-function f in Y where the operand of f is 'a'\n      i = top(stack[a])\n      replace jth operand wit a_i\n  for each child of X of n (in the dominator tree)\n    rename(X)\n    for each instruction S in n\n       pop stack(S.dest)\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\n\nL5--&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3"
  },
  {
    "objectID": "lectures/06_ssa.html#what-is-the-dominator-tree",
    "href": "lectures/06_ssa.html#what-is-the-dominator-tree",
    "title": "Static Single Assignment",
    "section": "What is the dominator tree?",
    "text": "What is the dominator tree?\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/06_ssa.html#dominance-frontiers",
    "href": "lectures/06_ssa.html#dominance-frontiers",
    "title": "Static Single Assignment",
    "section": "dominance frontiers",
    "text": "dominance frontiers\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/06_ssa.html#add-phi-nodes",
    "href": "lectures/06_ssa.html#add-phi-nodes",
    "title": "Static Single Assignment",
    "section": "add phi nodes",
    "text": "add phi nodes\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3"
  },
  {
    "objectID": "lectures/06_ssa.html#the-arity-of-phi-functions",
    "href": "lectures/06_ssa.html#the-arity-of-phi-functions",
    "title": "Static Single Assignment",
    "section": "The arity of phi-functions",
    "text": "The arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\ndoing dead code elimination pruned ssa form"
  },
  {
    "objectID": "lectures/06_ssa.html#making-use-of-ssa-form",
    "href": "lectures/06_ssa.html#making-use-of-ssa-form",
    "title": "Static Single Assignment",
    "section": "making use of ssa form",
    "text": "making use of ssa form\nOur previous analyses always used a (variable, program point), but in ssa these are the same"
  },
  {
    "objectID": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "href": "lectures/06_ssa.html#dead-code-elimination-in-ssa",
    "title": "Static Single Assignment",
    "section": "dead code elimination in ssa",
    "text": "dead code elimination in ssa\nwhile there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]"
  },
  {
    "objectID": "lectures/06_ssa.html#sparse-constant-prop",
    "href": "lectures/06_ssa.html#sparse-constant-prop",
    "title": "Static Single Assignment",
    "section": "sparse constant prop",
    "text": "sparse constant prop\nwe define a partial order on constats, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is any\n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn"
  },
  {
    "objectID": "lectures/06_ssa.html#what-order-do-we-process-nodes",
    "href": "lectures/06_ssa.html#what-order-do-we-process-nodes",
    "title": "Static Single Assignment",
    "section": "What order do we process nodes?",
    "text": "What order do we process nodes?\nbecause the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a1,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1"
  },
  {
    "objectID": "lectures/06_ssa.html#walking-the-dominator-tree-b0---b1",
    "href": "lectures/06_ssa.html#walking-the-dominator-tree-b0---b1",
    "title": "Static Single Assignment",
    "section": "walking the dominator tree b0 -> b1",
    "text": "walking the dominator tree b0 -&gt; b1\n\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a0,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 -  1 (only one input defined)\nb0  - any\na2 -  2\nupdate the uses of a2 - the phi\na1 -  any \n\nupdate the uses of a1 \nno change"
  },
  {
    "objectID": "lectures/06_ssa.html#converting-from-ssa",
    "href": "lectures/06_ssa.html#converting-from-ssa",
    "title": "Static Single Assignment",
    "section": "Converting from SSA",
    "text": "Converting from SSA\nEventually, we need to convert out of SSA form to generate efficient code for real machines that don’t have phi-nodes and do have finite space for variable storage."
  },
  {
    "objectID": "lectures/06_ssa.html#basic-algorithm",
    "href": "lectures/06_ssa.html#basic-algorithm",
    "title": "Static Single Assignment",
    "section": "basic algorithm",
    "text": "basic algorithm\nThe basic algorithm is pretty straightforward. If you have a phi-node:\nv = phi .l1 x .l2 y;\nThen there must be assignments to x and y (recursively) preceding this statement in the CFG.\nThe paths from x to the phi-containing block and from y to the same block must “converge” at that block. So insert code into the phi-containing block’s immediate predecessors along each of those two paths: one that does v = id x and one that does v = id y. Then you can delete the phi instruction."
  },
  {
    "objectID": "lectures/06_ssa.html#extra-copies",
    "href": "lectures/06_ssa.html#extra-copies",
    "title": "Static Single Assignment",
    "section": "extra copies",
    "text": "extra copies\nThis basic approach can introduce some redundant copying. (Take a look at the code it generates after you implement it!) Non-SSA copy propagation optimization can work well as a post-processing step. For a more extensive take on how to translate out of SSA efficiently, see “Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al."
  },
  {
    "objectID": "lectures/06_ssa.html#overlap",
    "href": "lectures/06_ssa.html#overlap",
    "title": "Static Single Assignment",
    "section": "overlap",
    "text": "overlap\nits possible that an optimization can give overlapping phi-functions\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1,x3)\ny2 = phi(y1, y3)\n  z = x2\n  x3 = y2\n  y3= z\n  if() go to b1"
  },
  {
    "objectID": "lectures/06_ssa.html#optimize-it",
    "href": "lectures/06_ssa.html#optimize-it",
    "title": "Static Single Assignment",
    "section": "optimize it",
    "text": "optimize it\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1, y2)\ny2 = phi(y1, x2)\n  if() go to b1"
  },
  {
    "objectID": "lectures/06_ssa.html#lost-the-temp-this-is-called-the-swap-problem",
    "href": "lectures/06_ssa.html#lost-the-temp-this-is-called-the-swap-problem",
    "title": "Static Single Assignment",
    "section": "lost the temp (this is called the swap problem)",
    "text": "lost the temp (this is called the swap problem)\nif we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nphi nodes execute all at once - not one at a time\nSome SSA slides from Todd Mowry at CMU"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#static-single-assignment-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#static-single-assignment-ssa",
    "title": "Static Single Assignment",
    "section": "Static single assignment (SSA)",
    "text": "Static single assignment (SSA)\nA variable in a program can have multiple definitions. In Bril definitions are instructions which compute values. Up till now we have been thinking about analysis which look at variables (names) but a different way to look at this is based on values, If we think of instructions calculating values, and uses being uses of values we can picture a graph called the data flow graph showing how values move through a program"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#ssa",
    "title": "Static Single Assignment",
    "section": "ssa",
    "text": "ssa\nin SSA we change our IR so that every variable has exactly one definition in the program (each variable is assigned only once). The name SSA means statically there is only a single assignment per variable."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#the-ssa-philosophy",
    "href": "lectures/revealjs_06_ssa.qmd.html#the-ssa-philosophy",
    "title": "Static Single Assignment",
    "section": "The SSA Philosophy",
    "text": "The SSA Philosophy\nIn addition to a language form, SSA is also a philosophy! It can fundamentally change the way you think about programs. In the SSA philosophy:\n\ndefinitions == variables\ninstructions == values\narguments == data flow graph edges"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\"0: i = 0\n    1: s = 0\"]\nB1[\"2: x = m\n    3: s = s + x\n    4: i = i +4\n    5: if i &lt; n go to B0\"]\nB0 --&gt; B1\nB1 --&gt; B1\n\n\n\n\n\n\nvariable i has two static assignments 0 and 4, so this program is not in SSA\nVariable s has two static assignments, x has one static assignment but x has lots of dynamic assignments (when the program executes)"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#straight-line-code",
    "href": "lectures/revealjs_06_ssa.qmd.html#straight-line-code",
    "title": "Static Single Assignment",
    "section": "straight line code",
    "text": "straight line code\nWe call a program without branches a piece of straight line code.\n    @main {\n      a: int = const 4;\n      b: int = const 2;\n      a: int = add a b;\n      b: int = add a b;\n      print b;\n    }\n\nIts easy to see how to convert straight line code into ssa\n    @main {\n      a.1: int = const 4;\n      b.1: int = const 2;\n      a.2: int = add a.1 b.1;\n      b.2: int = add a.2 b.1;\n      print b.2;\n    }"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#pseudo-code-for-one-basic-block",
    "href": "lectures/revealjs_06_ssa.qmd.html#pseudo-code-for-one-basic-block",
    "title": "Static Single Assignment",
    "section": "pseudo code for one basic block",
    "text": "pseudo code for one basic block\nfor each variable a: \n    Count[a] = 0 \n    Stack[a] = [0]\n\nrename_basic_block(B): \n    for each instruction S in block B:\n        for each use of a argument x in S: \n            i = top(Stack[x]) \n            replace the use of x with $x_i$\n            \n        for each variable a that S defines (a dest)\n            count[a] = Count[a] + 1 \n            i = Count[a]             \n            push i onto Stack[a]             \n            replace definition of a with $a_i$ \nWe don’t need the stack here but we will need it later."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes",
    "title": "Static Single Assignment",
    "section": "phi-Nodes",
    "text": "phi-Nodes\nJust renaming assignments will quickly run into problems. Consider this program:\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nB0[\".b0\n    a: int = const 47;\n    br cond .left .right;\"]\nleft[\"a: int = add a a;\n    jmp .exit;\"]\nright[\"a: int = mul a a;\n        jmp .exit;\"]\nexit[\"print a;\"]\nB0 --&gt; left\nB0 --&gt; right\nleft --&gt; exit\nright --&gt; exit\n\n\n\n\n\n\nWhich “version” of a should we use in the print statement?"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-1",
    "title": "Static Single Assignment",
    "section": "phi nodes",
    "text": "phi nodes\nTo match the expressiveness of unrestricted programs, SSA adds a new kind of instruction: a phi-node.\nphi-nodes are flow-sensitive copy instructions: they get a value from one of several variables, depending on which incoming CFG edge was most recently taken to get to them."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-in-bril",
    "href": "lectures/revealjs_06_ssa.qmd.html#phi-nodes-in-bril",
    "title": "Static Single Assignment",
    "section": "phi nodes in Bril",
    "text": "phi nodes in Bril\nIn Bril, a phi-node appears as a phi instruction:\na.4: int = phi .left a.2 .right a.3;\nThe phi instruction chooses between any number of variables, and it picks between them based on labels. If the program most recently executed a basic block with the given label, then the phi instruction takes its value from the corresponding variable."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#back-to-the-example",
    "href": "lectures/revealjs_06_ssa.qmd.html#back-to-the-example",
    "title": "Static Single Assignment",
    "section": "back to the example",
    "text": "back to the example\nYou can write the above program in SSA like this:\n    @main(cond: bool) {\n    .entry:\n        a.1: int = const 47;\n        br cond .left .right;\n    .left:\n        a.2: int = add a.1 a.1;\n        jmp .exit;\n    .right:\n        a.3: int = mul a.1 a.1;\n        jmp .exit;\n    .exit:\n        a.4: int = phi .left a.2 .right a.3;\n        print a.4;\n    }"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#bril-in-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#bril-in-ssa",
    "title": "Static Single Assignment",
    "section": "Bril in SSA",
    "text": "Bril in SSA\nBril has an SSA extension It adds support for a phi instruction. Beyond that, SSA form is just a restriction on the normal expressiveness of Bril—if you solemnly promise never to assign statically to the same variable twice, you are writing “SSA Bril.”\nThe reference interpreter has built-in support for phi, so you can execute your SSA-form Bril programs without fuss."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#getting-out-of-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#getting-out-of-ssa",
    "title": "Static Single Assignment",
    "section": "Getting out of ssa",
    "text": "Getting out of ssa\nCompilers that use the SSA form usually contain a step, before the generation of actual assembly code, in which phi functions are replaced by ordinary instructions. Normally these instructions are simple copies."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-example-1",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-example-1",
    "title": "Static Single Assignment",
    "section": "an example",
    "text": "an example\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n A0[\"io =\n     j0 = \n     k0 =\"]\nA1[\"i1 =\n   j1 =\n   k1 = \"]\nA2[\"i2 = phi(i0, i1)\n   j2 = phi(j0, j1)\n   k2 = phi(k0, k1)\n   ...\n    = i2\n    = j2 \n    = k2\"]\n\n    A0 --&gt; A2\n    A1--&gt; A2\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\n B0[\"io =\n     j0 = \n     k0 =\"]\nB1[\"i1 =\n   j1 =\n   k1 = \"]\nB2[\"\n   ...\n    = i2\n    = j2 \n    = k2\"]\n    B0 --\"i2 = i0\n       j2 = j0\n       k2 = k0\"--&gt; B2\n    B1 --\"i2 = i1\n          j2 = j1\n          k2 = k1\"--&gt; B2\n\n\n\n\n\n\n\nwe cannot put instructions on edges, but we can add to prev block"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#critical-edges",
    "href": "lectures/revealjs_06_ssa.qmd.html#critical-edges",
    "title": "Static Single Assignment",
    "section": "critical edges",
    "text": "critical edges\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nA0[\"L1:\n   a0 =\n   b0 =\n   if A0 &gt; b0\"]\nA1[\"b1 = a0\"]\nA2[\"l2:\nb2 = phi(b1,b0)\"]\nA0 --&gt; A1\nA1 --&gt; A2\nA0 --&gt; A2\n\n\n\n\n\n\n\nb2 = b0?\n\nThe placement of the copy b2 = b0 is not simple, because the edge that links L2 to L5 is critical. A critical edge connects a block with multiple successors to a block with multiple predecessors. This should remind you of adding a preheader to a loop"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#critical-edge-splitting",
    "href": "lectures/revealjs_06_ssa.qmd.html#critical-edge-splitting",
    "title": "Static Single Assignment",
    "section": "critical edge splitting",
    "text": "critical edge splitting\nWe can solve this problem by doing critical edge splitting. This CFG transformation consists in adding an empty basic block (empty, except by – perhaps – a goto statement) between each pair of blocks connected by a critical edge."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#converting-to-ssa---very-simple-scheme",
    "href": "lectures/revealjs_06_ssa.qmd.html#converting-to-ssa---very-simple-scheme",
    "title": "Static Single Assignment",
    "section": "Converting to SSA - Very simple scheme",
    "text": "Converting to SSA - Very simple scheme\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph LR\nX[\"Block X\n   a = \n   b = \n   if s &gt; b\"]\nY[\"Block Y\n  b = a\"]\nZ[\"Block Z\nret b\"]\nX --&gt; Y\nY--&gt; Z\nX --&gt; Z\n\n\n\n\n\n\nWhere do we need phi-functions?\nWhich variables\n\nAt the merge (join) node\nb"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#scheme",
    "href": "lectures/revealjs_06_ssa.qmd.html#scheme",
    "title": "Static Single Assignment",
    "section": "scheme",
    "text": "scheme\nconditions: phi-function for variable b at node z\n\nThere is a block x containing a definition of b\nThere is a block y (with y ≠ x) containing a definition of b\nThere is a nonempty path Pxz of edges from x to z\nThere is a nonempty path Pyz of edges from y to z\nPaths Pxz and Pyz do not have any node in common other than z, and…\nThe node z does not appear within both Pxz and Pyz prior to the end, though it may appear in one or the other."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#scheme-part-2",
    "href": "lectures/revealjs_06_ssa.qmd.html#scheme-part-2",
    "title": "Static Single Assignment",
    "section": "scheme part 2",
    "text": "scheme part 2\nthis is iterative since when we add a phi, we are creating a new defintion, which may add new phi-functions\nWhen we find nodes X,Y,Z that match these steps and z does not contain a phi function for b, insert a phi\nWhile really expensive this will work"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#fast-methods",
    "href": "lectures/revealjs_06_ssa.qmd.html#fast-methods",
    "title": "Static Single Assignment",
    "section": "fast methods",
    "text": "fast methods\nTo convert to SSA, we want to insert phi-nodes whenever there are distinct paths containing distinct definitions of a variable. We don’t need phi-nodes in places that are dominated by a definition of the variable. So what’s a way to know when control reachable from a definition is not dominated by that definition?\nThe dominance frontier!"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#an-almost-linear-method",
    "href": "lectures/revealjs_06_ssa.qmd.html#an-almost-linear-method",
    "title": "Static Single Assignment",
    "section": "an almost linear method",
    "text": "an almost linear method\nWe do it in two steps.\n\ninsert phi-nodes:\nrename variables:"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#rename-variables",
    "href": "lectures/revealjs_06_ssa.qmd.html#rename-variables",
    "title": "Static Single Assignment",
    "section": "rename variables:",
    "text": "rename variables:\nrename(n):\n  rename_basic_block(n)  # from before \n  for each successor Y of n, where n is the jth pred of Y\n    for each phi-function f in Y where the operand of f is 'a'\n      i = top(stack[a])\n      replace jth operand wit a_i\n  for each child of X of n (in the dominator tree)\n    rename(X)\n    for each instruction S in n\n       pop stack(S.dest)"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#what-is-the-dominator-tree",
    "href": "lectures/revealjs_06_ssa.qmd.html#what-is-the-dominator-tree",
    "title": "Static Single Assignment",
    "section": "What is the dominator tree?",
    "text": "What is the dominator tree?\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#dominance-frontiers",
    "href": "lectures/revealjs_06_ssa.qmd.html#dominance-frontiers",
    "title": "Static Single Assignment",
    "section": "dominance frontiers",
    "text": "dominance frontiers\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3 \n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 -.-&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TB \nL0 --&gt; L3 \nL3--&gt; L4\nL3 --&gt; L10\nL4--&gt; L5 \nL4 --&gt; L9\nL4 --&gt; L7"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#add-phi-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#add-phi-nodes",
    "title": "Static Single Assignment",
    "section": "add phi nodes",
    "text": "add phi nodes\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[L9: goto l3]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TB\nL0[\"L0: i = 1\n   L1: j = 1\n   L2: k = 0\"]\n\nL3[\"j = phi(j,j) \n    k = phi(k,k) \n   L3: if j &lt;20 go to l4 else l10\"]\n\nL4[\"l4: if j &lt; 20 goto l7 else l5\"]\n\nL5[\"l5: j = i\n   l6: k = k +1\"]\n\n\nL7[\"l7: j = k\n  l8: k = k +2\"]\n\nL9[\"j = phi(j,j)\n   k = phi(k,k)\n  L9: goto l3\"]\n\nL10[\"l10: ret j\"]\n\nL0--&gt; L3\n\nL3--&gt; L4\nL3 --&gt; L10\n\nL4 --&gt; L5\nL4 --&gt; L7\nL5 --&gt; L9\nL7 --&gt; L9\nL9 --&gt; L3"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#the-arity-of-phi-functions",
    "href": "lectures/revealjs_06_ssa.qmd.html#the-arity-of-phi-functions",
    "title": "Static Single Assignment",
    "section": "The arity of phi-functions",
    "text": "The arity of phi-functions\nCould we have a phi-function in a node with only one predecessor?\ncould we have a phi-function wit more then two arguments?\nThis algorithm computes what is called minimal SSA form which is not so mimimal since it can leave dead assignments\ndoing dead code elimination pruned ssa form"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#making-use-of-ssa-form",
    "href": "lectures/revealjs_06_ssa.qmd.html#making-use-of-ssa-form",
    "title": "Static Single Assignment",
    "section": "making use of ssa form",
    "text": "making use of ssa form\nOur previous analyses always used a (variable, program point), but in ssa these are the same"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#dead-code-elimination-in-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#dead-code-elimination-in-ssa",
    "title": "Static Single Assignment",
    "section": "dead code elimination in ssa",
    "text": "dead code elimination in ssa\nwhile there is some variable v with no uses and the statement that defines v has no other side effects, delete the statement that defines v from the program.\nwe need a counter for each variable (or each instruction)\nwalk the program once increment the counter each time the variable is used\nwhile there exists v, such that counter[v] = 0 remove the instruction that defined v, e.g., “v = E for each variable x used in E decrement counter[x]"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#sparse-constant-prop",
    "href": "lectures/revealjs_06_ssa.qmd.html#sparse-constant-prop",
    "title": "Static Single Assignment",
    "section": "sparse constant prop",
    "text": "sparse constant prop\nwe define a partial order on constats, any &gt; all constants &gt; undefined and define the intersection of two states as the common parent\nwith each variable we have an abstract state (like a value number)\nv  = const c   ==&gt; v state is const \n\nv = id q      ==&gt; v state is the state of  q \n\nv = v0 op v1  ==&gt; if both are constants v = c0 op c1\n\n             ==&gt; if one is any, v's state is any\n\nv = phi(v0,..vn) ==&gt; v's state is the intersection of the states of v0,..,vn"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#what-order-do-we-process-nodes",
    "href": "lectures/revealjs_06_ssa.qmd.html#what-order-do-we-process-nodes",
    "title": "Static Single Assignment",
    "section": "What order do we process nodes?",
    "text": "What order do we process nodes?\nbecause the program is in ssa form we can do the nodes in dominator tree order, then before processing any instruction that is not a phi, we will have processed all the arguments"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#walking-the-dominator-tree-b0---b1",
    "href": "lectures/revealjs_06_ssa.qmd.html#walking-the-dominator-tree-b0---b1",
    "title": "Static Single Assignment",
    "section": "walking the dominator tree b0 -> b1",
    "text": "walking the dominator tree b0 -&gt; b1\n\n\nB0: x0  = input \n    a0 = 1 \n    c0 = a0 +10\n    if a0 &lt; c0 go to b1\n\nB1: a1 phi(a0,a2 )\n    b0 = x0 * a1\n    print b0 \n    a2 = a1 +1 \n    go to b1\n\nB0:\nx0 - any \na0 - 1 \nc0 - 11 (folding the constant)\na0 &lt; c0  skip\nB1:\na1 -  1 (only one input defined)\nb0  - any\na2 -  2\nupdate the uses of a2 - the phi\na1 -  any \n\nupdate the uses of a1 \nno change"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#converting-from-ssa",
    "href": "lectures/revealjs_06_ssa.qmd.html#converting-from-ssa",
    "title": "Static Single Assignment",
    "section": "Converting from SSA",
    "text": "Converting from SSA\nEventually, we need to convert out of SSA form to generate efficient code for real machines that don’t have phi-nodes and do have finite space for variable storage."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#basic-algorithm",
    "href": "lectures/revealjs_06_ssa.qmd.html#basic-algorithm",
    "title": "Static Single Assignment",
    "section": "basic algorithm",
    "text": "basic algorithm\nThe basic algorithm is pretty straightforward. If you have a phi-node:\nv = phi .l1 x .l2 y;\nThen there must be assignments to x and y (recursively) preceding this statement in the CFG.\nThe paths from x to the phi-containing block and from y to the same block must “converge” at that block. So insert code into the phi-containing block’s immediate predecessors along each of those two paths: one that does v = id x and one that does v = id y. Then you can delete the phi instruction."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#extra-copies",
    "href": "lectures/revealjs_06_ssa.qmd.html#extra-copies",
    "title": "Static Single Assignment",
    "section": "extra copies",
    "text": "extra copies\nThis basic approach can introduce some redundant copying. (Take a look at the code it generates after you implement it!) Non-SSA copy propagation optimization can work well as a post-processing step. For a more extensive take on how to translate out of SSA efficiently, see “Revisiting Out-of-SSA Translation for Correctness, Code Quality, and Efficiency” by Boissinot et al."
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#overlap",
    "href": "lectures/revealjs_06_ssa.qmd.html#overlap",
    "title": "Static Single Assignment",
    "section": "overlap",
    "text": "overlap\nits possible that an optimization can give overlapping phi-functions\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1,x3)\ny2 = phi(y1, y3)\n  z = x2\n  x3 = y2\n  y3= z\n  if() go to b1"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#optimize-it",
    "href": "lectures/revealjs_06_ssa.qmd.html#optimize-it",
    "title": "Static Single Assignment",
    "section": "optimize it",
    "text": "optimize it\nb0 \n  x1 = 1\n  y1 = 2\nB1 \nx2 = phi(x1, y2)\ny2 = phi(y1, x2)\n  if() go to b1"
  },
  {
    "objectID": "lectures/revealjs_06_ssa.qmd.html#lost-the-temp-this-is-called-the-swap-problem",
    "href": "lectures/revealjs_06_ssa.qmd.html#lost-the-temp-this-is-called-the-swap-problem",
    "title": "Static Single Assignment",
    "section": "lost the temp (this is called the swap problem)",
    "text": "lost the temp (this is called the swap problem)\nif we add copies x2 = y3 y2 = x2 (uses the wrong value of x2)\nphi nodes execute all at once - not one at a time\nSome SSA slides from Todd Mowry at CMU"
  },
  {
    "objectID": "weekly.html",
    "href": "weekly.html",
    "title": "EECS7398 Weekly Schedule fa 2024",
    "section": "",
    "text": "Since the is the first time this course is offered. This is a tentative schedule.\ndo to ********",
    "crumbs": [
      "EECS 7398",
      "Weekly Schedule"
    ]
  },
  {
    "objectID": "weekly.html#ai-in-compilers",
    "href": "weekly.html#ai-in-compilers",
    "title": "EECS7398 Weekly Schedule fa 2024",
    "section": "ai in compilers",
    "text": "ai in compilers\npapers\nGenerating GPU Compiler Heuristics using Reinforcement Learning https://arxiv.org/abs/2111.12055 Ian Colbert, Jake Daly, Norm Rubin\nRevealing Compiler Heuristics Through Automated Discovery and Optimization Volker Seeker; Chris Cummins; Murray Cole; Björn Franke; Kim Hazelwood; Hugh Leather https://ieeexplore.ieee.org/document/10444847\nEnd-to-End Deep Learning of Optimization Heuristics Chris Cummins; Pavlos Petoumenos; Zheng Wang; Hugh Leather https://ieeexplore.ieee.org/document/8091247\npossible lecture source Machine Learning in Compilers: Past, Present and Future https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9232934 Hugh Leather; Chris Cummins",
    "crumbs": [
      "EECS 7398",
      "Weekly Schedule"
    ]
  },
  {
    "objectID": "weekly.html#optimizing-compiler-deep-learning",
    "href": "weekly.html#optimizing-compiler-deep-learning",
    "title": "EECS7398 Weekly Schedule fa 2024",
    "section": "optimizing compiler deep learning",
    "text": "optimizing compiler deep learning\npapers\nTVM: An Automated End-to-End Optimizing Compiler for Deep Learning https://www.usenix.org/conference/osdi18/presentation/chen Tianqi Chen and Thierry Moreau, University of Washington; Ziheng Jiang, University of Washington, AWS; Lianmin Zheng, Shanghai Jiao Tong University; Eddie Yan, Haichen Shen, and Meghan Cowan, University of Washington; Leyuan Wang, UC Davis, AWS; Yuwei Hu, Cornell; Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy, University of Washington\nProGraML: Graph-based Deep Learning for Program Optimization and Analysis https://arxiv.org/abs/2003.10536 Chris Cummins, Zacharias V. Fisches, Tal Ben-Nun, Torsten Hoefler, Hugh Leather\nA comprehensive study of deep learning compiler bugs https://dl.acm.org/doi/abs/10.1145/3468264.3468591?casa_token=Aj2H-DPPcmQAAAAA:7gy0bCEqaIBDoYDSS6MTtMtGYNTUYySFlmyNjrzsc0d1S8DAEC9yuCUwv0Sx4SLk2ujUhKWijbvo Qingchao Shen, Haoyang Ma, Junjie Chen, Yongqiang Tian, Shing-Chi Cheung, and Xiang ChenAuthors Info & Claims\nRelay: A High-Level Compiler for Deep Learning https://arxiv.org/abs/1904.08368 Jared Roesch, Steven Lyubomirsky, Marisa Kirisame, Logan Weber, Josh Pollock, Luis Vega, Ziheng Jiang, Tianqi Chen, Thierry Moreau, Zachary Tatlock\npossible lecture source https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html https://medium.com/geekculture/ai-compilers-ae28afbc4907\n:::\n\n\n\n\n\n\n\n\n\nDate\ntopic\ndue\ndiscussions\n\n\n\n\nSept 6\nCompiler overview and structure\nhw0 needs 1 week\n\n\n\n\n\n\n\n\n\n\n\n\n\nSept 10\nPerformance Measurement\n\n\n\n\nSept 13\nRepresenting programs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSept 17\nOverview of Bril\nhw0 due\n\n\n\nSept 20\nLocal analysis and optimization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSept 24\nValue numbering\nhw1\n\n\n\nSept 27\nData flow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 1\nGlobal analysis\nhw2\n\n\n\nOct 4\nloop invariant code motion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 8\nStatic single assignment\nhw3\n\n\n\nOct 11\nLLVM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 15\nGlobal value number\nhw4\n\n\n\nOct 18\ntesting reg allocator\nproject proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 22\npapers\n\n\n\n\nOct 25\nGPU Compilers might need two classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 29\npapers\nhw5\n\n\n\nNov 1\nDynamic compilers 1\nhomework needs two weeks\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 5\nDynamic compilers 2\n\n\n\n\nNov 8\nClassical loop optimizations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 12\npapers\nhw6 (extra credit)\n\n\n\nNov 15\nPolyhedral analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 19\npapers\n\n\n\n\nNov 22\npapers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 26\npapers\n\n\n\n\nNov 29\nThanksgiving\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 3\nInterprocedural Analysis (could drop)\n\n\n\n\nDec 6\nMLIR (could drop)\n\n\n\n\n\npapers new\n[Retargeting and Respecializing GPU Workloads for Performance Portability] (https://ieeexplore.ieee.org/document/10444828) Ivanov, I.R., Zinenko, O., Domke, J., Endo, T. and Moses, W.S., cgo 2024\nLOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers Merouani, M., Boudaoud, K.A., Aouadj, I.N., Tchoulak, N., Bernou, I.K., Benyamina, H., Tayeb, F.B.S., Benatchba, K., Leather, H. and Baghdadi, R. arXiv preprint arXiv:2403.11522 after polyhedrial\npapers classics\nImproving Data Locality with Loop Transformations McKinley, Carr, & Tseng toplas 1996\nAdaptive Online Context-Sensitive Inlining K. Hazelwood, and D. Grove cgo 2003\nHigh-performance code generation for stencil computations on GPU architectures. *Holewinski, Jan, Louis-Noël Pouchet, and P. Sadayappan. supercomputing 2012\nContext Threading: A flexible and efficient dispatch technique for virtual machine interpreters chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.cs.toronto.edu/syslab/pubs/demkea_context.pdf Marc Berndl, Benjamin Vitale, Mathew Zaleski and Angela Demke Brown\nProgram optimization space pruning for a multithreaded gpu Shane Ryoo, Christopher I. Rodrigues, Sam S. Stone, Sara S. Baghsorkhi, Sain-Zee Ueng, John A. Stratton, and Wen-mei W. Hwu cgo 2008\nDetecting equality of variables in programs Alpern, Bowen, Mark N. Wegman, and F. Kenneth Zadeck. ??\nhttps://dl.acm.org/doi/pdf/10.1145/1133255.1134000 DieHard: probabilistic memory safety for unsafe languages\nmaybes\nThe Garbage Collection Advantage: Improving Program Locality X. Huang, S. M. Blackburn, K. S. McKinley, J. E. B. Moss, Z. Wang, and P. Cheng, oopsla 2004\nPradelle, B., Baskaran, M., Henretty, T., Meister, B., Konstantinidis, A. and Lethin, R., 2016, September. Polyhedral compilation for energy efficiency. In 2016 IEEE High Performance Extreme Computing Conference (HPEC) (pp. 1-7). IEEE. https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7761595\n\nBaskaran, Muthu Manikandan, et al. “Automatic data movement and computation mapping for multi-level parallel architectures with explicitly managed memories.” Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming. 2010.\nRyoo, Seongbeom, et al. “Optimization principles and application performance evaluation of a multithreaded GPU using CUDA.” Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming. 2008.\nBoehm, Hans-Juergen, and Mark Weiser. “Garbage collection in an uncooperative environment.” Software: Practice and Experience 18.9 (1988): 807-820. possible lectures\n\n[cranelift checking correctness in register allocator])(https://cfallin.org/blog/2021/03/15/cranelift-isel-3/) this is a blog post - after ssa\nValue Numbering P. Briggs, K. D. Cooper, L. Taylor Simpson, Software-Practice & Experience, 1997 global value numbering in ssa, congruence\nWilson PR. Uniprocessor garbage collection techniques. InInternational Workshop on Memory Management 1992 Sep 17 (pp. 1-42). Berlin, Heidelberg: Springer Berlin Heidelberg.\nhttps://ieeexplore.ieee.org/document/10444819 A. Murtovi, G. Georgakoudis, K. Parasyris, C. Liao, I. Laguna and B. Steffen, “Enhancing Performance Through Control-Flow Unmerging and Loop Unrolling on GPUs,” 2024 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), Edinburgh, United Kingdom, 2024, pp. 106-118, doi: 10.1109/CGO57630.2024.10444819. keywords: {Codes;Costs;Graphics processing units;Prototypes;Benchmark testing;Predictive models;Optimization;compiler;code duplication;LLVM;GPU},\nhttps://escholarship.org/uc/item/3rt0n0q2 Gal, A., Probst, C. W, & Franz, M. (2003). A denial of service attack on the Java bytecode verifier. UC Irvine: Donald Bren School of Information and Computer Sciences. Retrieved from https://escholarship.org/uc/item/3rt0n0q2\nhttps://dl.acm.org/doi/pdf/10.1145/3620665.3640366 PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation ASPLOS ’24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2\nMeta Large Language Model Compiler: Foundation Models of Compiler Optimization Chris Cummins†, Volker Seeker†, Dejan Grubisic, Baptiste Rozière, Jonas Gehring, Gabriel Synnaeve, Hugh Leather /https://scontent-bos5-1.xx.fbcdn.net/v/t39.2365-6/448997590_1496256481254967_2304975057370160015_n.pdf?_nc_cat=106&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=4Yn8V9DFdbsQ7kNvgEwOdGk&_nc_ht=scontent-bos5-1.xx&oh=00_AYD-0YTCXuS11WU8rqC3N2aA-AfiflOptch_BD__V1V3xA&oe=6684630D\n——————- papers\npaper 1 - [Producing Wrong Data Without Doing Anything Obviously Wrong!]\npaper 2 - iterative data-flow analysis, revisited Cooper, Keith D.; Harvey, Timothy J.; Kennedy, Ken (2004-03-26) [November 2002]. pldi 2002\npaper 3 https://dl.acm.org/doi/10.1145/1064978.1065042 Threads cannot be implemented as a library\npaper 4 Superoptimizer: A Look at the Smallest Program Alexia Massalin. ASPLOS 1987.\npaper 5 pappe 5 Formal Verification of a Realistic Compiler Xavier Leroy. CACM in 2009.\npaper 6 Efficient Path Profiling Thomas Ball and James R. Larus. MICRO 1996.\npaper 7 An Efficient Implementation of SELF, a Dynamically-Typed Object-Oriented Language Based on Prototypes C. Chambers, D. Ungar, and E. Lee. OOPSLA 1989.\npaper 8 “Partial Redundancy Elimination” by Jens Knoop, Oliver Rüthing, and Bernhard Steffen\nFormal Verification of a Realistic Compiler Xavier Leroy. CACM in 2009.\npaper [Dynamo: A Transparent Dynamic Optimization System] (https://dl.acm.org/doi/pdf/10.1145/349299.349303) Vasanth Bala\nhttps://dada.cs.washington.edu/research/tr/2017/12/UW-CSE-17-12-01.pdf 12-01 TVM:End-to-End Optimization Stack for Deep Learnin\nRevealing Compiler Heuristics through Automated Discovery and Optimization, V. Seeker, C. Cummins, M. Cole, B. Franke, K. Hazelwood, H. Leather\nEnd-to-end deep learning of optimization heuristics - Chris Cummins, Pavlos Petoumenos, Zheng Wang, and Hugh Leather PACT 2017. https://ieeexplore.ieee.org/document/8091247\n1988\n2000\nDynamo: A Transparent Dynamic Optimization System Bala, V., Duesterwald, E. and Banerjia, S., PLDI 2000\n2002 iterative data-flow analysis, revisited Cooper, Keith D.; Harvey, Timothy J.; Kennedy, Ken (2004-03-26),November 2002\n2005 [Threads cannot be implemented as a library] (https://dl.acm.org/doi/10.1145/1064978.1065042) Boehm, H.J.. PLDI 2005\n2015 Provably correct peephole optimizations with alive Lopes, N.P., Menendez, D., Nagarakatte, S. and Regehr, J. pldi 2015\n2009 Formal Verification of a Realistic Compiler Xavier Leroy. CACM 2009.\n2018 TVM: end-to-end optimization stack for deep learning Chen, Tianqi, Thierry Moreau, Ziheng Jiang, Haichen Shen, Eddie Q. Yan, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy.arXiv preprint arXiv:1802.04799 11, no. 2018 (2018): 20.\n2024 Enhancing Performance Through Control-Flow Unmerging and Loop Unrolling on GPU A. Murtovi, G. Georgakoudis, K. Parasyris, C. Liao, I. Laguna and B. Steffen, cgo 2024\nhttps://escholarship.org/uc/item/3rt0n0q2 Gal, A., Probst, C. W, & Franz, M. (2003). A denial of service attack on the Java bytecode verifier. UC Irvine: Donald Bren School of Information and Computer Sciences. Retrieved from https://escholarship.org/uc/item/3rt0n0q2\nhttps://dl.acm.org/doi/pdf/10.1145/3620665.3640366 PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation ASPLOS ’24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2\n/https://scontent-bos5-1.xx.fbcdn.net/v/t39.2365-6/448997590_1496256481254967_2304975057370160015_n.pdf?_nc_cat=106&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=4Yn8V9DFdbsQ7kNvgEwOdGk&_nc_ht=scontent-bos5-1.xx&oh=00_AYD-0YTCXuS11WU8rqC3N2aA-AfiflOptch_BD__V1V3xA&oe=6684630D Meta Large Language Model Compiler: Foundation Models of Compiler Optimization Chris Cummins†, Volker Seeker†, Dejan Grubisic, Baptiste Rozière, Jonas Gehring, Gabriel Synnaeve, Hugh Leather†\nChlorophyll: Synthesis-Aided Compiler for Low-Power Spatial Architectures Phitchaya Mangpo Phothilimthana, Tikhon Jelvis, Rohin Shah, Nishant Totla, Sarah Chasins, and Rastislav Bodik. PLDI 2014.\nMLIR: A Compiler Infrastructure for the End of Moore’s Law Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy Davis, Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasilache, and Oleksandr Zinenko. arXiv preprint, 2020.\nTrace-Based Just-in-Time Type Specialization for Dynamic Languages Andreas Gal, Brendan Eich, Mike Shaver, David Anderson, David Mandelin, Mohammad R. Haghighat, Blake Kaplan, Graydon Hoare, Boris Zbarsky, Jason Orendorff, Jesse Ruderman, Edwin W. Smith, Rick Reitmaier, Michael Bebenita, Mason Chang, and Michael Franz. PLDI 2009.\nMesh: Compacting Memory Management for C/C++ Applications Bobby Powers, David Tench, Emery D. Berger, and Andrew McGregor. PLDI 2019.\nA Unified Theory of Garbage Collection David F. Bacon, Perry Cheng, and V. T. Rajan. OOPSLA 2004.\nType-Based Alias Analysis Amer Diwan, Kathryn S. McKinley, and J. Eliot B. Moss.\nBodik, Rastislav, Rajiv Gupta, and Vivek Sarkar. “ABC: Path-sensitive dynamic test generation.” ACM SIGPLAN Notices 35.5 (2000): 61-73.\nCooper, Keith D., and Linda Torczon. “Tiling for improved register usage.” ACM SIGPLAN Notices 28.6 (1993): 279-290. Cytron, Ron, et al. “Efficiently computing static single assignment form and the control dependence graph.” ACM Transactions on Programming Languages and Systems (TOPLAS) 13.4 (1991): 451-490. Ertl, M. Anton. “Threaded code.” ACM Computing Surveys (CSUR) 32.2 (2000): 290-318 Ferrante, Jeanne, Karl J. Ottenstein, and Joe D. Warren. “The program dependence graph and its use in optimization.” ACM Transactions on Programming Languages and Systems (TOPLAS) 9.3 (1987): 319-349. Ganapathi, Madhusudhan, et al. “Experience with the MIPS compiler.” ACM SIGPLAN Notices 21.7 (1986): 175-187.\nGo Hall, Mary W., and Ken Kennedy. “Efficient call graph analysis.” ACM Letters on Programming Languages and Systems (LOPLAS) 1.3 (1992): 227-242.\nKennedy, Ken, and Kathryn S. McKinley. “Loop distribution with arbitrary control flow.” ACM SIGPLAN Notices 29.6 (1994): 140-151. Knoop, Jens, Oliver Rüthing, and Bernhard Steffen. “Lazy code motion.” ACM SIGPLAN Notices 27.7 (1992): 224-234. Lamport, Leslie. “The parallel execution of DO loops.” Communications of the ACM 17.2 (1974): 83-93.\nSarkar, Vivek. “Partitioning parallel programs for macro-dataflow.” ACM SIGPLAN Notices 23.7 (1988): 98-106. Shivers, Olin. “Control-flow analysis in Scheme.” ACM SIGPLAN Notices 23.7 (1988): 164-174. Steensgaard, Bjarne. “Points-to analysis in almost linear time.” ACM SIGPLAN Notices 31.5 (1996): 32-41. Tarjan, Robert E. “Depth-first search and linear graph algorithms.” SIAM journal on computing 1.2 (1972): 146-160. Tichy, Walter F. “Smart recompilation.” ACM Transactions on Programming Languages and Systems (TOPLAS) 8.3 (1986): 273-291. Wolf, Michael E., and Monica S. Lam. “A data locality optimizing algorithm.” ACM SIGPLAN Notices 26.6 (1991): 30-44. Yaccarino, Joseph, and Keshav Pingali. “Data-flow analysis for distributed-memory multiprocessors.” ACM SIGPLAN Notices 27.9 (1992): 353-363. Zadeck, F. Kenneth, and Olivier Rüthing. “Incremental data flow analysis.” ACM SIGPLAN Notices 23.7 (1988): 132-146.\n\nBodik, Rastislav, Rajiv Gupta, and Vivek Sarkar. “ABC: Path-sensitive dynamic test generation.” ACM SIGPLAN Notices 35.5 (2000): 61-73.\nCooper, Keith D., and Linda Torczon. “Tiling for improved register usage.” ACM SIGPLAN Notices 28.6 (1993): 279-290.\nCytron, Ron, et al. “Efficiently computing static single assignment form and the control dependence graph.” ACM Transactions on Programming Languages and Systems (TOPLAS) 13.4 (1991): 451-490.\nFerrante, Jeanne, Karl J. Ottenstein, and Joe D. Warren. “The program dependence graph and its use in optimization.” ACM Transactions on Programming Languages and Systems (TOPLAS) 9.3 (1987): 319-349.\nGanapathi, Madhusudhan, et al. “Experience with the MIPS compiler.” ACM SIGPLAN Notices 21.7 (1986): 175-187.\nHall, Mary W., and Ken Kennedy. “Efficient call graph analysis.” ACM Letters on Programming Languages and Systems (LOPLAS) 1.3 (1992): 227-242.\nKennedy, Ken, and Kathryn S. McKinley. “Loop distribution with arbitrary control flow.” ACM SIGPLAN Notices 29.6 (1994): 140-151.\nKnoop, Jens, Oliver Rüthing, and Bernhard Steffen. “Lazy code motion.” ACM SIGPLAN Notices 27.7 (1992): 224-234.\nLamport, Leslie. “The parallel execution of DO loops.” Communications of the ACM 17.2 (1974): 83-93.\nMcKinley, Kathryn S., Steve Carr, and Chau-Wen Tseng. “Improving data locality with loop transformations.” ACM Transactions on Programming Languages and Systems (TOPLAS) 18.4 (1996): 424-453.\nSarkar, Vivek. “Partitioning parallel programs for macro-dataflow.” ACM SIGPLAN Notices 23.7 (1988): 98-106.\nShivers, Olin. “Control-flow analysis in Scheme.” ACM SIGPLAN Notices 23.7 (1988): 164-174.\nSteensgaard, Bjarne. “Points-to analysis in almost linear time.” ACM SIGPLAN Notices 31.5 (1996): 32-41.\nTichy, Walter F. “Smart recompilation.” ACM Transactions on Programming Languages and Systems (TOPLAS) 8.3 (1986): 273-291.\nWolf, Michael E., and Monica S. Lam. “A data locality optimizing algorithm.” ACM SIGPLAN Notices 26.6 (1991): 30-44.\nAppel, Andrew W. “Simple generational garbage collection and fast allocation.” Software: Practice and Experience 19.2 (1989): 171-183.\nDijkstra, Edsger W., et al. “On-the-fly garbage collection: An exercise in cooperation.” Communications of the ACM 21.11 (1978): 965-975.\nBacon, David F., Perry Cheng, and V. T. Rajan. “A real-time garbage collector with low overhead and consistent utilization.” ACM SIGPLAN Notices. Vol. 38. No. 5. 2003.\n\nWegman & Zadeck, Constant Propagation with Conditional Branches, ACM Transactions on Programming Languages and Systems, 13(2):181-210, April 1991.\n\nGarland, Michael, et al. “Parallel computing experiences with CUDA.” IEEE Micro 28.4 (2008): 13-27.",
    "crumbs": [
      "EECS 7398",
      "Weekly Schedule"
    ]
  },
  {
    "objectID": "notebooks/llvm.html",
    "href": "notebooks/llvm.html",
    "title": "intro to llvm",
    "section": "",
    "text": "difference between bril and llvm\nlinks\nllvm page\nAdrians tutorial\nllvm doc\ngoogle or github pilot is very useful for this\n\n#as a first step I'm going to show how to install clang and cmake \n\n# step remove any old copies \n# the -S flag to sudo means - read from stdinput\n# the -y flag means always ans yes to apt \n# since sudo needs a password \n# -qq is the very quiet option \n!sudo -S apt purge -y -qq clang cmake &lt;  ~/pw\n!sudo -S apt install -y -qq clang cmake &lt; ~/pw\n\n\n[sudo] password for norm: The following packages were automatically installed and are no longer required:\n  cmake-data dh-elpa-helper emacsen-common libarchive13 libjsoncpp25 librhash0\nUse 'sudo apt autoremove' to remove them.\nThe following packages will be REMOVED:\n  clang* cmake*\n0 upgraded, 0 newly installed, 2 to remove and 48 not upgraded.\nAfter this operation, 21.3 MB disk space will be freed.\n\n(Reading database ... 40226 files and directories currently installed.)\nRemoving clang (1:14.0-55~exp2) ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Progress: [ 22%] [############..............................................] Progress: [ 33%] [###################.......................................] Progress: [ 44%] [#########################.................................] emoving cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] Progress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n[sudo] password for norm: Suggested packages:\n  cmake-doc ninja-build cmake-format\nThe following NEW packages will be installed:\n  clang cmake\n0 upgraded, 2 newly installed, 0 to remove and 48 not upgraded.\nNeed to get 0 B/5014 kB of archives.\nAfter this operation, 21.3 MB of additional disk space will be used.\n\nSelecting previously unselected package clang.\n(Reading database ... 40203 files and directories currently installed.)\nPreparing to unpack .../clang_1%3a14.0-55~exp2_amd64.deb ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Unpacking clang (1:14.0-55~exp2) ...\nProgress: [ 22%] [############..............................................] electing previously unselected package cmake.\nPreparing to unpack .../cmake_3.22.1-1ubuntu1.22.04.2_amd64.deb ...\nProgress: [ 33%] [###################.......................................] Unpacking cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 44%] [#########################.................................] etting up clang (1:14.0-55~exp2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] etting up cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n\n\nlets take a look at llvm ir\n\n%%writefile temp.c\nint main(int argc, char** argv){\n    return argc;\n}\n\nOverwriting temp.c\n\n\n\n# call clang and dump the ir\n# # -emit-llvm  print the ir\n# -S print as text not as binary \n# 0 -  output to stdout \n# \n!clang -emit-llvm -S -o - temp.c\n\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"frame-pointer\"=\"all\" \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\n!llvm.ident = !{!5}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 7, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"PIE Level\", i32 2}\n!3 = !{i32 7, !\"uwtable\", i32 1}\n!4 = !{i32 7, !\"frame-pointer\", i32 2}\n!5 = !{!\"Ubuntu clang version 14.0.0-1ubuntu1.1\"}\n\n\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThere is a cs6120 package that makes setting up the build process for plugins simple\nllvm ir, has two forms .bc files are bitcode, .ll forms are text versions that look like assembly.\nllvm is not written in C++ but it has a lot of features that look like C++.\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\n\n\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions so if I is an instruction\nouts() &lt;&lt; *(I.getOperand(0)) ; prints an instruction\nGiven a Value* V, what kind of thing is V?\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument\n\nStatic bool isLoopInvariant(const Value *V, const Loop *L) { \n    if (isa&lt;Constant&gt;(V) || isa&lt;Argument&gt;(V) || isa&lt;GlobalValue&lt;(V)) {\n         return true; } \n    //otherwise it must be an instruction…    \n    return !L-&gt;contains(cast&lt;Instruction&gt;(V)-&gt;getParent());\n     … \n}\nNavigating llvm IR - IT Containers\n\nModule - two way linked list of Functions\nFunction - two way linked list of Basic Blocks\nBasic Block - two way linked list of Instructions\n\n%5 = add i32 %4,2\nthis instruction adds two 32 bit ints, input is in register %4 and the constant 2, result goes into register %5\nblog post: Why would a grad student care about llvm\n\n%%bash \nrm -r llvm-pass-skeleton/\ngit clone   https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n# look at  llvm-pass-skeleton/skeleton/Skeleton.cpp\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\nThe function returns PreservedAnalyses::all() to indicate that it didn’t modify M. Later, when we actually transform the program, we’ll need to return something like PreservedAnalyses::none().\nThe ModuleAnalysisManager is responsible for managing the analysis results for Module passes.\nWhen a pass requests an analysis, the ModuleAnalysisManager checks if the analysis result is already available. If it is, the ModuleAnalysisManager returns the cached result. If it’s not, the ModuleAnalysisManager runs the analysis pass, caches the result, and then returns it.\nThis allows LLVM to avoid recomputing analysis results unnecessarily, which can significantly improve the performance of the compiler.\nHere’s an example of how you might use it:\nPreservedAnalyses MyPass::run(Module &M, ModuleAnalysisManager &MAM) {\n    // Request an analysis result.\n    const auto &Result = MAM.getResult&lt;SomeAnalysis&gt;(M);\n\n    // Use the analysis result.\n    // ...\n\n    return PreservedAnalyses::all();\n}\nHere is a second example getting the dominator tree\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Request the dominator tree of the function.\n            const DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Use the dominator tree.\n            // ...\n        }\n\n        return PreservedAnalyses::all();\n    }\nnow let look at the containers\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b containers  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\nError while terminating subprocess (pid=71626): \n[100%] Built target SkeletonPass\n\n\n\n# run the plugin \n# \n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp.c\n\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  ret i32 %6\nI saw a function called main!\n\n\n\n%%writefile temp1.c\nint main(int argc, char** argv){\n    if (argc &gt;2 )\n        return argc;\n    return 0;\n}\n\nOverwriting temp1.c\n\n\n\n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp1.c\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  %7 = icmp sgt i32 %6, 2\nInstruction: \n  br i1 %7, label %8, label %10\nBasic block:\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\nInstruction: \n  %9 = load i32, i32* %4, align 4\nInstruction: \n  store i32 %9, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\nInstruction: \n  %12 = load i32, i32* %3, align 4\nInstruction: \n  ret i32 %12\nI saw a function called main!\n\n\n\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\n[100%] Built target SkeletonPass\n\n\n\n%%bash \ncat ls ~/llvm/llvm-pass-skeleton/skeleton/Skeleton.cpp \necho done\n\ncat: ls: No such file or directory\n\n\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/Transforms/Utils/BasicBlockUtils.h\"\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}\ndone\n\n\n\n%%bash \ncat /home/norm/llvm/llvm-pass-skeleton/rtlib.c\necho\n\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}\n\n\n\n\n%%writefile llvm-pass-skeleton/test_r.cpp\n#include &lt;stdio.h&gt;\nint main (int argc, char** argv) {\n    printf(\"%d %d\", argc, (argc + 2) * (argc +3));\n}\n\nOverwriting llvm-pass-skeleton/test_r.cpp\n\n\n\n%%bash \ncd llvm-pass-skeleton/\ncc -c rtlib.c\nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test_r.cpp\ncc test_r.o rtlib.o\n./a.out 1 2 3 4\necho \n\ncomputed: 7\n5 56\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/possible_papers.html",
    "href": "notebooks/possible_papers.html",
    "title": "possible papers",
    "section": "",
    "text": "Glow: Graph Lowering Compiler Techniques for Neural Networks Nadav Rotem, Jordan Fix, Saleem Abdulrasool, Garret Catron, Summer Deng, Roman Dzhabarov, Nick Gibson, James Hegeman, Meghan Lele, Roman Levenstein, Jack Montgomery, Bert Maher, Satish Nadathur, Jakob Olesen, Jongsoo Park, Artem Rakhov, Misha Smelyanski chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/1805.00907\nA Deep Learning Based Cost Model for Automatic Code Optimization. Riyadh Baghdadi, Massinissa Merouani, Mohamed-Hicham Leghettas, Kamel Abdous, Taha Arbaoui, Karima Benatchba, Saman Amarasinghe. Proceedings of the Fourth Conference on Machine Learning and Systems (MLSys).\nhttps://dl.acm.org/doi/abs/10.1145/3213846.3213848?casa_token=cbgdY_Wgz9kAAAAA:IMKfnKAYKl3t9wXFen_yauFHY__vyUHcqSgjENz7RB2QEGeTC1L70FEC5vM9FnKBWdAiL6tw1uC4 Compiler fuzzing through deep learning\n“Effective Superword Level Parallelism for Multimedia Extension Architectures” by Samuel Larsen and Saman Amarasinghe (2000)\nEnergy-Aware Tile Size Selection for Affine Programs on GPUs, M. Jayaweera, M. Kong, Y. Wang, D. Kaeli, Pre-print, Artifact\n\n\n\n Back to top"
  },
  {
    "objectID": "check-links.html",
    "href": "check-links.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "# check all the links - get a list of all internal links\n# find all the files that are not used\n\n\nimport os\n\ndef get_all_files(base):\n    \"\"\"Returns a set of all paths to all files below base.\"\"\"\n    all_files = set()\n    skips = ['.git', '_site', \".quarto\"]\n    for root, dirs, files in os.walk(base):\n        for skip in skips:\n            if skip in dirs:\n                dirs.remove(skip)\n        for file in files:\n            all_files.add(os.path.join(root, file)[2:])\n    return all_files\n\n\nextra_files = get_all_files(\".\")\n\nprint(extra_files)\n\n{'lectures/images/StaticSingleAssignment_Part48.jpg', 'lectures/images/StaticSingleAssignment_Part73.jpg', 'issues', 'runfirst.py', 'lectures/images/StaticSingleAssignment_Part71.jpg', 'lectures/12_memory.qmd', 'Class_Overview/sylibus.qmd', 'lectures/03b_local_value_numbering.qmd', 'lectures/02b_bril.qmd.saved', 'lectures/100_mlir.qmd', 'lectures/03_local.qmd', 'lectures/05_global.qmd', 'description.txt', 'Class_Overview/about.qmd', 'lectures/04_data_flow.qmd', 'lectures/images/StaticSingleAssignment_Part69.jpg', 'index.qmd', 'notebooks/representation.ipynb', 'lectures/13_dynamic_compilers.qmd', 'lectures/images/my_ast', 'lectures/images/StaticSingleAssignment_Part40.jpg', 'lectures/images/add.json', 'lectures/images/Grace_Hopper_and_UNIVAC.jpg', 'lectures/08_classic_loop_ops.qmd', 'weekly.qmd', 'found_links.csv', 'lectures/02b_bril.qmd', 'lectures/14_gpu_compilers.qmd', 'Links-21-6-2024 83848.csv', 'lectures/junk.qmd', 'lectures/images/StaticSingleAssignment_Part40.pdf', 'Links-21-6-2024 84630.csv', 'notebooks/possible_papers.qmd', 'about.qmd', 'notebooks/02aa_reps.ipynb', 'lectures/images/Digraph.gv', 'Links-21-6-2024 84311.csv', 'lectures/images/StaticSingleAssignment_Part41.jpg', 'lectures/bril.qmd', 'lectures/images/StaticSingleAssignment_Part70.jpg', 'notebooks/llvm.ipynb', '.github/workflows/publish.yml', 'lectures/110_whole_program.qmd', 'lectures/images/Digraph.gv.png', 'requirements.txt', 'lectures/02a_representation.qmd.saved', 'lectures/02a_representation.qmd', 'lectures/06_ssa.qmd', 'lectures/images/StaticSingleAssignment_Part46.jpg', 'lectures/01a_performance_measurement.qmd', '.gitignore', 'lectures/images/toy.ts', '.vscode/settings.json', 'setenv.sh', 'lectures/images/StaticSingleAssignment_Part43.jpg', 'lectures/images/my_ast.png', 'styles.css', 'notebooks/02_reps.ipynb', 'Links-21-6-2024 84544.csv', 'check-links.ipynb', 'Links-21-6-2024 8400.csv', 'Class_Overview/schedule.qmd', 'lectures/02b_bril.ipynb', 'lectures/05b_licm.qmd', 'Links-21-6-2024 84235.csv', '_quarto.yml', 'lectures/09_poly.qmd', 'Class_Overview/What_to_do.qmd', 'lectures/07_llvm.ipynb', 'lectures/images/cfg.png', 'lectures/010_compiler_overview.qmd', 'notebooks/bril.ipynb', 'lectures/02a_representation.ipynb'}\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\nclass ctx():\n    def __init__(self, top):\n        self.top = top\n        self.external_links = set()\n        self.missing_files = set()\n        self.extra_files = set()\n        self.seen_urls = set()\n        self.seen_links = set()\n\n\n\n\ndef parseLinks(pageHtml, pageUrl, ctx):\n    soup = BeautifulSoup(pageHtml, 'html.parser')\n\n    #get all the &lt;a&gt; elements from the HTML page\n    allLinks = soup.find_all('a')\n\n    extIntLinks(allLinks, pageUrl, ctx)\n\n\ndef requestMaker(url, ctx):\n    if (url in ctx.seen_urls):\n        return\n    ctx.seen_urls.add(url)\n    try:\n        #make the get request to the url\n        response = requests.get(url)\n\n        #if the request is successful\n        if response.status_code in range(200, 300):\n            #extract the page html content for parsing the links\n            pageHtml = response.text\n            pageUrl = response.url\n\n            #call the parseLink function\n            parseLinks(pageHtml, pageUrl, ctx)\n        \n        else:\n            print(\"Sorry Could not fetch the result status code {response.status_code}!\")\n\n    except Exception as e:\n        print(f\"{e} Could Not Connect to url {url}\")\n\n\nfrom sympy import I\n\n\ndef extIntLinks(allLinks, pageUrl, ctx):\n\n    #go through all the &lt;a&gt; elements list \n    for anchor in allLinks:\n        link = anchor.get(\"href\")   #get the link from the &lt;a&gt; element\n\n        link_orig = link\n\n        if link is None:\n            continue\n        print(f\"link {link}\")\n\n        if link.startswith(\".\"):\n            if link == \"./\":\n                continue\n\n            if link in ctx.seen_links:\n                continue\n            ctx.seen_links.add(link)\n            file = link[2:] # remove ./\n            ## deal with the possible enddings \n\n            if file.startswith(\"revealjs-\"):\n                file = file[10:]\n\n            if file.endswith(\".html\"):\n                file_qmd =  file[:-4]+ \"qmd\"\n                if file_qmd in extra_files:\n                    extra_files.remove(file_qmd)\n                    newurl = ctx.top + '/' + file\n                    requestMaker(newurl, ctx)\n                    continue\n\n        elif link.startswith(ctx.top):\n            print(\"starts with top\")\n            continue\n\n        \n        elif link.startswith(\"#\") :\n            print(\"ref link\")\n\n        elif link.startswith(\"https://capra\"):\n            ctx.external_links.add(link)\n\n        elif link.startswith(\"https://github.com\"):\n            ctx.external_links.add(link)\n\n        elif link.startswith(\"https://quarto.org\"):\n            ctx.external_links.add(link)\n        \n        else: \n            print(\"else \", link, link_orig)\n\n     \n\n\nurl = \"https://normrubin.github.io\"\nrequestMaker(url, ctx(url))\n\nlink ./\nlink ./weekly.html\nlink ./weekly.html\nlink ./weekly.html\nlink ./\nlink ./weekly.html\nlink ./Class_Overview/about.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/about.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/about.html\nlink ../weekly.html\nlink ../Class_Overview/schedule.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/about.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/schedule.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.ipynb\nlink ../lectures/02b_bril.ipynb\nlink ../lectures/03_local.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/schedule.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/sylibus.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/sylibus.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.ipynb\nlink ../lectures/02b_bril.ipynb\nlink ../lectures/03_local.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/What_to_do.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/sylibus.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./Class_Overview/What_to_do.html\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/What_to_do.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/What_to_do.html\nlink https://quarto.org/\nlink ../Class_Overview/sylibus.html\nlink ../lectures/010_compiler_overview.html\nlink https://normrubin.github.io/\nstarts with top\nlink https://github.com/normrubin/normrubin.github.io/edit/main/Class_Overview/What_to_do.qmd\nlink https://github.com/normrubin/normrubin.github.io/issues/new\nlink https://quarto.org/\nlink ./lectures/010_compiler_overview.html\nlink ../weekly.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/010_compiler_overview.html\nlink ../\nlink ../weekly.html\nlink ../Class_Overview/about.html\nlink ../Class_Overview/schedule.html\nlink ../Class_Overview/sylibus.html\nlink ../Class_Overview/What_to_do.html\nlink ../lectures/010_compiler_overview.html\nlink ../lectures/01a_performance_measurement.html\nlink ../lectures/02a_representation.html\nlink ../lectures/02b_bril.html\nlink ../lectures/03_local.html\nlink ../lectures/03b_local_value_numbering.html\nlink ../lectures/04_data_flow.html\nlink ../lectures/05_global.html\nlink ../lectures/05b_licm.html\nlink ../lectures/06_ssa.html\nlink ../lectures/07_llvm.html\nlink ../lectures/08_classic_loop_ops.html\nlink ../lectures/09_poly.html\nlink ../lectures/100_mlir.html\nlink ../lectures/110_whole_program.html\nlink ../lectures/12_memory.html\nlink ../lectures/13_dynamic_compilers.html\nlink ../lectures/14_gpu_compilers.html\nlink ../lectures/bril.html\nlink ../lectures/junk.html\nlink https://capra.cs.cornell.edu/bril/\nlink https://github.com/normrubin/bril\nlink revealjs-compiler_overview.html\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Class_Overview/What_to_do.html",
    "href": "Class_Overview/What_to_do.html",
    "title": "How to do assignments",
    "section": "",
    "text": "#How to How to do assignments",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "href": "Class_Overview/What_to_do.html#mechanics-of-writing-a-blog",
    "title": "How to do assignments",
    "section": "Mechanics of writing a blog",
    "text": "Mechanics of writing a blog\nAssignments get submitted as blog postings. In setting up the class web site I used quarto which lets you write a blog post in markdown (no messy html required). I recommend you use it as well.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "href": "Class_Overview/What_to_do.html#submitting-via-pull-requests",
    "title": "How to do assignments",
    "section": "submitting via pull requests",
    "text": "submitting via pull requests\nTo add a blog post (which you must do for discussion leading and project reports), use a pull request.\nYou’ll want to create a text file in the blog directory with your new post. Use a filename like YYYY-MM-DD-title.md, where the date is the discussion day or the project deadline and the title is up to you.\nInclude a link to your homepage if you have one, but it’s optional. Also write a short bio for yourself (using Markdown), which will appear at the bottom of the post. Then, the rest of the text file is the Markdown text of your blog post.\nIf you want to use math in your blog post, you can use \\(\\pi\\) for inline math and [ e^{i} + 1 = 0 ] for display math.\nTo include images or other resources in your post, make your post into a directory. That is, make a new directory called YYYY-MM-DD-title inside blog. Then, put your text in a file called index.md inside that. Put your images in the same directory and refer to them with relative paths. See the QUARTO docs on for more details.\nYou can preview your writing with any Markdown renderer. To see what it will look like when published, install quarto and type quarto render to preview the entire site.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#homeworks",
    "href": "Class_Overview/What_to_do.html#homeworks",
    "title": "How to do assignments",
    "section": "Homeworks",
    "text": "Homeworks\nTo reinforce the specific compiler techniques we cover in class, you will implement them on your own. In lessons, we will discuss the high-level ideas and provide pseudo-code; your task is to translate these into working code and collect empirical evidence to demonstrate their effectiveness. Completing these implementations will reveal practical challenges that are not apparent from a high-level overview.\nTesting your implementation is crucial. Your goal is to provide convincing evidence that your implementation performs as intended. For instance, an optimization should generally make programs faster without causing any errors. While formal proofs of these properties are likely out of scope, you will need to find alternative ways to gather evidence. Avoid relying solely on existing test cases in the Bril repository, as they are typically insufficient. instead, consider using all the benchmarks available in the repo.\nYou may work individually or in groups of 2–3 students. Upon completing an implementation, follow these steps:\n\nConsider putting all your code online in an open-source repository, such as GitHub (optional but recommended). Create a fork of the class repository if desired.\nSubmit the assignment on Canvas by providing a text file with a URL to your open-source implementation. If you prefer not to open-source your code, you can upload the code itself.\nWrite a brief post in the lesson’s associated GitHub Discussions thread, covering the following topics (one paragraph each is sufficient):\n\nSummarize what you did.\nExplain how you tested your implementation. What test inputs did you use? Do you have any quantitative results?\nDescribe the hardest part of the task and how you addressed this challenge.\n\n\nEnsure all implementation tasks are your own work or done with your group. Although sample implementations for many tasks are available in the GitHub repository, you are not allowed to use this code. Similarly, you may not use implementations open-sourced by past students. I recommend not looking at these implementations while working on your tasks to ensure you genuinely learn the material. However, if you absolutely need to refer to them, you are responsible for managing your own learning process.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#paper-reading-discussion",
    "href": "Class_Overview/What_to_do.html#paper-reading-discussion",
    "title": "How to do assignments",
    "section": "Paper Reading & Discussion",
    "text": "Paper Reading & Discussion\nI’m not sure yet if the discussions will be on Canvas or GitHub Discussions.\nAnother part of this course involves reading and discussing research papers. For each paper (see the schedule), everyone will participate in the discussion in two ways: asynchronously on GitHub Discussions threads before class, and synchronously in class. For every paper, there will be a Discussions topic; post at least one message with your thoughts on the paper before the class discussion. Your comment doesn’t need to be long—just a couple of sentences is fine. You can also respond to others’ thoughts on the thread.\nFor some papers, you will be the discussion leader. Leaders have three extra responsibilities: monitoring and replying to the asynchronous discussion, moderating and guiding the in-class discussion, and synthesizing ideas into a blog post afterward.\nLeader Responsibilities\nAt least a week before the discussion day:\n1) Create a GitHub Discussions thread in the Reading category for your topic.\nDuring the lead-up to the discussion day:\n1) Monitor the GitHub Discussions thread for your topic. Answer questions and offer additional insights as needed.\n1) Collect a list of questions for the in-class discussion. You can create your own or select the best from the online discussion.\nOn the discussion day:\nModerate the discussion. Provide enough background to get to the discussion questions and facilitate the conversation.\nDue one week after the discussion day:\n\nWrite a post about the paper for our course blog. The post should include:\n\nBackground information necessary to understand the paper.\nA detailed summary of the main contributions.\nCritical analysis of the merits and shortcomings of the work.\nDiscussion of the paper’s role in history and its connections to the current computing landscape.\n\n\nIncorporate the best ideas from the online and in-class discussions. You can present your own opinions, the class consensus, or both.\n\n\nWriting the Blog Post\nWhile summarizing the paper, avoid letting direct summary dominate your post. Keep the technical explanation to about a quarter of the length. Prioritize breadth over depth in your summary, and highlight specific contributions instead of covering the entire paper.\nFocus most of your writing on your own commentary: context, criticism, and discussion. Choose a title for your blog post that reflects the main point you want to make about the paper, rather than just the paper’s title.\nFor inspiration, check out previous vd6120 blog posts. However, avoid reading posts about your paper, if they exist.\nPublishing\nPublish the post to the course GitHub repository by opening a pull request. Once your PR is open, announce it on the appropriate Discussions thread to let others know.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#project-proposal",
    "href": "Class_Overview/What_to_do.html#project-proposal",
    "title": "How to do assignments",
    "section": "project Proposal",
    "text": "project Proposal\nThe first deadline is the project proposal. Open a GitHub issue answering these three questions, which are a sort of abbreviated form of the Heilmeier catechism:\nWhat will you do? How will you do it? How will you empirically measure success? You should also list the GitHub usernames of everyone in the group. After you send the PR, submit its URL to the “Project Proposal” assignment on CMS.\nThe instructor will have feedback on how to approach your project.\nImplementation The main phase, of course, is implementing the thing you said you would implement. I recommend you keep a “lab notebook” to log your thoughts, attempts, and frustrations—this will come in handy for the report you’ll write about the project.\nI strongly recommend that you develop your code as an open-source project. Use a publicly-visible version control repository on a host like GitHub, and include an open source license. When you create your repository, comment on your proposal GitHub issue with a link. (If you have a specific objection to open-sourcing your code, that’s OK—include a description of how you’ll share your code privately with me.)\nEvaluation A major part of your project is an empirical evaluation. To design your evaluation strategy, you will need to consider at least these things:\nWhere will you get the input code you’ll use in your evaluation? How will you check the correctness of your implementation? If you’ve implemented an optimization, for example, “correctness” means that the transformed programs behave the same way as the original programs. How will you measure the benefit (in performance, energy, complexity, etc.) of your implementation? How will you present the data you collect from your empirical evaluation? Other questions may be relevant depending on the project you choose. Consider the SIGPLAN empirical evaluation guidelines when you design your methodology.",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "Class_Overview/What_to_do.html#project-experience-report",
    "href": "Class_Overview/What_to_do.html#project-experience-report",
    "title": "How to do assignments",
    "section": "project Experience Report",
    "text": "project Experience Report\nFor the main project deadline, you will write up the project’s outcomes in the form of a post on the course blog. Your writeup should answer these questions in excruciating, exhaustive detail:\nWhat was the goal? What did you do? (Include both the design and the implementation.) What were the hardest parts to get right? Were you successful? (Report rigorously on your empirical evaluation.) As with paper discussions, you can optionally include a video to go along with your blog post.\nTo submit your report, open a pull request in the course’s GitHub repository to add your post to the blog. In your PR description, please include “closes #N” where N is the issue number for your proposal",
    "crumbs": [
      "EECS 7398",
      "How to submit assignments"
    ]
  },
  {
    "objectID": "src/briltxt/docs/tools/swift.html",
    "href": "src/briltxt/docs/tools/swift.html",
    "title": "Swift Library",
    "section": "",
    "text": "Swift Library\nThe Swift bril library, which lives in the bril-swift directory, provides a Swift interface for Bril’s JSON files. It supports the Bril core and the SSA extension.\nUse\n\nTo use this package in a SwiftPM project, add a dependency to your Package.swift:\nlet package = Package(\n  name: \"MyPackage\",\n  dependencies: [\n    .package(name: \"Bril\", path: \"../bril-swift\"),\n  ]\n)\nand add \"Bril\" to the dependencies array for any target that needs it:\ntargets: [\n    .target(\n        name: \"MyTarget\",\n        dependencies: [\"Bril\"]),\n// ...\nThe Bril objects conform to Decodable. Instantiate a program from data as follows:\nimport Bril\n\n/// to read from stdin:\n/// let data = FileHandle.standardInput.availableData\n\n/// or from a string:\n/// let data = \"&lt;Bril JSON&gt;\".data(using: .utf8)!\n\nlet program = try JSONDecoder().decode(Program.self, from: data)\nThe models conform to CustomStringConvertible so printing the Bril representation is simply:\nprint(program)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/ts.html",
    "href": "src/briltxt/docs/tools/ts.html",
    "title": "TypeScript Library",
    "section": "",
    "text": "TypeScript Library\nbril-ts is a TypeScript library for interacting with Bril programs. It is the basis for the reference interpreter and the included type checker, but it is also useful on its own.\nThe library includes:\n\nbril.ts: Type definitions for the Bril language. Parsing a JSON file produces a value of type Program from this module.\nbuilder.ts: A builder class that makes it more convenient to generate Bril programs from front-end compilers.\ntypes.ts: A description of the type signatures for Bril operations, including the core language and all currently known extensions.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/rust.html",
    "href": "src/briltxt/docs/tools/rust.html",
    "title": "Rust Library",
    "section": "",
    "text": "This is a no-frills interface between Bril’s JSON and your Rust code. It supports the Bril core along with the SSA, memory, floating point, speculative execution, char, and source positions extensions.\nUse\n\nInclude this by adding the following to your Cargo.toml:\n[dependencies.bril-rs]\nversion = \"0.1.0\"\npath = \"../bril-rs\"\nfeatures = [\"ssa\", \"memory\", \"float\", \"speculate\", \"position\"]\nEach of the extensions to Bril core is feature gated. To ignore an extension, remove its corresponding string from the features list.\nThere are two helper functions: load_program will read a valid Bril program from stdin, and output_program will write your Bril program to stdout. Otherwise, this library can be treated like any other serde JSON representation.\n\n\nThis library supports fully compatible Rust implementations of bril2txt and bril2json. This library also implements the import extension with a static linker called brild.\nThis library is used in a Rust compiler called rs2bril which supports generating core, float, and memory Bril from a subset of valid Rust.\nThis library is used in a Bril-to-LLVM IR compiler called brillvm which supports core, float, memory, and ssa.\nFor ease of use, these tools can be installed and added to your path by running the following in bril-rs/:\n$ make install\nMake sure that ~/.cargo/bin is on your path. Each of these tools supports the --help flag which specifies some helpful flags.\n\n\n\nTo maintain consistency and cleanliness, run:\ncargo fmt\ncargo clippy\ncargo doc\nmake test\nmake features"
  },
  {
    "objectID": "src/briltxt/docs/tools/rust.html#tools",
    "href": "src/briltxt/docs/tools/rust.html#tools",
    "title": "Rust Library",
    "section": "",
    "text": "This library supports fully compatible Rust implementations of bril2txt and bril2json. This library also implements the import extension with a static linker called brild.\nThis library is used in a Rust compiler called rs2bril which supports generating core, float, and memory Bril from a subset of valid Rust.\nThis library is used in a Bril-to-LLVM IR compiler called brillvm which supports core, float, memory, and ssa.\nFor ease of use, these tools can be installed and added to your path by running the following in bril-rs/:\n$ make install\nMake sure that ~/.cargo/bin is on your path. Each of these tools supports the --help flag which specifies some helpful flags."
  },
  {
    "objectID": "src/briltxt/docs/tools/rust.html#development",
    "href": "src/briltxt/docs/tools/rust.html#development",
    "title": "Rust Library",
    "section": "",
    "text": "To maintain consistency and cleanliness, run:\ncargo fmt\ncargo clippy\ncargo doc\nmake test\nmake features"
  },
  {
    "objectID": "src/briltxt/docs/tools/brilck.html",
    "href": "src/briltxt/docs/tools/brilck.html",
    "title": "Type Checker",
    "section": "",
    "text": "Bril comes with a simple type checker to catch errors statically. It checks the types of instructions in the core language and the floating point, SSA, memory, and speculation extensions. It also checks calls and return values and the labels used in control flow.\n\n\nThe brilck tool uses Deno. Type this:\n$ deno install brilck.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path].\n\n\n\nJust pipe a Bril program into brilck:\nbril2json &lt; benchmarks/fizz-buzz.bril | brilck\nIt will print any problems it finds to standard error. (If it doesn’t find any problems, it doesn’t print anything at all.)\nYou can optionally provide a filename as a (sole) command-line argument. This filename will appear in any error messages for easier parsing when many files are involved.\nConsider supplying the -p flag to the bril2json parser to get source positions in the error messages."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilck.html#install",
    "href": "src/briltxt/docs/tools/brilck.html#install",
    "title": "Type Checker",
    "section": "",
    "text": "The brilck tool uses Deno. Type this:\n$ deno install brilck.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path]."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilck.html#check",
    "href": "src/briltxt/docs/tools/brilck.html#check",
    "title": "Type Checker",
    "section": "",
    "text": "Just pipe a Bril program into brilck:\nbril2json &lt; benchmarks/fizz-buzz.bril | brilck\nIt will print any problems it finds to standard error. (If it doesn’t find any problems, it doesn’t print anything at all.)\nYou can optionally provide a filename as a (sole) command-line argument. This filename will appear in any error messages for easier parsing when many files are involved.\nConsider supplying the -p flag to the bril2json parser to get source positions in the error messages."
  },
  {
    "objectID": "src/briltxt/docs/tools/ocaml.html",
    "href": "src/briltxt/docs/tools/ocaml.html",
    "title": "OCaml Library",
    "section": "",
    "text": "The OCaml bril library, which lives in the bril-ocaml directory, provides an OCaml interface and parser for Bril’s JSON files.\n\n\nTo build the library, you first need to install OCaml. Then, install the dependencies with opam install core yojson.\nTo install the bril-ocaml library:\ngit clone https://github.com/sampsyo/bril path/to/my/bril\nopam pin add -k path bril path/to/brill/bril-ocaml\nopam install bril\nThat’s it! You can include it in your Dune files as bril, like any other OCaml library.\nUse\n\nThe interface for the library can be found in bril.mli—good starting points are from_string, from_file, and to_string. A small code example for the library lives in the count subdirectory.\nIf you wish to make changes to the bril OCaml library, simply hack on the git clone.\nWhen you are done, simply reinstall the package with opam reinstall bril. Restart the build of your local project to pick up changes made to bril-ocaml.\n\n\n\nocamlformat is recommended for style consistency. The dune documentation on Automatic Formatting has information about using ocamlformat with dune."
  },
  {
    "objectID": "src/briltxt/docs/tools/ocaml.html#install",
    "href": "src/briltxt/docs/tools/ocaml.html#install",
    "title": "OCaml Library",
    "section": "",
    "text": "To build the library, you first need to install OCaml. Then, install the dependencies with opam install core yojson.\nTo install the bril-ocaml library:\ngit clone https://github.com/sampsyo/bril path/to/my/bril\nopam pin add -k path bril path/to/brill/bril-ocaml\nopam install bril\nThat’s it! You can include it in your Dune files as bril, like any other OCaml library.\nUse\n\nThe interface for the library can be found in bril.mli—good starting points are from_string, from_file, and to_string. A small code example for the library lives in the count subdirectory.\nIf you wish to make changes to the bril OCaml library, simply hack on the git clone.\nWhen you are done, simply reinstall the package with opam reinstall bril. Restart the build of your local project to pick up changes made to bril-ocaml."
  },
  {
    "objectID": "src/briltxt/docs/tools/ocaml.html#for-development",
    "href": "src/briltxt/docs/tools/ocaml.html#for-development",
    "title": "OCaml Library",
    "section": "",
    "text": "ocamlformat is recommended for style consistency. The dune documentation on Automatic Formatting has information about using ocamlformat with dune."
  },
  {
    "objectID": "src/briltxt/docs/tools/ts2bril.html",
    "href": "src/briltxt/docs/tools/ts2bril.html",
    "title": "TypeScript-to-Bril Compiler",
    "section": "",
    "text": "Bril comes with a compiler from a very small subset of TypeScript to Bril called ts2bril.\nIt is not supposed to make it easy to port existing JavaScript code to Bril; it is a convenient way to write larger, more interesting programs without manually fiddling with Bril directly. It also emits somewhat obviously inefficient code to keep the compiler simple; some obvious optimizations can go a long way.\n\n\nThe TypeScript compiler uses Deno. Type this:\n$ deno install --allow-env --allow-read ts2bril.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path].\nUse\n\nCompile a TypeScript program to Bril by giving a filename on the command line:\n$ ts2bril mycode.ts\nThe compiler supports both integers (from core Bril) and floating point numbers. Perhaps somewhat surprisingly, plain JavaScript numbers and the TypeScript number type map to float in Bril. For integers, use JavaScript big integers whenever you need an integer, like this:\nvar x: bigint = 5n;\nprintInt(x);\n\nfunction printInt(x: bigint) {\n    console.log(x);\n}\nThe n suffix on literals distinguishes integer literals, and the bigint type in TypeScript reflects them."
  },
  {
    "objectID": "src/briltxt/docs/tools/ts2bril.html#install",
    "href": "src/briltxt/docs/tools/ts2bril.html#install",
    "title": "TypeScript-to-Bril Compiler",
    "section": "",
    "text": "The TypeScript compiler uses Deno. Type this:\n$ deno install --allow-env --allow-read ts2bril.ts\nIf you haven’t already, you will then need to add $HOME/.deno/bin to [your $PATH][path].\nUse\n\nCompile a TypeScript program to Bril by giving a filename on the command line:\n$ ts2bril mycode.ts\nThe compiler supports both integers (from core Bril) and floating point numbers. Perhaps somewhat surprisingly, plain JavaScript numbers and the TypeScript number type map to float in Bril. For integers, use JavaScript big integers whenever you need an integer, like this:\nvar x: bigint = 5n;\nprintInt(x);\n\nfunction printInt(x: bigint) {\n    console.log(x);\n}\nThe n suffix on literals distinguishes integer literals, and the bigint type in TypeScript reflects them."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html",
    "href": "src/briltxt/docs/tools/brilift.html",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Brilift is a ahead-of-time or just-in-time compiler from Bril to native code using the Cranelift code generator. It supports core Bril, floating point, and the memory extension.\nIn AOT mode, Brilift emits .o files and also provides a simple run-time library. By linking these together, you get a complete native executable. In JIT mode, Brilift mimics an interpreter.\n\n\nBrilift is a Rust project using the bril-rs library. You can build it using Cargo:\n$ cd brilift\n$ cargo run -- --help\n$ cargo install --path .  # If you want the executable on your $PATH.\n\n\n\nProvide the brilift executable with a Bril JSON program:\n$ bril2json &lt; something.bril | brilift\nBy default, Brilift produces a file bril.o. (You can pick your own output filename with -o something.o; see the full list of options below.)\nA complete executable will also need our runtime library, which is in rt.c. There is a convenient Makefile rule to produce rt.o:\n$ make rt.o\nThen, you will want to link rt.o and bril.o to produce an executable:\n$ cc bril.o rt.o -o myprog\nIf your Bril @main function takes arguments, those are now command-line arguments to the myprog executable.\n\n\n\nUse the -j flag to compile and run the program immediately:\n$ bril2json &lt; something.bril | brilift -j\nPass any arguments to the Bril @main function as command-line arguments to Brilift. For example, if you have a function @main(foo: int, bar: bool), you can type brilift -j 42 true.\n\n\n\nType brilift --help to see the full list of options:\n\n-j: JIT-compile the code and run it immediately, instead of AOT-compiling an object file (the default).\n-O [none|speed|speed_and_size]: An optimization level, according to Cranelift. The default is none.\n-v: Enable lots of logging from the Cranelift library.\n-d: Dump the Cranelift IR text for debugging.\n\nThese options are only relevant in AOT mode:\n\n-o &lt;FILE&gt;: Place the output object file in &lt;FILE&gt; instead of bril.o (the default).\n-t &lt;TARGET&gt;: Specify the target triple, as interpreted by Cranelift. These triples resemble the target triples that LLVM also understands, for example. For instance, x86_64-unknown-darwin-macho is the triple for macOS on Intel processors."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#build",
    "href": "src/briltxt/docs/tools/brilift.html#build",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Brilift is a Rust project using the bril-rs library. You can build it using Cargo:\n$ cd brilift\n$ cargo run -- --help\n$ cargo install --path .  # If you want the executable on your $PATH."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#ahead-of-time-compilation",
    "href": "src/briltxt/docs/tools/brilift.html#ahead-of-time-compilation",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Provide the brilift executable with a Bril JSON program:\n$ bril2json &lt; something.bril | brilift\nBy default, Brilift produces a file bril.o. (You can pick your own output filename with -o something.o; see the full list of options below.)\nA complete executable will also need our runtime library, which is in rt.c. There is a convenient Makefile rule to produce rt.o:\n$ make rt.o\nThen, you will want to link rt.o and bril.o to produce an executable:\n$ cc bril.o rt.o -o myprog\nIf your Bril @main function takes arguments, those are now command-line arguments to the myprog executable."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#just-in-time-compilation",
    "href": "src/briltxt/docs/tools/brilift.html#just-in-time-compilation",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Use the -j flag to compile and run the program immediately:\n$ bril2json &lt; something.bril | brilift -j\nPass any arguments to the Bril @main function as command-line arguments to Brilift. For example, if you have a function @main(foo: int, bar: bool), you can type brilift -j 42 true."
  },
  {
    "objectID": "src/briltxt/docs/tools/brilift.html#options",
    "href": "src/briltxt/docs/tools/brilift.html#options",
    "title": "Cranelift Compiler",
    "section": "",
    "text": "Type brilift --help to see the full list of options:\n\n-j: JIT-compile the code and run it immediately, instead of AOT-compiling an object file (the default).\n-O [none|speed|speed_and_size]: An optimization level, according to Cranelift. The default is none.\n-v: Enable lots of logging from the Cranelift library.\n-d: Dump the Cranelift IR text for debugging.\n\nThese options are only relevant in AOT mode:\n\n-o &lt;FILE&gt;: Place the output object file in &lt;FILE&gt; instead of bril.o (the default).\n-t &lt;TARGET&gt;: Specify the target triple, as interpreted by Cranelift. These triples resemble the target triples that LLVM also understands, for example. For instance, x86_64-unknown-darwin-macho is the triple for macOS on Intel processors."
  },
  {
    "objectID": "src/briltxt/docs/tools/bench.html",
    "href": "src/briltxt/docs/tools/bench.html",
    "title": "Benchmarks",
    "section": "",
    "text": "Benchmarks\nThe bench directory in the Bril repository contains a fledgling suite of microbenchmarks that you can use to measure the impact of your optimizations. (Benchmarks are different from tests because they are meant to actually calculate something instead of just exercising a language feature.)\nThe current benchmarks are:\n\nackermann: Print the value of Ack(m, n), the two-argument Ackermann–Péter function.\nadj2csr: Convert a graph in adjacency matrix format (dense representation) to Compressed Sparse Row (CSR) format (sparse representation). The random graph is generated using the same linear congruential generator.\nadler32: Computes the Adler-32 Checksum of an integer array.\narmstrong: Determines if the input is an Armstrong number, a number that is the sum of its own digits each raised to the power of the number of digits.\nbinary-fmt: Print the binary format for the given positive integer.\nbinary-search: Search a target integer within an integer array, outputs the index of target.\nbirthday: Simulation of the birthday paradox with an input of n people in a given room.\nbitwise-ops: Computes the OR, AND, or XOR between two 64-bit integers. (Three modes: 0 = AND, 1 = OR, 2 = XOR)\nbitshift: Computes the LEFTSHIFT and RIGHTSHIFT for any integer, also implements an efficient pow function for integers\nbubblesort: Sorting algorithm that works by repeatedly swapping the adjacent elements if they are in wrong order.\ncatalan: Print the nth term in the Catalan sequence, compute using recursive function calls.\ncheck-primes: Check the first n natural numbers for primality, printing out a 1 if the number is prime and a 0 if it’s not.\ncholesky: Perform Cholesky decomposition of a Hermitian and positive definite matrix. The result is validated by comparing with Python’s scipy.linalg.cholesky.\ncollatz: Print the Collatz sequence starting at n. Note: it is not known whether this will terminate for all n.\nconjugate-gradient: Uses conjugate gradients to solve Ax=b for any arbitrary positive semidefinite A.\ncordic: Print an approximation of sine(radians) using 8 iterations of the CORDIC algorithm.\ncsrmv: Multiply a sparse matrix in the Compressed Sparse Row (CSR) format with a dense vector. The matrix and input vector are generated using a Linear Feedback Shift Register random number generator.\ndigial-root: Computes the digital root of the input number.\ndead-branch: Repeatedly call a br instruction whose condition always evaluates to false. The dead branch should be pruned by a smart compiler.\ndot-product: Computes the dot product of two vectors.\neight-queens: Counts the number of solutions for n queens problem, a generalization of Eight queens puzzle.\neuclid: Calculates the greatest common divisor between two large numbers using the Euclidean Algorithm with a helper function for the modulo operator.\neuler: Approximates Euler’s number using the Taylor series.\nfact: Prints the factorial of n, computing it recursively.\nfactors: Print the factors of the n using the trial division method.\nfib: Calculate the nth Fibonacci number by allocating and filling an array of numbers up to that point.\nfizz-buzz: The infamous programming test.\nfunction_call: For benchmarking the overhead of simple function calls.\ngcd: Calculate Greatest Common Divisor (GCD) of two input positive integer using Euclidean algorithm.\nhanoi: Print the solution to the n-disk Tower of Hanoi puzzle.\nis-decreasing: Print if a number contains strictly decreasing digits.\nlcm: Compute LCM for two numbers using a very inefficient loop.\nloopfact: Compute n! imperatively using a loop.\nmajor-elm: Find the majority element in an array using a linear time voting algorithm.\nmandelbrot: Generates a really low resolution, ascii, mandelbrot set.\nmat-inv : Calculates the inverse of a 3x3 matrix and prints it out.\nmat-mul: Multiplies two nxn matrices using the naive matrix multiplication algorithm. The matrices are randomly generated using a linear congruential generator.\nmax-subarray: solution to the classic Maximum Subarray problem.\nmod_inv: Calculates the modular inverse of n under to a prime modulus p.\nnewton: Calculate the square root of 99,999 using the newton method\nnorm: Calculate the euclidean norm of a vector\nn_root: Calculate nth root of a float using newton’s method.\norders: Compute the order ord(u) for each u in a cyclic group &lt;Zn,+&gt; of integers modulo n under the group operation + (modulo n). Set the second argument is_lcm to true if you would like to compute the orders using the lowest common multiple and otherwise the program will use the greatest common divisor.\npascals-row: Computes a row in Pascal’s Triangle.\npalindrome: Outputs a 0-1 value indicating whether the input is a palindrome number.\nperfect: Check if input argument is a perfect number. Returns output as Unix style return code.\npow: Computes the n^th power of a given (float) number.\nprimes-between: Print the primes in the interval [a, b].\nprimitive-root: Computes a primitive root modulo a prime number input.\npythagorean_triple: Prints all Pythagorean triples with the given c, if such triples exist. An intentionally very naive implementation.\nquadratic: The quadratic formula, including a hand-rolled implementation of square root.\nquickselect: Find the kth smallest element in an array using the quickselect algorithm.\nquicksort: Quicksort using the Lomuto partition scheme.\nquicksort-hoare: Quicksort using Hoare partioning and median of three pivot selection.\nrecfact: Compute n! using recursive function calls.\nrectangles-area-difference: Output the difference between the areas of rectangles (as a positive value) given their respective side lengths.\nfitsinside: Output whether or not a rectangle fits inside of another rectangle given the width and height lengths.\nrelative-primes: Print all numbers relatively prime to n using Euclidean algorithm.\nriemann: Prints the left, midpoint, and right Riemann Sums for a specified function, which is the square function in this benchmark.\nsieve: Print all prime numbers up to n using the Sieve of Eratosthenes.\nsqrt: Implements the Newton–Raphson Method of approximating the square root of a number to arbitrary precision\nsum-bit: Print the number of 1-bits in the binary representation of the input integer.\nsum-check: Compute the sum of [1, n] by both loop and formula, and check if the result is the same.\nsum-divisors: Prints the positive integer divisors of the input integer, followed by the sum of the divisors.\nsum-sq-diff: Output the difference between the sum of the squares of the first n natural numbers and the square of their sum.\ntotient: Computes Euler’s totient function on an input integer n.\ntwo-sum: Print the indices of two distinct elements in the list [2, 7, 11, 13] whose sum equals the input.\nup-arrow: Computes Knuth’s up arrow notation, with the first argument being the number, the second argument being the number of Knuth’s up arrows, and the third argument being the number of repeats.\nvsmul: Multiplies a constant scalar to each element of a large array. Tests the performance of vectorization optimizations.\nreverse: Compute number with reversed digits (e.g. 123 -&gt; 321).\n\nCredit for several of these benchmarks goes to Alexa VanHattum and Gregory Yauney, who implemented them for their global value numbering project.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html",
    "href": "src/briltxt/docs/lang/syntax.html",
    "title": "Syntax Reference",
    "section": "",
    "text": "Bril programs are JSON objects that directly represent abstract syntax. This chapter exhaustively describes the structure of that syntax. All objects are JSON values of one sort or another.\n\n\n{ \"functions\": [&lt;Function&gt;, ...] }\nA Program is the top-level object. It has one key:\n\nfunctions, a list of Function objects.\n\n\n\n\n\"&lt;string&gt;\"\n{\"&lt;string&gt;\": &lt;Type&gt;}\nThere are two kinds of types: primitive types, whose syntax is just a string, and parameterized types, which wrap a smaller type. The semantics chapters list the particular types that are available—for example, core Bril defines the basic primitive types int and bool and the memory extension defines a parameterized pointer type.\n\n\n\n{\n  \"name\": \"&lt;string&gt;\",\n  \"args\": [{\"name\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;}, ...]?,\n  \"type\": &lt;Type&gt;?,\n  \"instrs\": [&lt;Instruction&gt;, ...]\n}\nA Function object represents a (first-order) procedure consisting of a sequence of instructions. There are four fields:\n\nname, a string.\nargs, optionally, a list of arguments, which consist of a name and a type. Missing args is the same as an empty list.\nOptionally, type, a Type object: the function’s return type, if any.\ninstrs, a list of Label and Instruction objects.\n\nWhen a function runs, it creates an activation record and transfers control to the first instruction in the sequence.\nA Bril program is executable if it contains a function named main. When execution starts, this function will be invoked. The main function can have arguments (which implementations may supply using command-line arguments) but must not have a return type.\n\n\n\n{ \"label\": \"&lt;string&gt;\" }\nA Label marks a position in an instruction sequence as a destination for control transfers. It only has one key:\n\nlabel, a string. This is the name that jump and branch instructions will use to transfer control to this position and proceed to execute the following instruction.\n\n\n\n\n{ \"op\": \"&lt;string&gt;\", ... }\nAn Instruction represents a unit of computational work. Every instruction must have this field:\n\nop, a string: the opcode that determines what the instruction does. (See the Core Language section and the subsequent extension sections for listings of the available opcodes.)\n\nDepending on the opcode, the instruction might also have:\n\ndest, a string: the name of the variable where the operation’s result is stored.\ntype, a Type object: the type of the destination variable.\nargs, a list of strings: the arguments to the operation. These are names of variables.\nfuncs, a list of strings: any names of functions referenced by the instruction.\nlabels, a list of strings: any label names referenced by the instruction.\n\nThere are three kinds of instructions: constants, value operations, and effect operations.\n\n\n{ \"op\": \"const\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"value\": &lt;literal&gt; }\nA Constant is an instruction that produces a literal value. Its op field must be the string \"const\". It has the dest and type fields described above, and also:\n\nvalue, the literal value for the constant. This is either a JSON number or a JSON Boolean value. The type field must match—i.e., it must be “int” or “bool”, respectively.\n\n\n\n\n{ \"op\": \"&lt;string&gt;\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nA Value Operation is an instruction that takes arguments, does some computation, and produces a value. Like a Constant, it has the dest and type fields described above, and also any of these three optional fields:\n\nargs, a list of strings. These are variable names defined elsewhere in the same function.\nfuncs, a list of strings. The names of any functions that this instruction references. For example, core Bril’s call instruction takes one function name.\nlabels, a list of strings. The names of any labels within the current function that the instruction references. For example, core Bril’s jump and branch instructions have target labels.\n\nIn all three cases, these keys may be missing and the semantics are identical to mapping to an empty list.\n\n\n\n{ \"op\": \"&lt;string&gt;\",\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nAn Effect Operation is like a Value Operation but it does not produce a value. It also has the optional args, funcs, and labels fields.\n\n\n\n\nAny syntax object may optionally have position fields to reflect a source position:\n{ ..., \"pos\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;},\n       \"pos_end\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;}?,\n       \"src\": \"&lt;string&gt;\"? }\nThe pos and pos_end objects have two keys: row (the line number) and col (the column number within the line). The src object can optionally provide the absolute path to a file which is referenced to by the source position. If pos_end is provided, it must be equal to or greater than pos. Front-end compilers that generate Bril code may add this information to help with debugging. The text format parser, for example, can optionally add source positions. However, tools can’t require positions to exist, to consistently exist or not on all syntax objects in a program, or to follow any particular rules."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#program",
    "href": "src/briltxt/docs/lang/syntax.html#program",
    "title": "Syntax Reference",
    "section": "",
    "text": "{ \"functions\": [&lt;Function&gt;, ...] }\nA Program is the top-level object. It has one key:\n\nfunctions, a list of Function objects."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#type",
    "href": "src/briltxt/docs/lang/syntax.html#type",
    "title": "Syntax Reference",
    "section": "",
    "text": "\"&lt;string&gt;\"\n{\"&lt;string&gt;\": &lt;Type&gt;}\nThere are two kinds of types: primitive types, whose syntax is just a string, and parameterized types, which wrap a smaller type. The semantics chapters list the particular types that are available—for example, core Bril defines the basic primitive types int and bool and the memory extension defines a parameterized pointer type."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#function",
    "href": "src/briltxt/docs/lang/syntax.html#function",
    "title": "Syntax Reference",
    "section": "",
    "text": "{\n  \"name\": \"&lt;string&gt;\",\n  \"args\": [{\"name\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;}, ...]?,\n  \"type\": &lt;Type&gt;?,\n  \"instrs\": [&lt;Instruction&gt;, ...]\n}\nA Function object represents a (first-order) procedure consisting of a sequence of instructions. There are four fields:\n\nname, a string.\nargs, optionally, a list of arguments, which consist of a name and a type. Missing args is the same as an empty list.\nOptionally, type, a Type object: the function’s return type, if any.\ninstrs, a list of Label and Instruction objects.\n\nWhen a function runs, it creates an activation record and transfers control to the first instruction in the sequence.\nA Bril program is executable if it contains a function named main. When execution starts, this function will be invoked. The main function can have arguments (which implementations may supply using command-line arguments) but must not have a return type."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#label",
    "href": "src/briltxt/docs/lang/syntax.html#label",
    "title": "Syntax Reference",
    "section": "",
    "text": "{ \"label\": \"&lt;string&gt;\" }\nA Label marks a position in an instruction sequence as a destination for control transfers. It only has one key:\n\nlabel, a string. This is the name that jump and branch instructions will use to transfer control to this position and proceed to execute the following instruction."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#instruction",
    "href": "src/briltxt/docs/lang/syntax.html#instruction",
    "title": "Syntax Reference",
    "section": "",
    "text": "{ \"op\": \"&lt;string&gt;\", ... }\nAn Instruction represents a unit of computational work. Every instruction must have this field:\n\nop, a string: the opcode that determines what the instruction does. (See the Core Language section and the subsequent extension sections for listings of the available opcodes.)\n\nDepending on the opcode, the instruction might also have:\n\ndest, a string: the name of the variable where the operation’s result is stored.\ntype, a Type object: the type of the destination variable.\nargs, a list of strings: the arguments to the operation. These are names of variables.\nfuncs, a list of strings: any names of functions referenced by the instruction.\nlabels, a list of strings: any label names referenced by the instruction.\n\nThere are three kinds of instructions: constants, value operations, and effect operations.\n\n\n{ \"op\": \"const\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"value\": &lt;literal&gt; }\nA Constant is an instruction that produces a literal value. Its op field must be the string \"const\". It has the dest and type fields described above, and also:\n\nvalue, the literal value for the constant. This is either a JSON number or a JSON Boolean value. The type field must match—i.e., it must be “int” or “bool”, respectively.\n\n\n\n\n{ \"op\": \"&lt;string&gt;\", \"dest\": \"&lt;string&gt;\", \"type\": &lt;Type&gt;,\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nA Value Operation is an instruction that takes arguments, does some computation, and produces a value. Like a Constant, it has the dest and type fields described above, and also any of these three optional fields:\n\nargs, a list of strings. These are variable names defined elsewhere in the same function.\nfuncs, a list of strings. The names of any functions that this instruction references. For example, core Bril’s call instruction takes one function name.\nlabels, a list of strings. The names of any labels within the current function that the instruction references. For example, core Bril’s jump and branch instructions have target labels.\n\nIn all three cases, these keys may be missing and the semantics are identical to mapping to an empty list.\n\n\n\n{ \"op\": \"&lt;string&gt;\",\n  \"args\": [\"&lt;string&gt;\", ...]?,\n  \"funcs\": [\"&lt;string&gt;\", ...]?,\n  \"labels\": [\"&lt;string&gt;\", ...]? }\nAn Effect Operation is like a Value Operation but it does not produce a value. It also has the optional args, funcs, and labels fields."
  },
  {
    "objectID": "src/briltxt/docs/lang/syntax.html#source-positions",
    "href": "src/briltxt/docs/lang/syntax.html#source-positions",
    "title": "Syntax Reference",
    "section": "",
    "text": "Any syntax object may optionally have position fields to reflect a source position:\n{ ..., \"pos\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;},\n       \"pos_end\": {\"row\": &lt;int&gt;, \"col\": &lt;int&gt;}?,\n       \"src\": \"&lt;string&gt;\"? }\nThe pos and pos_end objects have two keys: row (the line number) and col (the column number within the line). The src object can optionally provide the absolute path to a file which is referenced to by the source position. If pos_end is provided, it must be equal to or greater than pos. Front-end compilers that generate Bril code may add this information to help with debugging. The text format parser, for example, can optionally add source positions. However, tools can’t require positions to exist, to consistently exist or not on all syntax objects in a program, or to follow any particular rules."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html",
    "href": "src/briltxt/docs/lang/char.html",
    "title": "Character",
    "section": "",
    "text": "The character extension adds one new base type:\n\"char\"\nCharacters are a singular Unicode character.\n\n\n\nComparison operators, which take two char values and produce a bool:\n\nceq\nclt\ncle\ncgt\ncge\n\nConversion operators:\n\nchar2int: One argument: a variable of type char. Returns an integer representing the Unicode code point of the given value.\nint2char: One argument: a variable of type int. Returns the corresponding Unicode character. Throws if the value does not correspond to a valid Unicode code point.\n\n\n\n\nThe core print operation prints char values."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html#types",
    "href": "src/briltxt/docs/lang/char.html#types",
    "title": "Character",
    "section": "",
    "text": "The character extension adds one new base type:\n\"char\"\nCharacters are a singular Unicode character."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html#operations",
    "href": "src/briltxt/docs/lang/char.html#operations",
    "title": "Character",
    "section": "",
    "text": "Comparison operators, which take two char values and produce a bool:\n\nceq\nclt\ncle\ncgt\ncge\n\nConversion operators:\n\nchar2int: One argument: a variable of type char. Returns an integer representing the Unicode code point of the given value.\nint2char: One argument: a variable of type int. Returns the corresponding Unicode character. Throws if the value does not correspond to a valid Unicode code point."
  },
  {
    "objectID": "src/briltxt/docs/lang/char.html#printing",
    "href": "src/briltxt/docs/lang/char.html#printing",
    "title": "Character",
    "section": "",
    "text": "The core print operation prints char values."
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html",
    "href": "src/briltxt/docs/lang/import.html",
    "title": "Import",
    "section": "",
    "text": "Typically, Bril programs are self-contained: they only use functions defined elsewhere in the same program. This import extension lets Bril code use functions defined in other files.\nA Bril import refers to a file and lists the functions to import from it, like this:\n{\n    \"path\": \"my_library.json\",\n    \"functions\": [{\"name\": \"libfunc\"}]\n}\nThis import assumes that there’s a Bril file called my_library.json, and that it declares a function @libfunc. The current Bril file may now invoke @libfunc as if it were defined locally.\n\n\nThe top-level Bril program is extended with an imports field:\n{ \"functions\": [&lt;Function&gt;, ...], \"imports\": [&lt;Import&gt;, ...] }\nEach import object has this syntax:\n{\n    \"path\": \"&lt;string&gt;\",\n    \"functions\": [\n        { \"name\": \"&lt;string&gt;\", \"alias\": \"&lt;string&gt;\"? },\n        ...\n    ]\n}\nThe path is a relative reference to a Bril JSON file containing the functions to import. In the objects in the functions list, the name is the original name of the function, and the optional alias is the local name that the program will use to refer to the function. A missing alias makes the local name equal to the original name.\nIt is an error to refer to functions that do not exist, or to create naming conflicts between imports and local functions (or between different imports). Import cycles are allowed.\n\n\n\nIn Bril’s text format, the import syntax looks like this:\nfrom \"something.json\" import @libfunc, @otherfunc as @myfunc;\n\n\n\nWe do not define the exact mechanism for using the path string to find the file to import. Reasonable options include:\n\nResolve the path relative to the file the import appears in.\nUse a pre-defined set of library search paths.\n\nWe only specify what it means to import JSON files; implementations can choose to allow importing other kinds of files too (e.g., text-format source code)."
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html#syntax",
    "href": "src/briltxt/docs/lang/import.html#syntax",
    "title": "Import",
    "section": "",
    "text": "The top-level Bril program is extended with an imports field:\n{ \"functions\": [&lt;Function&gt;, ...], \"imports\": [&lt;Import&gt;, ...] }\nEach import object has this syntax:\n{\n    \"path\": \"&lt;string&gt;\",\n    \"functions\": [\n        { \"name\": \"&lt;string&gt;\", \"alias\": \"&lt;string&gt;\"? },\n        ...\n    ]\n}\nThe path is a relative reference to a Bril JSON file containing the functions to import. In the objects in the functions list, the name is the original name of the function, and the optional alias is the local name that the program will use to refer to the function. A missing alias makes the local name equal to the original name.\nIt is an error to refer to functions that do not exist, or to create naming conflicts between imports and local functions (or between different imports). Import cycles are allowed."
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html#text-format",
    "href": "src/briltxt/docs/lang/import.html#text-format",
    "title": "Import",
    "section": "",
    "text": "In Bril’s text format, the import syntax looks like this:\nfrom \"something.json\" import @libfunc, @otherfunc as @myfunc;"
  },
  {
    "objectID": "src/briltxt/docs/lang/import.html#search-paths",
    "href": "src/briltxt/docs/lang/import.html#search-paths",
    "title": "Import",
    "section": "",
    "text": "We do not define the exact mechanism for using the path string to find the file to import. Reasonable options include:\n\nResolve the path relative to the file the import appears in.\nUse a pre-defined set of library search paths.\n\nWe only specify what it means to import JSON files; implementations can choose to allow importing other kinds of files too (e.g., text-format source code)."
  },
  {
    "objectID": "src/briltxt/docs/lang/ssa.html",
    "href": "src/briltxt/docs/lang/ssa.html",
    "title": "Static Single Assignment (SSA) Form",
    "section": "",
    "text": "This language extension lets you represent Bril programs in static single assignment (SSA) form. As in the standard definition, an SSA-form Bril program contains only one assignment per variable, globally—that is, variables within a function cannot be reassigned. This extension adds ϕ-nodes to the language.\n\n\nThere is one new instruction:\n\nphi: Takes n labels and n arguments, for any n. Copies the value of the ith argument, where i is the index of the second-most-recently-executed label. (It is an error to use a phi instruction when two labels have not yet executed, or when the instruction does not contain an entry for the second-most-recently-executed label.)\n\nIntuitively, a phi instruction takes its value according to the current basic block’s predecessor.\n\n\n\nIn the text format, you can write phi instructions like this:\nx: int = phi a .here b .there;\nThe text format doesn’t care how you interleave arguments and labels, so this is equivalent to (but more readable than) phi a b .here .there. The “second-most-recent label” rule means that the labels refer to predecessor basic blocks, if you imagine blocks being “named” by their labels.\nHere’s a small example:\n.top:\n  a: int = const 5;\n  br cond .here .there;\n.here:\n  b: int = const 7;\n.there:\n  c: int = phi a .top b .here;\n  print c;\nA phi instruction is sensitive to the incoming CFG edge that execution took to arrive at the current block. The phi instruction in this program, for example, gets its value from a if control came from the .top block and b if control came from the .here block.\nThe reference interpreter can supports programs in SSA form because it can faithfully execute the phi instruction."
  },
  {
    "objectID": "src/briltxt/docs/lang/ssa.html#operations",
    "href": "src/briltxt/docs/lang/ssa.html#operations",
    "title": "Static Single Assignment (SSA) Form",
    "section": "",
    "text": "There is one new instruction:\n\nphi: Takes n labels and n arguments, for any n. Copies the value of the ith argument, where i is the index of the second-most-recently-executed label. (It is an error to use a phi instruction when two labels have not yet executed, or when the instruction does not contain an entry for the second-most-recently-executed label.)\n\nIntuitively, a phi instruction takes its value according to the current basic block’s predecessor."
  },
  {
    "objectID": "src/briltxt/docs/lang/ssa.html#examples",
    "href": "src/briltxt/docs/lang/ssa.html#examples",
    "title": "Static Single Assignment (SSA) Form",
    "section": "",
    "text": "In the text format, you can write phi instructions like this:\nx: int = phi a .here b .there;\nThe text format doesn’t care how you interleave arguments and labels, so this is equivalent to (but more readable than) phi a b .here .there. The “second-most-recent label” rule means that the labels refer to predecessor basic blocks, if you imagine blocks being “named” by their labels.\nHere’s a small example:\n.top:\n  a: int = const 5;\n  br cond .here .there;\n.here:\n  b: int = const 7;\n.there:\n  c: int = phi a .top b .here;\n  print c;\nA phi instruction is sensitive to the incoming CFG edge that execution took to arrive at the current block. The phi instruction in this program, for example, gets its value from a if control came from the .top block and b if control came from the .here block.\nThe reference interpreter can supports programs in SSA form because it can faithfully execute the phi instruction."
  },
  {
    "objectID": "src/briltxt/docs/lang/wellformed.html",
    "href": "src/briltxt/docs/lang/wellformed.html",
    "title": "Well Formedness",
    "section": "",
    "text": "Well Formedness\nNot every syntactically complete Bril program is well formed. Here is an incomplete list of rules that well-formed Bril programs must follow:\n\nInstructions may name variables as arguments when they are defined elsewhere in the function. Similarly, they may only refer to labels that exist within the same function, and they can only refer to functions defined somewhere in the same file.\nDynamically speaking, during execution, instructions may refer only to variables that have already been defined earlier in execution. (This is a dynamic property, not a static property.)\nEvery variable may have only a single type within a function. It is illegal to have two assignments to the same variable with different types, even if the function’s logic guarantees that it is impossible to execute both instructions in a single call.\nMany operations have constraints on the types of arguments they can take; well-formed programs always provide the right type of value.\n\nTools do not need to handle ill-formed Bril programs. As someone working with Bril, you never need to check for well-formedness and can do anything when fed with ill-formed code, including silently working just fine, producing ill-formed output, or crashing and burning.\nTo help check for well-formedness, the reference interpreter has many dynamic checks and the type inference tool can check types statically.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "old-weekly.html",
    "href": "old-weekly.html",
    "title": "EECS7398 Weekly Schedule",
    "section": "",
    "text": "tbl-colwidths: [10,20,20,20, 15, 15 ]\nSince the is the first time this course is offered. This is a tentative schedule.\n\n\n\n\n\n\nWarning\n\n\n\nNeed to figure out where discussions are kept. Is it on github? or in canvas?\n\n\n\n\n\n\n\n\n\n\n\n\n\nweek\nday\nDate\ntopic\ndiscussions\nDue\n\n\n\n\n1\nFriday\nSept 6\nCompiler overview and structure\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nTuesday\nSept 10\nPerformance Measurement\n\nhw0\n\n\n\npaper 1 - Producing Wrong Data Without Doing Anything Obviously Wrong! Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, and Peter F. Sweeney. ASPLOS 2009.\nLEADER: Norm using Adrian’s blog)\nSIGPLAN Empirical Evaluation Guidelines\n\n\n\n\n\n\n\n\n\n\n\n2\nFriday\nSept 13\nRepresenting programs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nTuesday\nSept 17\nOverview of Bril\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nFriday\nSept 20\nLocal analysis and optimization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nTuesday\nSept 24\nValue numbering\n\nhw1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nFriday\nSept 27\nData flow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\nTuesday\nOct 1\nGlobal analysis\n\nhw2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\nFriday\nOct 4\nloop invariant code motion\n\n\n\n\n\npaper 2 - iterative data-flow analysis, revisited Cooper, Keith D.; Harvey, Timothy J.; Kennedy, Ken (2004-03-26) [November 2002]. pldi 2002\n\n\n\n\n\n\n\n\n\n\n\n6\nTuesday\nOct 8\nStatic single assignment\n\n\n\n\n\nDynamo: A Transparent Dynamic Optimization System Vasanth Bala vas@hpl.hp.com chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://dl.acm.org/doi/pdf/10.1145/349299.349303\n\n\n\n\n\n\n\n\n\n\n\n6\nFriday\nOct 11\ncontinued\n\n\n\n\n\nGlobal value numbers and redundant computations chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://dl.acm.org/doi/pdf/10.1145/73560.73562\n\n\n\n\n\n\n\n\n\n\n\n7\nTuesday\nOct 15\nLLVM\n\n\n\n\n\nhttps://dl.acm.org/doi/10.1145/1064978.1065042 Threads cannot be implemented as a library\n\n\n\n\n\n\n\n\n\n\n\n7\nFriday\nOct 18\ncontinued\n\n\n\n\n\nfinal project propsal ????\n\n\n\n\n\n\n\n\n\n\n\n8\nTuesday\nOct 22\nClassical loop optimizations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\nFriday\nOct 25\nPolyhedral analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\nTuesday\nOct 29\ncontinued\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\nFriday\nNov 1\nMLIR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\nTuesday\nNov 5\ncontinued\n\n\n\n\n\nSuperoptimizer: A Look at the Smallest Program Alexia Massalin. ASPLOS 1987.\n\n\n\n\n\n\n\n\n\n\n\n10\nFriday\nNov 8\nInterprocedural Analysis\n\n\n\n\n\nFormal Verification of a Realistic Compiler Xavier Leroy. CACM in 2009.\n\n\n\n\n\n\n\n\n\n\n\n11\nTuesday\nNov 12\ncontinued\n\n\n\n\n\nEfficient Path Profiling Thomas Ball and James R. Larus. MICRO 1996.\n\n\n\n\n\n\n\n\n\n\n\n11\nFriday\nNov 15\nMemory Management\n\n\n\n\n\nAn Efficient Implementation of SELF, a Dynamically-Typed Object-Oriented Language Based on Prototypes C. Chambers, D. Ungar, and E. Lee. OOPSLA 1989.\n\n\n\n\n\n\n\n\n\n\n\n12\nTuesday\nNov 19\ncontinued\n\n\n\n\n\n“Partial Redundancy Elimination” by Jens Knoop, Oliver Rüthing, and Bernhard Steffen\nYear: 1992\n\n\n\n\n\n\n\n\n\n\n\n12\nFriday\nNov 22\nDynamic compilers\n\n\n\n\n\nFormal Verification of a Realistic Compiler Xavier Leroy. CACM in 2009.\n\n\n\n\n\n\n\n\n\n\n\n13\nTuesday\nNov 26\ncontinued\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13\nFriday\nNov 29\nThanksgiving\n\n\n\n\n\nhttps://dada.cs.washington.edu/research/tr/2017/12/UW-CSE-17-12-01.pdf 12-01 TVM:End-to-End Optimization Stack for Deep Learnin\n\n\n\n\n\n\n\n\n\n\n\n14\nTuesday\nDec 3\nGPU Compilers\n\n\n\n\n\nRevealing Compiler Heuristics through Automated Discovery and Optimization, V. Seeker, C. Cummins, M. Cole, B. Franke, K. Hazelwood, H. Leather\n\n\n\n\n\n\n\n\n\n\n\n14\nFriday\nDec 6\ncontinued\n\n\n\n\n\nEnd-to-end deep learning of optimization heuristics - Chris Cummins, Pavlos Petoumenos, Zheng Wang, and Hugh Leather PACT 2017. https://ieeexplore.ieee.org/document/8091247\nfinal project deadline ——\nhttps://ieeexplore.ieee.org/document/10444819 A. Murtovi, G. Georgakoudis, K. Parasyris, C. Liao, I. Laguna and B. Steffen, “Enhancing Performance Through Control-Flow Unmerging and Loop Unrolling on GPUs,” 2024 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), Edinburgh, United Kingdom, 2024, pp. 106-118, doi: 10.1109/CGO57630.2024.10444819. keywords: {Codes;Costs;Graphics processing units;Prototypes;Benchmark testing;Predictive models;Optimization;compiler;code duplication;LLVM;GPU},\nhttps://escholarship.org/uc/item/3rt0n0q2 Gal, A., Probst, C. W, & Franz, M. (2003). A denial of service attack on the Java bytecode verifier. UC Irvine: Donald Bren School of Information and Computer Sciences. Retrieved from https://escholarship.org/uc/item/3rt0n0q2\nhttps://dl.acm.org/doi/pdf/10.1145/3620665.3640366 PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation ASPLOS ’24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2\nhttps://scontent-bos5-1.xx.fbcdn.net/v/t39.2365-6/448997590_1496256481254967_2304975057370160015_n.pdf?_nc_cat=106&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=4Yn8V9DFdbsQ7kNvgEwOdGk&_nc_ht=scontent-bos5-1.xx&oh=00_AYD-0YTCXuS11WU8rqC3N2aA-AfiflOptch_BD__V1V3xA&oe=6684630D\nMeta Large Language Model Compiler: Foundation Models of Compiler Optimization Chris Cummins†, Volker Seeker†, Dejan Grubisic, Baptiste Rozière, Jonas Gehring, Gabriel Synnaeve, Hugh Leather†\n—- papers\n1987 Superoptimizer: A Look at the Smallest Program Alexia Massalin. ASPLOS 1987.\n1988 Global value numbers and redundant computations Rosen, B.K., Wegman, M.N. and Zadeck, F.K., popl 1988\n2000\nDynamo: A Transparent Dynamic Optimization System Bala, V., Duesterwald, E. and Banerjia, S., PLDI 2000\n2002 iterative data-flow analysis, revisited Cooper, Keith D.; Harvey, Timothy J.; Kennedy, Ken (2004-03-26),November 2002\n2005 [Threads cannot be implemented as a library] (https://dl.acm.org/doi/10.1145/1064978.1065042) Boehm, H.J.. PLDI 2005\n2015 Provably correct peephole optimizations with alive Lopes, N.P., Menendez, D., Nagarakatte, S. and Regehr, J. pldi 2015\n2009 Formal Verification of a Realistic Compiler Xavier Leroy. CACM 2009.\n2018 TVM: end-to-end optimization stack for deep learning Chen, Tianqi, Thierry Moreau, Ziheng Jiang, Haichen Shen, Eddie Q. Yan, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy.arXiv preprint arXiv:1802.04799 11, no. 2018 (2018): 20.\n2024 Enhancing Performance Through Control-Flow Unmerging and Loop Unrolling on GPU A. Murtovi, G. Georgakoudis, K. Parasyris, C. Liao, I. Laguna and B. Steffen, cgo 2024\nhttps://escholarship.org/uc/item/3rt0n0q2 Gal, A., Probst, C. W, & Franz, M. (2003). A denial of service attack on the Java bytecode verifier. UC Irvine: Donald Bren School of Information and Computer Sciences. Retrieved from https://escholarship.org/uc/item/3rt0n0q2\nhttps://dl.acm.org/doi/pdf/10.1145/3620665.3640366 PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation ASPLOS ’24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2\n/https://scontent-bos5-1.xx.fbcdn.net/v/t39.2365-6/448997590_1496256481254967_2304975057370160015_n.pdf?_nc_cat=106&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=4Yn8V9DFdbsQ7kNvgEwOdGk&_nc_ht=scontent-bos5-1.xx&oh=00_AYD-0YTCXuS11WU8rqC3N2aA-AfiflOptch_BD__V1V3xA&oe=6684630D Meta Large Language Model Compiler: Foundation Models of Compiler Optimization Chris Cummins†, Volker Seeker†, Dejan Grubisic, Baptiste Rozière, Jonas Gehring, Gabriel Synnaeve, Hugh Leather†\nChlorophyll: Synthesis-Aided Compiler for Low-Power Spatial Architectures Phitchaya Mangpo Phothilimthana, Tikhon Jelvis, Rohin Shah, Nishant Totla, Sarah Chasins, and Rastislav Bodik. PLDI 2014.\nMLIR: A Compiler Infrastructure for the End of Moore’s Law Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy Davis, Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasilache, and Oleksandr Zinenko. arXiv preprint, 2020.\nTrace-Based Just-in-Time Type Specialization for Dynamic Languages Andreas Gal, Brendan Eich, Mike Shaver, David Anderson, David Mandelin, Mohammad R. Haghighat, Blake Kaplan, Graydon Hoare, Boris Zbarsky, Jason Orendorff, Jesse Ruderman, Edwin W. Smith, Rick Reitmaier, Michael Bebenita, Mason Chang, and Michael Franz. PLDI 2009.\nMesh: Compacting Memory Management for C/C++ Applications Bobby Powers, David Tench, Emery D. Berger, and Andrew McGregor. PLDI 2019.\nA Unified Theory of Garbage Collection David F. Bacon, Perry Cheng, and V. T. Rajan. OOPSLA 2004.\nType-Based Alias Analysis Amer Diwan, Kathryn S. McKinley, and J. Eliot B. Moss.\nAho, Alfred V., Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. “Compilers: Principles, Techniques, and Tools.” Alpern, Bowen, Mark N. Wegman, and F. Kenneth Zadeck. “Detecting equality of variables in programs.” ACM SIGPLAN Notices 23.7 (1988): 1-11. Bodik, Rastislav, Rajiv Gupta, and Vivek Sarkar. “ABC: Path-sensitive dynamic test generation.” ACM SIGPLAN Notices 35.5 (2000): 61-73. Chaitin, Gregory J., et al. “Register allocation via coloring.” Computer languages 6.1 (1981): 47-57. Cooper, Keith D., and Linda Torczon. “Tiling for improved register usage.” ACM SIGPLAN Notices 28.6 (1993): 279-290. Cytron, Ron, et al. “Efficiently computing static single assignment form and the control dependence graph.” ACM Transactions on Programming Languages and Systems (TOPLAS) 13.4 (1991): 451-490. Ertl, M. Anton. “Threaded code.” ACM Computing Surveys (CSUR) 32.2 (2000): 290-318. Ferrante, Jeanne, Karl J. Ottenstein, and Joe D. Warren. “The program dependence graph and its use in optimization.” ACM Transactions on Programming Languages and Systems (TOPLAS) 9.3 (1987): 319-349. Ganapathi, Madhusudhan, et al. “Experience with the MIPS compiler.” ACM SIGPLAN Notices 21.7 (1986): 175-187. Goldberg, David. “What every computer scientist should know about floating-point arithmetic.” ACM Computing Surveys (CSUR) 23.1 (1991): 5-48. Hall, Mary W., and Ken Kennedy. “Efficient call graph analysis.” ACM Letters on Programming Languages and Systems (LOPLAS) 1.3 (1992): 227-242. Johnson, Mark. “Attribute grammars and the lambda calculus.” ACM SIGPLAN Notices 18.6 (1983): 39-45. Kennedy, Ken, and Kathryn S. McKinley. “Loop distribution with arbitrary control flow.” ACM SIGPLAN Notices 29.6 (1994): 140-151. Knoop, Jens, Oliver Rüthing, and Bernhard Steffen. “Lazy code motion.” ACM SIGPLAN Notices 27.7 (1992): 224-234. Lamport, Leslie. “The parallel execution of DO loops.” Communications of the ACM 17.2 (1974): 83-93. Muchnick, Steven S. “Advanced compiler design and implementation.” Elsevier, 1997.\nSarkar, Vivek. “Partitioning parallel programs for macro-dataflow.” ACM SIGPLAN Notices 23.7 (1988): 98-106. Shivers, Olin. “Control-flow analysis in Scheme.” ACM SIGPLAN Notices 23.7 (1988): 164-174. Steensgaard, Bjarne. “Points-to analysis in almost linear time.” ACM SIGPLAN Notices 31.5 (1996): 32-41. Tarjan, Robert E. “Depth-first search and linear graph algorithms.” SIAM journal on computing 1.2 (1972): 146-160. Tichy, Walter F. “Smart recompilation.” ACM Transactions on Programming Languages and Systems (TOPLAS) 8.3 (1986): 273-291. Wolf, Michael E., and Monica S. Lam. “A data locality optimizing algorithm.” ACM SIGPLAN Notices 26.6 (1991): 30-44. Yaccarino, Joseph, and Keshav Pingali. “Data-flow analysis for distributed-memory multiprocessors.” ACM SIGPLAN Notices 27.9 (1992): 353-363. Zadeck, F. Kenneth, and Olivier Rüthing. “Incremental data flow analysis.” ACM SIGPLAN Notices 23.7 (1988): 132-146.\nHere is a revised list of 25 important papers, focusing on middle-end optimizations, broader compiler topics, garbage collection, and parallelism, and excluding books:\n\nBodik, Rastislav, Rajiv Gupta, and Vivek Sarkar. “ABC: Path-sensitive dynamic test generation.” ACM SIGPLAN Notices 35.5 (2000): 61-73.\nChaitin, Gregory J., et al. “Register allocation via coloring.” Computer languages 6.1 (1981): 47-57.\nCooper, Keith D., and Linda Torczon. “Tiling for improved register usage.” ACM SIGPLAN Notices 28.6 (1993): 279-290.\nCytron, Ron, et al. “Efficiently computing static single assignment form and the control dependence graph.” ACM Transactions on Programming Languages and Systems (TOPLAS) 13.4 (1991): 451-490.\nFerrante, Jeanne, Karl J. Ottenstein, and Joe D. Warren. “The program dependence graph and its use in optimization.” ACM Transactions on Programming Languages and Systems (TOPLAS) 9.3 (1987): 319-349.\nGanapathi, Madhusudhan, et al. “Experience with the MIPS compiler.” ACM SIGPLAN Notices 21.7 (1986): 175-187.\nGoldberg, David. “What every computer scientist should know about floating-point arithmetic.” ACM Computing Surveys (CSUR) 23.1 (1991): 5-48.\nHall, Mary W., and Ken Kennedy. “Efficient call graph analysis.” ACM Letters on Programming Languages and Systems (LOPLAS) 1.3 (1992): 227-242.\nKennedy, Ken, and Kathryn S. McKinley. “Loop distribution with arbitrary control flow.” ACM SIGPLAN Notices 29.6 (1994): 140-151.\nKnoop, Jens, Oliver Rüthing, and Bernhard Steffen. “Lazy code motion.” ACM SIGPLAN Notices 27.7 (1992): 224-234.\nLamport, Leslie. “The parallel execution of DO loops.” Communications of the ACM 17.2 (1974): 83-93.\nMcKinley, Kathryn S., Steve Carr, and Chau-Wen Tseng. “Improving data locality with loop transformations.” ACM Transactions on Programming Languages and Systems (TOPLAS) 18.4 (1996): 424-453.\nSarkar, Vivek. “Partitioning parallel programs for macro-dataflow.” ACM SIGPLAN Notices 23.7 (1988): 98-106.\nShivers, Olin. “Control-flow analysis in Scheme.” ACM SIGPLAN Notices 23.7 (1988): 164-174.\nSteensgaard, Bjarne. “Points-to analysis in almost linear time.” ACM SIGPLAN Notices 31.5 (1996): 32-41.\nTarjan, Robert E. “Depth-first search and linear graph algorithms.” SIAM journal on computing 1.2 (1972): 146-160.\nTichy, Walter F. “Smart recompilation.” ACM Transactions on Programming Languages and Systems (TOPLAS) 8.3 (1986): 273-291.\nWolf, Michael E., and Monica S. Lam. “A data locality optimizing algorithm.” ACM SIGPLAN Notices 26.6 (1991): 30-44.\nAppel, Andrew W. “Simple generational garbage collection and fast allocation.” Software: Practice and Experience 19.2 (1989): 171-183.\nBoehm, Hans-Juergen, and Mark Weiser. “Garbage collection in an uncooperative environment.” Software: Practice and Experience 18.9 (1988): 807-820.\nDijkstra, Edsger W., et al. “On-the-fly garbage collection: An exercise in cooperation.” Communications of the ACM 21.11 (1978): 965-975.\nBacon, David F., Perry Cheng, and V. T. Rajan. “A real-time garbage collector with low overhead and consistent utilization.” ACM SIGPLAN Notices. Vol. 38. No. 5. 2003.\nLea, Doug. “A Java fork/join framework.” Proceedings of the ACM 2000 conference on Java Grande. 2000.\n\nHere is a list of 15 papers that discuss the differences and challenges between compiling for CPUs and GPUs, focusing on performance optimization, memory management, parallelism, and execution models:\n\nFatahalian, Kayvon, and Mike Houston. “A closer look at GPUs.” Communications of the ACM 51.10 (2008): 50-57.\nGarland, Michael, et al. “Parallel computing experiences with CUDA.” IEEE Micro 28.4 (2008): 13-27.\nRyoo, Seongbeom, et al. “Optimization principles and application performance evaluation of a multithreaded GPU using CUDA.” Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming. 2008.\nHong, Sunpyo, and Hyesoon Kim. “An analytical model for a GPU architecture with memory-level and thread-level parallelism awareness.” ACM SIGARCH Computer Architecture News. Vol. 37. No. 3. 2009.\nBaskaran, Muthu Manikandan, et al. “Automatic data movement and computation mapping for multi-level parallel architectures with explicitly managed memories.” Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming. 2010.\nDiamos, Gregory, and Sudhakar Yalamanchili. “Harmony: an execution model and runtime for heterogeneous many core systems.” Proceedings of the 17th international symposium on High performance distributed computing. 2008.\nKerr, Andrew, Gregory Diamos, and Sudhakar Yalamanchili. “A characterization and analysis of PTX kernels.” IEEE International Symposium on Workload Characterization (IISWC). 2009.\nWong, Hing-Cheong, et al. “Pangaea: a tightly-coupled IA32 heterogeneous chip multiprocessor.” ACM SIGARCH Computer Architecture News. Vol. 36. No. 3. 2008.\nMagni, Alessandro, et al. “Exploiting user-defined kernel threads on GPUs.” ACM Transactions on Architecture and Code Optimization (TACO) 8.3 (2011): 1-29.\nPai, Siddhartha, et al. “Improving GPGPU concurrency with elastic kernels.” Proceedings of the eighteenth international conference on Architectural support for programming languages and operating systems. 2013.\nZhang, Yixin, et al. “Synk: a framework for optimal synchronization selection.” Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems. 2014.\nBaghsorkhi, S. Shams, et al. “An adaptive performance modeling tool for GPU architectures.” ACM SIGPLAN Notices 45.5 (2010): 105-114.\nBoyd, Eric, et al. “Characterization of performance of data-parallel kernels on Intel’s experimental single-chip cloud computer.” Proceedings of the 2011 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS). 2011.\nAila, Timo, and Samuli Laine. “Understanding the efficiency of ray traversal on GPUs.” Proceedings of the conference on High Performance Graphics 2009. 2009.\nHolewinski, Jan, Louis-Noël Pouchet, and P. Sadayappan. “High-performance code generation for stencil computations on GPU architectures.” Proceedings of the 26th ACM international conference on Supercomputing. 2012.\n\nThese papers provide insights into the challenges and differences in compiling for CPUs and GPUs, highlighting the architectural differences and how they influence compilation strategies and performance optimizations.\nBaghdadi, S., Größlinger, A. and Cohen, A., 2010. Putting automatic polyhedral compilation for GPGPU to work. In Proceedings of the 15th Workshop on Compilers for Parallel Computers (CPC’10).\nPradelle, B., Baskaran, M., Henretty, T., Meister, B., Konstantinidis, A. and Lethin, R., 2016, September. Polyhedral compilation for energy efficiency. In 2016 IEEE High Performance Extreme Computing Conference (HPEC) (pp. 1-7). IEEE.\nMerouani, M., Boudaoud, K.A., Aouadj, I.N., Tchoulak, N., Bernou, I.K., Benyamina, H., Tayeb, F.B.S., Benatchba, K., Leather, H. and Baghdadi, R., 2024. LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers. arXiv preprint arXiv:2403.11522.\nWegman & Zadeck, Constant Propagation with Conditional Branches, ACM Transactions on Programming Languages and Systems, 13(2):181-210, April 1991.\n\n\n    P. Briggs, K. D. Cooper, L. Taylor Simpson, Value Numbering, Software-Practice & Experience, 27(6): 701-724, 1997\n\n\n        K. Hazelwood, and D. Grove, Adaptive Online Context-Sensitive Inlining Conference on Code Generation and Optimization, pp. 253-264, San Francisco, CA March 2003.\n\n    X. Huang, S. M. Blackburn, K. S. McKinley, J. E. B. Moss, Z. Wang, and P. Cheng, The Garbage Collection Advantage: Improving Program Locality, ACM Conference on Object Oriented Programming, Systems, Languages, and Applications (OOPSLA), pp. 69-80, Vancouver, Canada, October 2004.\n\n\n        McKinley, Carr, & Tseng, Improving Data Locality with Loop Transformations, ACM Transactions on Programming Languages and Systems, 18(4):424-453, July 1996.\n\n\n        https://cfallin.org/blog/2021/03/15/cranelift-isel-3/  cranelift checking correctness in register allocator \n        uses data flow, value numbering and fuzzing \n\n        Retargeting and Respecializing GPU Workloads for Performance Portability\n        Ivanov, I.R., Zinenko, O., Domke, J., Endo, T. and Moses, W.S., 2024, March. Retargeting and Respecializing GPU Workloads for Performance Portability. In 2024 IEEE/ACM International Symposium on Code Generation and Optimization (CGO) (pp. 119-132). IEEE.\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html",
    "href": "src/briltxt/docs/lang/spec.html",
    "title": "Speculative Execution",
    "section": "",
    "text": "This extension lets Bril programs use a form of explicit speculative execution with rollback.\nIn general, speculation is when programs perform work that might not actually be necessary or even correct, under the assumption that it is likely to be right and useful. If this assumption turns out to be wrong, speculation typically needs some rollback mechanism to undo incorrect side effects and recover to a correct state.\nIn this Bril extension, programs can explicitly enter a speculative mode, where variable assignments are temporary. Then, they can either abort or commit those assignments, discarding them or making them permanent.\n\n\n\nspeculate: Enter a speculative execution context. No arguments.\ncommit: End the current speculative context, committing the current speculative state as the “real” state. No arguments.\nguard: Check a condition and possibly abort the current speculative context. One argument, the Boolean condition, and one label, to which control is transferred on abort. If the condition is true, this is a no-op. If the condition is false, speculation aborts: the program state rolls back to the state at the corresponding speculate instruction, execution jumps to the specified label.\n\nSpeculation can be nested, in which case aborting or committing a child context returns execution to the parent context. Aborting speculation rolls back normal variable assignments, but it does not affect the memory extension’s heap—any changes there remain. It is an error to commit or abort outside of speculation. It is not an error to perform side effects like print during speculation, but it is probably a bad idea.\n\n\n\nCommitting a speculative update makes it behave like normal:\nv: int = const 4;\nspeculate;\nv: int = const 2;\ncommit;\nprint v;\nSo this example prints 2. However, when a guard fails, it rolls back any modifications that happened since the last speculate instruction:\n  b: bool = const false;\n\n  v: int = const 4;\n  speculate;\n  v: int = const 2;\n  guard b .failed;\n  commit;\n\n.failed:\n  print v;\nThe guard here fails because b is false, then v gets restored to its pre-speculation value, and then control transfers to the .failed label. So this example prints 4. You can think of the code at .failed as the “recovery routine” that handles exceptional conditions.\n\n\n\nThe reference interpreter supports speculative execution. However, it does not support function calls during speculation, so you will get an error if you try to use a call or ret instruction while speculating."
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html#operations",
    "href": "src/briltxt/docs/lang/spec.html#operations",
    "title": "Speculative Execution",
    "section": "",
    "text": "speculate: Enter a speculative execution context. No arguments.\ncommit: End the current speculative context, committing the current speculative state as the “real” state. No arguments.\nguard: Check a condition and possibly abort the current speculative context. One argument, the Boolean condition, and one label, to which control is transferred on abort. If the condition is true, this is a no-op. If the condition is false, speculation aborts: the program state rolls back to the state at the corresponding speculate instruction, execution jumps to the specified label.\n\nSpeculation can be nested, in which case aborting or committing a child context returns execution to the parent context. Aborting speculation rolls back normal variable assignments, but it does not affect the memory extension’s heap—any changes there remain. It is an error to commit or abort outside of speculation. It is not an error to perform side effects like print during speculation, but it is probably a bad idea."
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html#examples",
    "href": "src/briltxt/docs/lang/spec.html#examples",
    "title": "Speculative Execution",
    "section": "",
    "text": "Committing a speculative update makes it behave like normal:\nv: int = const 4;\nspeculate;\nv: int = const 2;\ncommit;\nprint v;\nSo this example prints 2. However, when a guard fails, it rolls back any modifications that happened since the last speculate instruction:\n  b: bool = const false;\n\n  v: int = const 4;\n  speculate;\n  v: int = const 2;\n  guard b .failed;\n  commit;\n\n.failed:\n  print v;\nThe guard here fails because b is false, then v gets restored to its pre-speculation value, and then control transfers to the .failed label. So this example prints 4. You can think of the code at .failed as the “recovery routine” that handles exceptional conditions."
  },
  {
    "objectID": "src/briltxt/docs/lang/spec.html#interpreter",
    "href": "src/briltxt/docs/lang/spec.html#interpreter",
    "title": "Speculative Execution",
    "section": "",
    "text": "The reference interpreter supports speculative execution. However, it does not support function calls during speculation, so you will get an error if you try to use a call or ret instruction while speculating."
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html",
    "href": "src/briltxt/docs/lang/float.html",
    "title": "Floating Point",
    "section": "",
    "text": "Bril has an extension for computing on floating-point numbers.\nYou can read more about the extension, which is originally by Dietrich Geisler and originally included two FP precision levels.\n\n\nThe floating point extension adds one new base type:\n\"float\"\nFloating point numbers are 64-bit, double-precision IEEE 754 values. (There is no single-precision type.)\n\n\n\nThere are the standard arithmetic operations, which take two float values and produce a new float value:\n\nfadd\nfmul\nfsub\nfdiv\n\nIt is not an error to fdiv by zero; as in IEEE 754, the result is infinity.\nThere are also comparison operators, which take two float values and produce a bool:\n\nfeq\nflt\nfle\nfgt\nfge\n\n\n\n\nThe core print operation prints float values with 17 decimal digits of precision, including trailing zeros. (This is like using the %.17lf format specifier in C’s printf.) Positive and negative zero, while they are equal according to feq, look different when printed. Not-a-number values are printed as NaN; infinite values are printed as the strings Infinity or -Infinity."
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html#types",
    "href": "src/briltxt/docs/lang/float.html#types",
    "title": "Floating Point",
    "section": "",
    "text": "The floating point extension adds one new base type:\n\"float\"\nFloating point numbers are 64-bit, double-precision IEEE 754 values. (There is no single-precision type.)"
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html#operations",
    "href": "src/briltxt/docs/lang/float.html#operations",
    "title": "Floating Point",
    "section": "",
    "text": "There are the standard arithmetic operations, which take two float values and produce a new float value:\n\nfadd\nfmul\nfsub\nfdiv\n\nIt is not an error to fdiv by zero; as in IEEE 754, the result is infinity.\nThere are also comparison operators, which take two float values and produce a bool:\n\nfeq\nflt\nfle\nfgt\nfge"
  },
  {
    "objectID": "src/briltxt/docs/lang/float.html#printing",
    "href": "src/briltxt/docs/lang/float.html#printing",
    "title": "Floating Point",
    "section": "",
    "text": "The core print operation prints float values with 17 decimal digits of precision, including trailing zeros. (This is like using the %.17lf format specifier in C’s printf.) Positive and negative zero, while they are equal according to feq, look different when printed. Not-a-number values are printed as NaN; infinite values are printed as the strings Infinity or -Infinity."
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html",
    "href": "src/briltxt/docs/lang/memory.html",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "While core Bril only has simple scalar stack values, the memory extension adds a manually managed heap of array-like allocations. You can create regions, like with malloc in C, and it is the program’s responsibility to delete them, like with free. Programs can manipulate pointers within these regions; a pointer indicates a particular offset within a particular allocated region.\nYou can read more about the memory extension from its creators, Drew Zagieboylo and Ryan Doenges.\n\n\nThe memory extension adds a parameterized ptr type to Bril:\n{\"ptr\": &lt;Type&gt;}\nA pointer value represents a reference to a specific offset within a uniformly-typed region of values.\n\n\n\nThese are the operations that manipulate memory allocations:\n\nalloc: Create a new memory region. One argument: the number of values to allocate (an integer). The result type is a pointer; the type of the instruction decides the type of the memory region to allocate. For example, this instruction allocates a region of integers:\n{\n    \"op\": \"alloc\",\n    \"args\": [\"size\"],\n    \"dest\": \"myptr\",\n    \"type\": {\"ptr\": \"int\"}\n}\nfree: Delete an allocation. One argument: a pointer produced by alloc. No return value.\nstore: Write into a memory region. Two arguments: a pointer and a value. The pointer type must agree with the value type (e.g., if the second argument is an int, the first argument must be a ptr&lt;int&gt;). No return value.\nload: Read from memory. One argument: a pointer. The return type is the pointed-to type for that pointer.\nptradd: Adjust the offset for a pointer, producing a new pointer to a different location in the same memory region. Two arguments: a pointer and an offset (an integer, which may be negative). The return type is the same as the original pointer type.\n\nIt is an error to access or free a region that has already been freed. It is also an error to access (load or store) a pointer that is out of bounds, i.e., outside the range of valid indices for a given allocation. (Doing a ptradd to produce an out-of-bounds pointer is not an error; subsequently accessing that pointer is.)\n\n\n\nIt is not an error to use the core print operation on pointers, but the output is not specified. Implementations can choose to print any representation of the pointer that they deem helpful."
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html#types",
    "href": "src/briltxt/docs/lang/memory.html#types",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "The memory extension adds a parameterized ptr type to Bril:\n{\"ptr\": &lt;Type&gt;}\nA pointer value represents a reference to a specific offset within a uniformly-typed region of values."
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html#operations",
    "href": "src/briltxt/docs/lang/memory.html#operations",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "These are the operations that manipulate memory allocations:\n\nalloc: Create a new memory region. One argument: the number of values to allocate (an integer). The result type is a pointer; the type of the instruction decides the type of the memory region to allocate. For example, this instruction allocates a region of integers:\n{\n    \"op\": \"alloc\",\n    \"args\": [\"size\"],\n    \"dest\": \"myptr\",\n    \"type\": {\"ptr\": \"int\"}\n}\nfree: Delete an allocation. One argument: a pointer produced by alloc. No return value.\nstore: Write into a memory region. Two arguments: a pointer and a value. The pointer type must agree with the value type (e.g., if the second argument is an int, the first argument must be a ptr&lt;int&gt;). No return value.\nload: Read from memory. One argument: a pointer. The return type is the pointed-to type for that pointer.\nptradd: Adjust the offset for a pointer, producing a new pointer to a different location in the same memory region. Two arguments: a pointer and an offset (an integer, which may be negative). The return type is the same as the original pointer type.\n\nIt is an error to access or free a region that has already been freed. It is also an error to access (load or store) a pointer that is out of bounds, i.e., outside the range of valid indices for a given allocation. (Doing a ptradd to produce an out-of-bounds pointer is not an error; subsequently accessing that pointer is.)"
  },
  {
    "objectID": "src/briltxt/docs/lang/memory.html#printing",
    "href": "src/briltxt/docs/lang/memory.html#printing",
    "title": "Manually Managed Memory",
    "section": "",
    "text": "It is not an error to use the core print operation on pointers, but the output is not specified. Implementations can choose to print any representation of the pointer that they deem helpful."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html",
    "href": "src/briltxt/docs/lang/core.html",
    "title": "Core Language",
    "section": "",
    "text": "This section describes the core Bril instructions. Any self-respecting Bril tool must support all of these operations; other extensions are more optional.\n\n\nCore Bril defines two primitive types:\n\nint: 64-bit, two’s complement, signed integers.\nbool: True or false.\n\n\n\n\nThese instructions are the obvious binary integer arithmetic operations. They all take two arguments, which must be names of variables of type int, and produce a result of type int:\n\nadd: x + y.\nmul: x × y.\nsub: x - y.\ndiv: x ÷ y.\n\nIn each case, overflow follows two’s complement rules. It is an error to div by zero.\n\n\n\nThese instructions compare integers. They all take two arguments of type int and produce a result of type bool:\n\neq: Equal.\nlt: Less than.\ngt: Greater than.\nle: Less than or equal to.\nge: Greater than or equal to.\n\n\n\n\nThese are the basic Boolean logic operators. They take arguments of type bool and produce a result of type bool:\n\nnot (1 argument)\nand (2 arguments)\nor (2 arguments)\n\n\n\n\nThese are the control flow operations. Unlike the value operations above, they take labels and functions in addition to normal arguments.\n\njmp: Unconditional jump. One label: the label to jump to.\nbr: Conditional branch. One argument: a variable of type bool. Two labels: a true label and a false label. Transfer control to one of the two labels depending on the value of the variable.\ncall: Function invocation. Takes the name of the function to call and, as its arguments, the function parameters. The call instruction can be a Value Operation or an Effect Operation, depending on whether the function returns a value.\nret: Function return. Stop executing the current activation record and return to the parent (or exit the program if this is the top-level main activation record). It has one optional argument: the return value for the function.\n\nOnly call may (optionally) produce a result; the rest appear only as Effect Operations.\n\n\n\n\nid: A type-insensitive identity. Takes one argument, which is a variable of any type, and produces the same value (which must have the same type, obvi).\nprint: Output values to the console (with a newline). Takes any number of arguments of any type and does not produce a result.\nnop: Do nothing. Takes no arguments and produces no result."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#types",
    "href": "src/briltxt/docs/lang/core.html#types",
    "title": "Core Language",
    "section": "",
    "text": "Core Bril defines two primitive types:\n\nint: 64-bit, two’s complement, signed integers.\nbool: True or false."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#arithmetic",
    "href": "src/briltxt/docs/lang/core.html#arithmetic",
    "title": "Core Language",
    "section": "",
    "text": "These instructions are the obvious binary integer arithmetic operations. They all take two arguments, which must be names of variables of type int, and produce a result of type int:\n\nadd: x + y.\nmul: x × y.\nsub: x - y.\ndiv: x ÷ y.\n\nIn each case, overflow follows two’s complement rules. It is an error to div by zero."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#comparison",
    "href": "src/briltxt/docs/lang/core.html#comparison",
    "title": "Core Language",
    "section": "",
    "text": "These instructions compare integers. They all take two arguments of type int and produce a result of type bool:\n\neq: Equal.\nlt: Less than.\ngt: Greater than.\nle: Less than or equal to.\nge: Greater than or equal to."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#logic",
    "href": "src/briltxt/docs/lang/core.html#logic",
    "title": "Core Language",
    "section": "",
    "text": "These are the basic Boolean logic operators. They take arguments of type bool and produce a result of type bool:\n\nnot (1 argument)\nand (2 arguments)\nor (2 arguments)"
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#control",
    "href": "src/briltxt/docs/lang/core.html#control",
    "title": "Core Language",
    "section": "",
    "text": "These are the control flow operations. Unlike the value operations above, they take labels and functions in addition to normal arguments.\n\njmp: Unconditional jump. One label: the label to jump to.\nbr: Conditional branch. One argument: a variable of type bool. Two labels: a true label and a false label. Transfer control to one of the two labels depending on the value of the variable.\ncall: Function invocation. Takes the name of the function to call and, as its arguments, the function parameters. The call instruction can be a Value Operation or an Effect Operation, depending on whether the function returns a value.\nret: Function return. Stop executing the current activation record and return to the parent (or exit the program if this is the top-level main activation record). It has one optional argument: the return value for the function.\n\nOnly call may (optionally) produce a result; the rest appear only as Effect Operations."
  },
  {
    "objectID": "src/briltxt/docs/lang/core.html#miscellaneous",
    "href": "src/briltxt/docs/lang/core.html#miscellaneous",
    "title": "Core Language",
    "section": "",
    "text": "id: A type-insensitive identity. Takes one argument, which is a variable of any type, and produces the same value (which must have the same type, obvi).\nprint: Output values to the console (with a newline). Takes any number of arguments of any type and does not produce a result.\nnop: Do nothing. Takes no arguments and produces no result."
  },
  {
    "objectID": "src/briltxt/docs/intro.html",
    "href": "src/briltxt/docs/intro.html",
    "title": "Bril: A Compiler Intermediate Representation for Learning",
    "section": "",
    "text": "Bril: A Compiler Intermediate Representation for Learning\nBril, the Big Red Intermediate Language, is a programming language for learning about compilers. It’s the intermediate representation we use in CS 6120, a PhD-level compilers course. Bril’s design tenets include:\n\nBril is an instruction-oriented language, like most good IRs.\nThe core is minimal and ruthlessly regular. Extensions make it interesting.\nThe tooling is language agnostic. Bril programs are just JSON.\nBril is typed.\n\nSee the language reference for the complete language specification and the tool documentation for details on the “batteries included” monorepo.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/interp.html",
    "href": "src/briltxt/docs/tools/interp.html",
    "title": "Interpreter",
    "section": "",
    "text": "brili is the reference interpreter for Bril. It is written in TypeScript. You can find brili in the bril-ts directory in the Bril repository.\nThe interpreter supports core Bril along with the memory, floating point, SSA, and speculation extensions.\n\n\nTo use the interpreter, you will need Deno. Just run:\n$ deno install brili.ts\nAs Deno tells you, you will then need to add $HOME/.deno/bin to your $PATH.\nRun\n\nThe brili program takes a Bril program as a JSON file on standard input:\n$ brili &lt; my_program.json\nIt emits any print outputs to standard output. To provide inputs to the main function, you can write them as command-line arguments:\n$ brili 37 5 &lt; add.json\n42\n\n\n\nThe interpreter has a rudimentary profiling mode. Add a -p flag to print out a total number of dynamic instructions executed to stderr:\n$ brili -p 37 5 &lt; add.json\n42\ntotal_dyn_inst: 9"
  },
  {
    "objectID": "src/briltxt/docs/tools/interp.html#install",
    "href": "src/briltxt/docs/tools/interp.html#install",
    "title": "Interpreter",
    "section": "",
    "text": "To use the interpreter, you will need Deno. Just run:\n$ deno install brili.ts\nAs Deno tells you, you will then need to add $HOME/.deno/bin to your $PATH.\nRun\n\nThe brili program takes a Bril program as a JSON file on standard input:\n$ brili &lt; my_program.json\nIt emits any print outputs to standard output. To provide inputs to the main function, you can write them as command-line arguments:\n$ brili 37 5 &lt; add.json\n42"
  },
  {
    "objectID": "src/briltxt/docs/tools/interp.html#profiling",
    "href": "src/briltxt/docs/tools/interp.html#profiling",
    "title": "Interpreter",
    "section": "",
    "text": "The interpreter has a rudimentary profiling mode. Add a -p flag to print out a total number of dynamic instructions executed to stderr:\n$ brili -p 37 5 &lt; add.json\n42\ntotal_dyn_inst: 9"
  },
  {
    "objectID": "src/briltxt/docs/tools/infer.html",
    "href": "src/briltxt/docs/tools/infer.html",
    "title": "Type Inference",
    "section": "",
    "text": "Type Inference\nBril requires exhaustive type annotations on every instruction, which can quickly get tedious. The type-infer directory contains a simple global type inference tool that fills in missing type annotations. For example, it can turn this easier-to-write program:\n@main(arg: int) {\n  five = const 5;\n  ten = const 10;\n  res = add arg five;\n  cond = le res ten;\n  br cond .then .else;\n.then:\n  print res;\n.else:\n}\nInto this actually executable program:\n@main(arg: int) {\n  five: int = const 5;\n  ten: int = const 10;\n  res: int = add arg five;\n  cond: bool = le res ten;\n  br cond .then .else;\n.then:\n  print res;\n.else:\n}\nThe tool is a simple Python program, infer.py, that takes JSON programs that are missing types and adds types to them. It is also useful even on fully-typed programs as a type checker to rule out common run-time errors. The included text format tools support missing types for both parsing and printing, so here’s a shell pipeline that adds types to your text-format Bril program:\ncat myprog.bril | bril2json | python type-infer/infer.py | bril2txt\nYou can read more about the inference tool, which is originally by Christopher Roman.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/tools/text.html",
    "href": "src/briltxt/docs/tools/text.html",
    "title": "Bril Text Format",
    "section": "",
    "text": "While Bril’s canonical representation is a JSON AST, humans don’t like to read and write JSON. To accommodate our human foibles, we also have a simple textual representation. There is a parser and pretty printer tool that can convert the text representation to and from JSON.\nFor example, this Bril program in JSON:\n{\n  \"functions\": [{\n    \"name\": \"main\",\n    \"instrs\": [\n      { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n      { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n      { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\", \"args\": [\"v0\", \"v1\"] },\n      { \"op\": \"print\", \"args\": [\"v2\"] },\n      { \"op\": \"alloc\", \"type\": { \"ptr\" : \"int\" }, \"dest\": \"v3\", \"args\": [\"v0\"] },\n      { \"op\": \"free\", \"args\": [\"v3\"] },\n    ]\n  }]\n}\nGets represented in text like this:\n@main {\n  v0: int = const 1;\n  v1: int = const 2;\n  v2: int = add v0 v1;\n  print v2;\n  v3: ptr&lt;int&gt; = alloc v0;\n  free v3;\n}\n\n\nThe bril-txt parser & pretty printer are written in Python. You can install them with Flit by doing something like:\n$ pip install --user flit\n$ cd bril-txt\n$ flit install --symlink --user\nYou’ll now have tools called bril2json and bril2txt. Both read from standard input and write to standard output. You can try a “round trip” like this, for example:\n$ bril2json &lt; test/parse/add.bril | bril2txt\nThe bril2json parser also supports a -p flag to include source positions."
  },
  {
    "objectID": "src/briltxt/docs/tools/text.html#tools",
    "href": "src/briltxt/docs/tools/text.html#tools",
    "title": "Bril Text Format",
    "section": "",
    "text": "The bril-txt parser & pretty printer are written in Python. You can install them with Flit by doing something like:\n$ pip install --user flit\n$ cd bril-txt\n$ flit install --symlink --user\nYou’ll now have tools called bril2json and bril2txt. Both read from standard input and write to standard output. You can try a “round trip” like this, for example:\n$ bril2json &lt; test/parse/add.bril | bril2txt\nThe bril2json parser also supports a -p flag to include source positions."
  },
  {
    "objectID": "src/briltxt/docs/tools/web-playground.html",
    "href": "src/briltxt/docs/tools/web-playground.html",
    "title": "Web Playground",
    "section": "",
    "text": "Web playground is available for Bril.\nFeatures: - Code evaluation using the reference interpreter - CFG visualization - Dominator visualization - SSA transformation\n\n\nhttps://github.com/agentcooper/bril-playground"
  },
  {
    "objectID": "src/briltxt/docs/tools/web-playground.html#source-code",
    "href": "src/briltxt/docs/tools/web-playground.html#source-code",
    "title": "Web Playground",
    "section": "",
    "text": "https://github.com/agentcooper/bril-playground"
  },
  {
    "objectID": "src/briltxt/docs/tools/brilirs.html",
    "href": "src/briltxt/docs/tools/brilirs.html",
    "title": "Fast Interpreter in Rust",
    "section": "",
    "text": "The brilirs directory contains a fast Bril interpreter written in Rust. It is a drop-in replacement for the reference interpreter that prioritizes speed over completeness and hackability. It implements core Bril along with the SSA, memory, char, and floating point extensions.\nRead more about the implementation, which is originally by Wil Thomason and Daniel Glus.\n\n\nTo use brilirs you will need to install Rust. Use echo $PATH to check that $HOME/.cargo/bin is on your path.\nIn the brilirs directory, install the interpreter with:\n$ cargo install --path .\nDuring installation, brilirs will attempt to create a tab completions file for current shell. If this of interest, follow the instructions provided as a warning to finish enabling this.\nRun a program by piping a JSON Bril program into it:\n$ bril2json &lt; myprogram.bril | brilirs\nor\n$ brilirs --text --file myprogram.bril\nSimilar to brilck, brilirs can be used to typecheck and validate your Bril JSON program by passing the --check flag (similar to cargo --check).\nTo see all of the supported flags, run:\n$ brilirs --help"
  },
  {
    "objectID": "src/briltxt/docs/tools/brilirs.html#install",
    "href": "src/briltxt/docs/tools/brilirs.html#install",
    "title": "Fast Interpreter in Rust",
    "section": "",
    "text": "To use brilirs you will need to install Rust. Use echo $PATH to check that $HOME/.cargo/bin is on your path.\nIn the brilirs directory, install the interpreter with:\n$ cargo install --path .\nDuring installation, brilirs will attempt to create a tab completions file for current shell. If this of interest, follow the instructions provided as a warning to finish enabling this.\nRun a program by piping a JSON Bril program into it:\n$ bril2json &lt; myprogram.bril | brilirs\nor\n$ brilirs --text --file myprogram.bril\nSimilar to brilck, brilirs can be used to typecheck and validate your Bril JSON program by passing the --check flag (similar to cargo --check).\nTo see all of the supported flags, run:\n$ brilirs --help"
  },
  {
    "objectID": "src/briltxt/docs/tools/brench.html",
    "href": "src/briltxt/docs/tools/brench.html",
    "title": "Brench",
    "section": "",
    "text": "Brench is a simple benchmark runner to help you measure the impact of optimizations. It can run the same set of benchmarks under multiple treatments, check that they still produce the correct answer, and report their performance under every condition.\n\n\nBrench is a Python tool. There is a brench/ subdirectory in the Bril repository. Get Flit and then type:\n$ flit install --symlink --user\n\n\n\nWrite a configuration file using TOML. Start with something like this:\nextract = 'total_dyn_inst: (\\d+)'\nbenchmarks = '../benchmarks/*.bril'\n\n[runs.baseline]\npipeline = [\n    \"bril2json\",\n    \"brili -p {args}\",\n]\n\n[runs.myopt]\npipeline = [\n    \"bril2json\",\n    \"myopt\",\n    \"brili -p {args}\",\n]\nThe global options are:\n\nextract: A regular expression to extract the figure of merit from a given run of a given benchmark. The example above gets the simple profiling output from the Bril interpreter in -p mode.\nbenchmarks (optional): A shell glob matching the benchmark files to run. You can also specify the files on the command line (see below).\ntimeout (optional): The timeout of each benchmark run in seconds. Default of 5 seconds.\n\nThen, define an map of runs, which are the different treatments you want to give to each benchmark. Each one needs a pipeline, which is a list of shell commands to run in a pipelined fashion on the benchmark file, which Brench will send to the first command’s standard input. The first run constitutes the “golden” output; subsequent runs will need to match this output.\nRun\n\nJust give Brench your config file and it will give you results as a CSV:\n$ brench example.toml &gt; results.csv\nYou can also specify a list of files after the configuration file to run a specified list of benchmarks, ignoring the pre-configured glob in the configuration file.\nThe command has only one command-line option:\n\n--jobs or -j: The number of parallel jobs to run. Set to 1 to run everything sequentially. By default, Brench tries to guess an adequate number of threads to fill up your machine.\n\nThe output CSV has three columns: benchmark, run, and result. The latter is the value extracted from the run’s standard output and standard error using the extract regular expression or one of these three status indicators:\n\nincorrect: The output did not match the “golden” output (from the first run).\ntimeout: Execution took too long.\nmissing: The extract regex did not match in the final pipeline stage’s standard output or standard error.\n\nTo check that a run’s output is “correct,” Brench compares its standard output to that of the first run (baseline in the above example, but it’s whichever run configuration comes first). The comparison is an exact string match."
  },
  {
    "objectID": "src/briltxt/docs/tools/brench.html#set-up",
    "href": "src/briltxt/docs/tools/brench.html#set-up",
    "title": "Brench",
    "section": "",
    "text": "Brench is a Python tool. There is a brench/ subdirectory in the Bril repository. Get Flit and then type:\n$ flit install --symlink --user"
  },
  {
    "objectID": "src/briltxt/docs/tools/brench.html#configure",
    "href": "src/briltxt/docs/tools/brench.html#configure",
    "title": "Brench",
    "section": "",
    "text": "Write a configuration file using TOML. Start with something like this:\nextract = 'total_dyn_inst: (\\d+)'\nbenchmarks = '../benchmarks/*.bril'\n\n[runs.baseline]\npipeline = [\n    \"bril2json\",\n    \"brili -p {args}\",\n]\n\n[runs.myopt]\npipeline = [\n    \"bril2json\",\n    \"myopt\",\n    \"brili -p {args}\",\n]\nThe global options are:\n\nextract: A regular expression to extract the figure of merit from a given run of a given benchmark. The example above gets the simple profiling output from the Bril interpreter in -p mode.\nbenchmarks (optional): A shell glob matching the benchmark files to run. You can also specify the files on the command line (see below).\ntimeout (optional): The timeout of each benchmark run in seconds. Default of 5 seconds.\n\nThen, define an map of runs, which are the different treatments you want to give to each benchmark. Each one needs a pipeline, which is a list of shell commands to run in a pipelined fashion on the benchmark file, which Brench will send to the first command’s standard input. The first run constitutes the “golden” output; subsequent runs will need to match this output.\nRun\n\nJust give Brench your config file and it will give you results as a CSV:\n$ brench example.toml &gt; results.csv\nYou can also specify a list of files after the configuration file to run a specified list of benchmarks, ignoring the pre-configured glob in the configuration file.\nThe command has only one command-line option:\n\n--jobs or -j: The number of parallel jobs to run. Set to 1 to run everything sequentially. By default, Brench tries to guess an adequate number of threads to fill up your machine.\n\nThe output CSV has three columns: benchmark, run, and result. The latter is the value extracted from the run’s standard output and standard error using the extract regular expression or one of these three status indicators:\n\nincorrect: The output did not match the “golden” output (from the first run).\ntimeout: Execution took too long.\nmissing: The extract regex did not match in the final pipeline stage’s standard output or standard error.\n\nTo check that a run’s output is “correct,” Brench compares its standard output to that of the first run (baseline in the above example, but it’s whichever run configuration comes first). The comparison is an exact string match."
  },
  {
    "objectID": "src/briltxt/docs/tools/plugin.html",
    "href": "src/briltxt/docs/tools/plugin.html",
    "title": "Syntax Plugin for Text Editors",
    "section": "",
    "text": "Syntax Plugin for Text Editors\nThere is a Vim syntax highlighting plugin for Bril’s text format available in bril-vim. You can use it with a Vim plugin manager. For example, if you use vim-plug, you can add this to your .vimrc:\nPlug 'sampsyo/bril', { 'for': 'bril', 'rtp': 'bril-vim' }\nYou can read more about the plugin, which is originally by Edwin Peguero.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "src/briltxt/docs/SUMMARY.html",
    "href": "src/briltxt/docs/SUMMARY.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIntroduction\n\nLanguage Reference\n\nSyntax\nWell Formedness\nCore\nStatic Single Assignment\nMemory\nFloating Point\nSpeculative Execution\nImport\nCharacter\n\nTools\n\nInterpreter\nText Representation\nTypeScript Compiler\nFast Interpreter\nEditor Plugin\nType Inference\nType Checker\nBenchmarks\nTypeScript Library\nOCaml Library\nRust Library\nBenchmark Runner\nCompiler\nWeb Playground\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "EECS 7398 Fall 2024\nInstructor: Dr. Norman Rubin\nemail: n.rubin@northeastern.edu\n\n\n\n\n\n\nWarning\n\n\n\nOffice hours: TBA\nWhere TBA\nOffice hours by appointment\n\n\nThis course draws heavily from the CS6120 Advanced Compilers course at Cornell University. Special thanks to Adrian Sampson for granting permission to use his course materials.\nYou can find videos of Adrian Sampson’s lectures on the CS6120 self-guided page. These videos provide an in-depth explanation of many topics we’ll cover in this course.\nI want to take a moment to address an important aspect of this course: its evolving nature. Since this is the first time this course is being offered, please be aware that both the schedule and assignments may change as we progress.\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/02_reps.html",
    "href": "notebooks/02_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02_reps.html#a-more-regular-representation",
    "href": "notebooks/02_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02aa_reps.html",
    "href": "notebooks/02aa_reps.html",
    "title": "2a Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/02aa_reps.html#a-more-regular-representation",
    "href": "notebooks/02aa_reps.html#a-more-regular-representation",
    "title": "2a Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/02aa_reps.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "2a Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "href": "notebooks/02aa_reps.html#extract-info-from-this-repreentation.",
    "title": "2a Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/02aa_reps.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "2a Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/representation.html",
    "href": "notebooks/representation.html",
    "title": "Representation",
    "section": "",
    "text": "The representation of a program - is what we read in and read out when transforming a program. What kind of properties make a good representation?\nOne possible representation is called concrete syntax form Programs are text - surface syntax- just what you would type into an editor.\n\nvalue = 8\nresult = 1\nfor i in range(value):\n  result = result + i\nprint(result)\n\n29\n\n\nWhat is good and what is bad about this representation?\nWhat is the level of abstraction? How do you understand the semantics.\nForm 2 - Abstract syntax form\nTree structure - Nodes are parts of the program, edges show how they are connected. We can write this as a list or a graph\n\n\nFunctionDef(\n    name='pgm',\n    args=arguments(\n        posonlyargs=[],\n        args=[],\n        kwonlyargs=[],\n        kw_defaults=[],\n        defaults=[]),\n    body=[\n        Assign(\n            targets=[\n                Name(id='value', ctx=Store())],\n            value=Constant(value=8)),\n        Assign(\n            targets=[\n                Name(id='result', ctx=Store())],\n            value=Constant(value=1)),\n        For(\n            target=Name(id='i', ctx=Store()),\n            iter=Call(\n                func=Name(id='range', ctx=Load()),\n                args=[\n                    Name(id='value', ctx=Load())],\n                keywords=[]),\n            body=[\n                Assign(\n                    targets=[\n                        Name(id='result', ctx=Store())],\n                    value=BinOp(\n                        left=Name(id='result', ctx=Load()),\n                        op=Mult(),\n                        right=Name(id='i', ctx=Load())))],\n            orelse=[]),\n        Expr(\n            value=Call(\n                func=Name(id='print', ctx=Load()),\n                args=[\n                    Name(id='result', ctx=Load())],\n                keywords=[]))],\n    decorator_list=[])\n\n\n\ndot_dia\n\n\n\n\n\n\n\n\nAST tree representation An AST is a tree structure, nodes like if, test, body, assign Each node is one concept from the program\nRecursive function can walk over the tree, one chunk of code for each node.\n\nGood - each type of node is different, making special cases are easy\nBad - each type of node is different so analysis has to know about every type, making general cases hard\n\nThis is the classic way to write an interpreter. Simple (non optimizing) compilers often use this format.\n\n\nPrograms are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments\n\n\n\nWhat is the abstract syntax form for this?\n\n\n\n\n\nRepresentation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge\n\n\n\n\n\njust find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "notebooks/representation.html#a-more-regular-representation",
    "href": "notebooks/representation.html#a-more-regular-representation",
    "title": "Representation",
    "section": "",
    "text": "Programs are lists of instructions. Like an assembly instructions. Same sort of representation as LLVM.\n\n\n    let value = 8\n    let result = 1\n    for (let i = 0;i &lt; value;i = i+ 1)\n    {\n        result = result * i\n    }\n    console.log(result )\n\n\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n\n\nos.system('ts2bril images/toy.ts | bril2txt')\n\n@main {\n  v0: float = const 8;\n  value: float = id v0;\n  v1: float = const 1;\n  result: float = id v1;\n  v3: float = const 0;\n  i: float = id v3;\n.for.cond.2:\n  v4: float = id i;\n  v5: float = id value;\n  v6: bool = flt v4 v5;\n  br v6 .for.body.2 .for.end.2;\n.for.body.2:\n  v7: float = id result;\n  v8: float = id i;\n  v9: float = fmul v7 v8;\n  result: float = id v9;\n  v10: float = id i;\n  v11: float = const 1;\n  v12: float = fadd v10 v11;\n  i: float = id v12;\n  jmp .for.cond.2;\n.for.end.2:\n  v13: float = id result;\n  print v13;\n  v14: int = const 0;\n}\n\n\n0\n\n\nLooks like assembly but no limit on registers, no condition codes. fully typed, no complex addressing modes.\nsyntax-\nDeclare functions, labels, instructions\ninstruction:\n1) variable type = opcode arguments 2) opcode list of arguments"
  },
  {
    "objectID": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "href": "notebooks/representation.html#what-is-good-and-what-is-about-this-reorientation",
    "title": "Representation",
    "section": "",
    "text": "What is the abstract syntax form for this?"
  },
  {
    "objectID": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "href": "notebooks/representation.html#extract-info-from-this-repreentation.",
    "title": "Representation",
    "section": "",
    "text": "Representation is a directed graph. Nodes are instructions, edges indicate possible flow of control, one entry and one exit node.\nHere is a simple program:\n    @main {\n        v: int = const 5;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[const] --&gt; B[print]\n\n\n\n\n\n\na second example\n    @main {\n        v: int = const 4;\n        jmp  .somewhere;\n        v: int = const 2;\n        .somewhere;\n        print v;\n    }\nWhat does the control flow graph look like?\n\n\n\n\n\nflowchart LR\n  A[const 4] --&gt; B[jmp]\n  B --&gt; C[print]\n  D[const 2] --&gt; C\n\n\n\n\n\n\nnotice label does not produce a node\nEasy to see a dead instruction.\nThird example:\n    @main {\n        v: int = const 4;\n        b: bool = const false;\n        br b .there .here;\n    .here:\n        v: int = const 2;\n    .there;\n        print v;\n    }\n\n\n\n\n\nflowchart LR\n  A[v: int const 4] --&gt; B[b: bool const false]\n  B --&gt; C[br b .there, .false]\n  C --&gt; D[v: const 2]\n  C --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nwhich is the true and which is the false, could mark the edges or use a convention\nWhich is the entry, which is the exit?\nThere is a long chain of instructions entered at the top, exit at the bottom, no branches inside.\nBasic blocks (cfg form 2) 1) nodes can be a sequence of instructions. 1) jumps and branches can only be at the end of a sequence 1) only label has to be at the start 1) every instruction in the sequence executes the same number of times\n\n\n\n\n\nflowchart LR\n  A[v: int const 4\\nb : bool\\n br ] \n  A --&gt; D[v: const 2]\n  A --&gt; E[print v]\n  D --&gt; E\n\n\n\n\n\n\nAs we construct basic blocks, we can add instructions up till something that ends the block (terminator)\nOption: do all blocks end in a terminator or not?\ngiven a block b, the predecessors of b are the blocks b_in where there is an edge bin-&gt;b. And the successors of B are the b_out where b-&gt;b_out is an edge"
  },
  {
    "objectID": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "href": "notebooks/representation.html#what-is-an-algorithm-that-forms-a-cfg",
    "title": "Representation",
    "section": "",
    "text": "just find all the basic blocks\nadd the control flow edges\n\npsuedo code\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\nstep 2 we need a map from labels to basic blocks\n\nin: instructions - list of instructions\nout blocks - list of lists of instructions\n\ncurrent_block = []\nfor i in instructions:\n    if i is not a label:\n       block.append(i)\n    if i is a label or terminator:\n        blocks.append(current_block)\n        current_block = []\n    \n\nfor block in blocks:\n   last = block[-1]\n   if last is a jmp (one successor)\n      add edge from block to last.dest \n   else if last is a br (two successors)\n      add two edges from block to last.true, last.false \n   else  fall through \n      add edge to next block (if it exists)\n\nwith open(\"images/add.json\", 'r') as f:\n  bril_program = f.read()\n  print(bril_program)\n\n{\n  \"functions\": [\n    {\n      \"name\": \"main\",\n      \"instrs\": [\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v0\", \"value\": 1 },\n        { \"op\": \"const\", \"type\": \"int\", \"dest\": \"v1\", \"value\": 2 },\n        { \"op\": \"add\", \"type\": \"int\", \"dest\": \"v2\",\n          \"args\": [\"v0\", \"v1\"] },\n        { \"op\": \"print\", \"args\": [\"v2\"] }\n      ],\n      \"args\": []\n    }\n  ]\n}"
  },
  {
    "objectID": "lectures/110_whole_program.html",
    "href": "lectures/110_whole_program.html",
    "title": "11 Whole program",
    "section": "",
    "text": "Warning\n\n\n\nNot done yet\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#this-is-based-on-the-cranelift-compiler-used-for-web-assembly-and-rust",
    "href": "lectures/revealjs_ra-checking.qmd.html#this-is-based-on-the-cranelift-compiler-used-for-web-assembly-and-rust",
    "title": "Testing Register allocators",
    "section": "this is based on the cranelift compiler used for web-assembly and rust",
    "text": "this is based on the cranelift compiler used for web-assembly and rust"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#what-is-register-allocation",
    "href": "lectures/revealjs_ra-checking.qmd.html#what-is-register-allocation",
    "title": "Testing Register allocators",
    "section": "what is register allocation",
    "text": "what is register allocation\nIn Bril and LLVM a program can use an arbitrary number of registers,\nvoid f() {\n    int x0 = compute(0);\n    int x1 = compute(1);\n    // ...\n    int x99 = compute(99);\n    \n    // --- 100 possibly different values were computed \n    // --- where are those values stored?\n    \n    consume(x0);\n    consume(x1);\n    // ...\n    consume(x99);\n}"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#storing-variables",
    "href": "lectures/revealjs_ra-checking.qmd.html#storing-variables",
    "title": "Testing Register allocators",
    "section": "storing variables",
    "text": "storing variables\none option\nAllocate a memory location for each local variable. All of the \\(x_N\\) variables above semantically live in memory. When the function is called, it allocates a nwe area on the stack called the stack frame and uses it to store local variables.\nThis means that adding two variables, takes two loads, one add, and one store so it is very slow\nCompiling code in this way is very fast because we need to make almost no decisions: a variable reference always becomes a memory load,\nOn computers we have a limited set of registers\nRegister allocation: is assigning a value in the program to a register for storage. The register allocator decides how to shuffle values between memory and registers, and between register.\nIn Bril and LLVM we have virtual registers - as many as you want. The register allocator has to rewrite the instructions to use physical registers. Since the number of physical registers is limited, The allocator might insert additional instructions:\n\nstores (called spills) to move a register to memory\nloads (called reloads) to move memory to a register\nmoves to copy from one register to another\n\nThe locations in memory are usually on the stack and are called spill-slots"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "href": "lectures/revealjs_ra-checking.qmd.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "title": "Testing Register allocators",
    "section": "example of register allocation on a machine with two physical registers",
    "text": "example of register allocation on a machine with two physical registers\nvirtual register code          physical register code \n                               {v0 -&gt; r0, v1 -&gt; r1}\n                               store r1, [sp+0]  a spill\nadd v2, v0, v1                 add r1, r0, r1 \n                               {v0 -&gt; r0, v1-&gt; [sp+-0], v2-&gt; r1}\nsub v3, v2, v0                 sub r1, r1, r0\n                               load r0, [sp+0]  a reload \nmul  v4, v3, v1                mul r0, r1, r0\n                               {v4-&gt; r0}\nstore v4, [sp+48]              store r0, [sp+48]"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#complexity",
    "href": "lectures/revealjs_ra-checking.qmd.html#complexity",
    "title": "Testing Register allocators",
    "section": "complexity",
    "text": "complexity\nif you do register allocation for code that is not in SSA, this is NP-complete But if you do it on code that is in SSA, the time complexity is polynomial.\nThere are lots of approximate algorithms- all complicated, lots of machines have extra constraints for instance there is a GPU load instruction that read 128 bits from memory and puts the value into 4 consecutive registers\nI’m not going to talk about these algorithms here"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-to-verify-correctness-of-an-allocator",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-to-verify-correctness-of-an-allocator",
    "title": "Testing Register allocators",
    "section": "How to Verify Correctness of an allocator?",
    "text": "How to Verify Correctness of an allocator?\nBefore and after the allocator, we have the same instructions (except for those added by the allocator)\nassume we have a machine with an infinite register set and a second machine with a finite register set.\nCorrect means both programs executed on these two machines get the same answer for all possible inputs"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-do-we-test-this",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-do-we-test-this",
    "title": "Testing Register allocators",
    "section": "how do we test this?",
    "text": "how do we test this?\nHow do we test this equivalence?\npick a random program and a random input. interpret and see if the result is the same.\ncould try more random inputs, could generate more random programs (fuzzer tools)\nCould reasonably confident but not 100% and very expensive"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "href": "lectures/revealjs_ra-checking.qmd.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "title": "Testing Register allocators",
    "section": "use value numbering check one program, one basic block, all possible inputs",
    "text": "use value numbering check one program, one basic block, all possible inputs\n// original               // allocated \nld v0, [A]                ld r0, [A]\nld v1, [B]                ld r1, [B]\nld v2, [C]                ld r2, [C]\nadd v3, v0, v1            add r0, r0, r1\nadd v4, v2, v3            add r0, r2, r0\nreturn v4                 return r0\n\nv0 -&gt; vn 1 ld [A]         r0 -&gt; vn 1 ld [A]\nv1 -&gt; vn 2 ld [B]         r1 -&gt; vn 2 ld [B]\nv2 -&gt; vn 3 ld [C]         r2 -&gt; vn 3 ld [C]\nv3 -&gt; vn 4 add 1,2        r0 -&gt; vn 4 add 1,2 \nv4 -&gt; vn 5 add 3,4        r0 -&gt; vn 5 add 3,4 \nreturn vn 5               return vn 5"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#check-more-then-one-program-all-programs-at-once",
    "href": "lectures/revealjs_ra-checking.qmd.html#check-more-then-one-program-all-programs-at-once",
    "title": "Testing Register allocators",
    "section": "check more then one program (all programs at once)",
    "text": "check more then one program (all programs at once)\nThis requires a proof that the two programs get the same result - this is an active research question -\nsome success but not easy\nnot used in production"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "href": "lectures/revealjs_ra-checking.qmd.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "title": "Testing Register allocators",
    "section": "best we can do is generate lots of programs check each one",
    "text": "best we can do is generate lots of programs check each one\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n\nWe could use the fuzzer to generate random programs or we could use a test set"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#algorithm-linear-in-number-of-instructions",
    "href": "lectures/revealjs_ra-checking.qmd.html#algorithm-linear-in-number-of-instructions",
    "title": "Testing Register allocators",
    "section": "algorithm (linear in number of instructions)",
    "text": "algorithm (linear in number of instructions)\nfor each instruction we need to form pairs - virtual and physical register that holds the same value\nfor instruction v and p, check that the arguments are equal, if not fail add the pair dest of v == dest of p\ndoes not matter what the original op code was, just need register names"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#more-general",
    "href": "lectures/revealjs_ra-checking.qmd.html#more-general",
    "title": "Testing Register allocators",
    "section": "more general",
    "text": "more general\nTreat the allocated program as containing:\n\nSpill , : copy data (symbol representing virtual register) from a register to a spill slot.\nReload , : copy data from a spill slot to a register.\ncopy , : move data from one CPU register to another (N.B.: only regalloc-inserted moves are recognized as a Move, not moves in the original input program.)\nOp read:, read_orig: write: write_orig:: some arbitrary operation that reads some registers and writes some other registers.\n\nRun the value number over this:\nstate: for each physical register, and spill slot\nwe need either:\n\nthe virtual register name\nunknown -\n\nconflicted if it has more then one virtual register"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#steps-still-no-control-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#steps-still-no-control-flow",
    "title": "Testing Register allocators",
    "section": "steps (still no control flow )",
    "text": "steps (still no control flow )\nWhen we see a Spill, Reload, or Move, we copy the symbolic state from the source location (register or spill slot) to the destination location.\nWhen we see an Op, we do some checks then some updates:\nFor each read (input) register, we examine the symbolic value stored in the given register.\nIf that symbol matches the virtual register that the original instruction used, then the allocator has properly conveyed the virtual register’s value to its use here, and thus the allocation is correct\nIf not, we can signal a checker error, and look for the bug in our register allocator. why are there no false positives?\nFor each write (output) register, we set the symbolic value stored in the given CPU register to be the given virtual register."
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#control-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#control-flow",
    "title": "Testing Register allocators",
    "section": "control flow",
    "text": "control flow\nWe can use data flow and a lattice\nhere is the lattice\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#now-for-the-data-flow",
    "href": "lectures/revealjs_ra-checking.qmd.html#now-for-the-data-flow",
    "title": "Testing Register allocators",
    "section": "now for the data flow",
    "text": "now for the data flow\nWe start out with all physical registers and spill slots as ‘unknown’ At each join point move down the lattice\nconflicted is ok, so long as it is not used\nSince the number of physical registers and spill slots is finite we can can merge all of them at the top of each basic block.\nlike usual we might pick a good order to process basic blocks"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#how-about-an-example",
    "href": "lectures/revealjs_ra-checking.qmd.html#how-about-an-example",
    "title": "Testing Register allocators",
    "section": "How about an example:",
    "text": "How about an example:\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n\nat the top of C, we see that physical p0 is conflicted -\nbut that is not a error\nafter the reload we find it contains v2"
  },
  {
    "objectID": "lectures/revealjs_ra-checking.qmd.html#tracing-pointers--",
    "href": "lectures/revealjs_ra-checking.qmd.html#tracing-pointers--",
    "title": "Testing Register allocators",
    "section": "tracing pointers -",
    "text": "tracing pointers -\nSince we know what virtual registers are in each spill-slot, and virtual registers have types we can tell which spill slots contain pointers\nsuppose we have a spot where we might call a gc, we could force spilling of all live vrs that contain a pointer and then tell the gc which spill locations to consider"
  },
  {
    "objectID": "lectures/ra-checking.html#what-is-register-allocation",
    "href": "lectures/ra-checking.html#what-is-register-allocation",
    "title": "Testing Register allocators",
    "section": "what is register allocation",
    "text": "what is register allocation\nIn Bril and LLVM a program can use an arbitrary number of registers,\nvoid f() {\n    int x0 = compute(0);\n    int x1 = compute(1);\n    // ...\n    int x99 = compute(99);\n    \n    // --- 100 possibly different values were computed \n    // --- where are those values stored?\n    \n    consume(x0);\n    consume(x1);\n    // ...\n    consume(x99);\n}"
  },
  {
    "objectID": "lectures/ra-checking.html#storing-variables",
    "href": "lectures/ra-checking.html#storing-variables",
    "title": "Testing Register allocators",
    "section": "storing variables",
    "text": "storing variables\none option\nAllocate a memory location for each local variable. All of the \\(x_N\\) variables above semantically live in memory. When the function is called, it allocates a nwe area on the stack called the stack frame and uses it to store local variables.\nThis means that adding two variables, takes two loads, one add, and one store so it is very slow\nCompiling code in this way is very fast because we need to make almost no decisions: a variable reference always becomes a memory load,\nOn computers we have a limited set of registers\nRegister allocation: is assigning a value in the program to a register for storage. The register allocator decides how to shuffle values between memory and registers, and between register.\nIn Bril and LLVM we have virtual registers - as many as you want. The register allocator has to rewrite the instructions to use physical registers. Since the number of physical registers is limited, The allocator might insert additional instructions:\n\nstores (called spills) to move a register to memory\nloads (called reloads) to move memory to a register\nmoves to copy from one register to another\n\nThe locations in memory are usually on the stack and are called spill-slots"
  },
  {
    "objectID": "lectures/ra-checking.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "href": "lectures/ra-checking.html#example-of-register-allocation-on-a-machine-with-two-physical-registers",
    "title": "Testing Register allocators",
    "section": "example of register allocation on a machine with two physical registers",
    "text": "example of register allocation on a machine with two physical registers\nvirtual register code          physical register code \n                               {v0 -&gt; r0, v1 -&gt; r1}\n                               store r1, [sp+0]  a spill\nadd v2, v0, v1                 add r1, r0, r1 \n                               {v0 -&gt; r0, v1-&gt; [sp+-0], v2-&gt; r1}\nsub v3, v2, v0                 sub r1, r1, r0\n                               load r0, [sp+0]  a reload \nmul  v4, v3, v1                mul r0, r1, r0\n                               {v4-&gt; r0}\nstore v4, [sp+48]              store r0, [sp+48]"
  },
  {
    "objectID": "lectures/ra-checking.html#complexity",
    "href": "lectures/ra-checking.html#complexity",
    "title": "Testing Register allocators",
    "section": "complexity",
    "text": "complexity\nif you do register allocation for code that is not in SSA, this is NP-complete But if you do it on code that is in SSA, the time complexity is polynomial.\nThere are lots of approximate algorithms- all complicated, lots of machines have extra constraints for instance there is a GPU load instruction that read 128 bits from memory and puts the value into 4 consecutive registers\nI’m not going to talk about these algorithms here"
  },
  {
    "objectID": "lectures/ra-checking.html#how-to-verify-correctness-of-an-allocator",
    "href": "lectures/ra-checking.html#how-to-verify-correctness-of-an-allocator",
    "title": "Testing Register allocators",
    "section": "How to Verify Correctness of an allocator?",
    "text": "How to Verify Correctness of an allocator?\nBefore and after the allocator, we have the same instructions (except for those added by the allocator)\nassume we have a machine with an infinite register set and a second machine with a finite register set.\nCorrect means both programs executed on these two machines get the same answer for all possible inputs"
  },
  {
    "objectID": "lectures/ra-checking.html#how-do-we-test-this",
    "href": "lectures/ra-checking.html#how-do-we-test-this",
    "title": "Testing Register allocators",
    "section": "how do we test this?",
    "text": "how do we test this?\nHow do we test this equivalence?\npick a random program and a random input. interpret and see if the result is the same.\ncould try more random inputs, could generate more random programs (fuzzer tools)\nCould reasonably confident but not 100% and very expensive"
  },
  {
    "objectID": "lectures/ra-checking.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "href": "lectures/ra-checking.html#use-value-numbering-check-one-program-one-basic-block-all-possible-inputs",
    "title": "Testing Register allocators",
    "section": "use value numbering check one program, one basic block, all possible inputs",
    "text": "use value numbering check one program, one basic block, all possible inputs\n// original               // allocated \nld v0, [A]                ld r0, [A]\nld v1, [B]                ld r1, [B]\nld v2, [C]                ld r2, [C]\nadd v3, v0, v1            add r0, r0, r1\nadd v4, v2, v3            add r0, r2, r0\nreturn v4                 return r0\n\nv0 -&gt; vn 1 ld [A]         r0 -&gt; vn 1 ld [A]\nv1 -&gt; vn 2 ld [B]         r1 -&gt; vn 2 ld [B]\nv2 -&gt; vn 3 ld [C]         r2 -&gt; vn 3 ld [C]\nv3 -&gt; vn 4 add 1,2        r0 -&gt; vn 4 add 1,2 \nv4 -&gt; vn 5 add 3,4        r0 -&gt; vn 5 add 3,4 \nreturn vn 5               return vn 5"
  },
  {
    "objectID": "lectures/ra-checking.html#check-more-then-one-program-all-programs-at-once",
    "href": "lectures/ra-checking.html#check-more-then-one-program-all-programs-at-once",
    "title": "Testing Register allocators",
    "section": "check more then one program (all programs at once)",
    "text": "check more then one program (all programs at once)\nThis requires a proof that the two programs get the same result - this is an active research question -\nsome success but not easy\nnot used in production"
  },
  {
    "objectID": "lectures/ra-checking.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "href": "lectures/ra-checking.html#best-we-can-do-is-generate-lots-of-programs-check-each-one",
    "title": "Testing Register allocators",
    "section": "best we can do is generate lots of programs check each one",
    "text": "best we can do is generate lots of programs check each one\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph LR\nA[Virtual code]\nB[Register allocator]\nC[Machine code]\nD[Checker]\nE[Fuzzing engine]\nA--&gt; B\nB--&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; A\nA --&gt; D\n\n\n\n\n\n\nWe could use the fuzzer to generate random programs or we could use a test set"
  },
  {
    "objectID": "lectures/ra-checking.html#algorithm-linear-in-number-of-instructions",
    "href": "lectures/ra-checking.html#algorithm-linear-in-number-of-instructions",
    "title": "Testing Register allocators",
    "section": "algorithm (linear in number of instructions)",
    "text": "algorithm (linear in number of instructions)\nfor each instruction we need to form pairs - virtual and physical register that holds the same value\nfor instruction v and p, check that the arguments are equal, if not fail add the pair dest of v == dest of p\ndoes not matter what the original op code was, just need register names"
  },
  {
    "objectID": "lectures/ra-checking.html#more-general",
    "href": "lectures/ra-checking.html#more-general",
    "title": "Testing Register allocators",
    "section": "more general",
    "text": "more general\nTreat the allocated program as containing:\n\nSpill , : copy data (symbol representing virtual register) from a register to a spill slot.\nReload , : copy data from a spill slot to a register.\ncopy , : move data from one CPU register to another (N.B.: only regalloc-inserted moves are recognized as a Move, not moves in the original input program.)\nOp read:, read_orig: write: write_orig:: some arbitrary operation that reads some registers and writes some other registers.\n\nRun the value number over this:\nstate: for each physical register, and spill slot\nwe need either:\n\nthe virtual register name\nunknown -\n\nconflicted if it has more then one virtual register"
  },
  {
    "objectID": "lectures/ra-checking.html#steps-still-no-control-flow",
    "href": "lectures/ra-checking.html#steps-still-no-control-flow",
    "title": "Testing Register allocators",
    "section": "steps (still no control flow )",
    "text": "steps (still no control flow )\nWhen we see a Spill, Reload, or Move, we copy the symbolic state from the source location (register or spill slot) to the destination location.\nWhen we see an Op, we do some checks then some updates:\nFor each read (input) register, we examine the symbolic value stored in the given register.\nIf that symbol matches the virtual register that the original instruction used, then the allocator has properly conveyed the virtual register’s value to its use here, and thus the allocation is correct\nIf not, we can signal a checker error, and look for the bug in our register allocator. why are there no false positives?\nFor each write (output) register, we set the symbolic value stored in the given CPU register to be the given virtual register."
  },
  {
    "objectID": "lectures/ra-checking.html#control-flow",
    "href": "lectures/ra-checking.html#control-flow",
    "title": "Testing Register allocators",
    "section": "control flow",
    "text": "control flow\nWe can use data flow and a lattice\nhere is the lattice\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[Unknown]\nB[VR0]\nC[VR1]\nD[VR2]\nE[Conflicted]\nA--&gt;B\nA--&gt;C\nA--&gt;D\nB --&gt;E\nC--&gt; E\nD--&gt; E"
  },
  {
    "objectID": "lectures/ra-checking.html#now-for-the-data-flow",
    "href": "lectures/ra-checking.html#now-for-the-data-flow",
    "title": "Testing Register allocators",
    "section": "now for the data flow",
    "text": "now for the data flow\nWe start out with all physical registers and spill slots as ‘unknown’ At each join point move down the lattice\nconflicted is ok, so long as it is not used\nSince the number of physical registers and spill slots is finite we can can merge all of them at the top of each basic block.\nlike usual we might pick a good order to process basic blocks"
  },
  {
    "objectID": "lectures/ra-checking.html#how-about-an-example",
    "href": "lectures/ra-checking.html#how-about-an-example",
    "title": "Testing Register allocators",
    "section": "How about an example:",
    "text": "How about an example:\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nA[p0-&gt;v1, [sp+4] -&gt; v2]\nB[p0-&gt;v9, [sp+4] -&gt; v2]\nC[\"top,\n   reload p0 from  [sp+4]]\nA--&gt; C\nB --&gt; C\n\n\n\n\n\n\nat the top of C, we see that physical p0 is conflicted -\nbut that is not a error\nafter the reload we find it contains v2"
  },
  {
    "objectID": "lectures/ra-checking.html#tracing-pointers--",
    "href": "lectures/ra-checking.html#tracing-pointers--",
    "title": "Testing Register allocators",
    "section": "tracing pointers -",
    "text": "tracing pointers -\nSince we know what virtual registers are in each spill-slot, and virtual registers have types we can tell which spill slots contain pointers\nsuppose we have a spot where we might call a gc, we could force spilling of all live vrs that contain a pointer and then tell the gc which spill locations to consider"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#reasoning-about-data-flow-global-analysis",
    "href": "lectures/revealjs_04_data_flow.qmd.html#reasoning-about-data-flow-global-analysis",
    "title": "Data Flow",
    "section": "Reasoning about data flow (global analysis)",
    "text": "Reasoning about data flow (global analysis)\nWe will see a single algorithm that can do lots of different analysis. And it works no matter what kind of control flow.\nThere is some theory to look at for this. How do we know if the algorithm will converge for any possible cfg.\nand some naming for each kind of problem"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#example",
    "href": "lectures/revealjs_04_data_flow.qmd.html#example",
    "title": "Data Flow",
    "section": "example",
    "text": "example\n\n\n     main(cond)\n     a int = const 47\n     b :int = const 42\n     br cond .left .right\n    .left\n     b: int = const 1\n     c:int = const 5 \n    jmp .end\n   .right\n     a :int = const 2\n     c: int = const 10\n   jmp .end\n   .end\n    d: int sub  a b\n    print d\n    ret\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \n     A[\"1: main cond\\n2: a int = const 47\\n3: b :int = const 42\\n4:br cond left .right\"] \n   \n   B[\"5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A  -- true --&gt; B\n    A  --false --&gt; C\n    B --&gt; D\n    C --&gt; D"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#first-we-are-going-to-look-at-a-specific-problem-reaching-definitions",
    "href": "lectures/revealjs_04_data_flow.qmd.html#first-we-are-going-to-look-at-a-specific-problem-reaching-definitions",
    "title": "Data Flow",
    "section": "first we are going to look at a specific problem “reaching definitions”",
    "text": "first we are going to look at a specific problem “reaching definitions”\nReaching definitions are an example of a global property that require you to look at an entire CFG."
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#definitions",
    "href": "lectures/revealjs_04_data_flow.qmd.html#definitions",
    "title": "Data Flow",
    "section": "definitions",
    "text": "definitions\nA Use: An instruction uses all of its arguments. (So any instruction with arguments is a “use.”), a binary instruction is two uses.\nA definition is place in the program that assigns a value to an instruction. For Bril, a definition is a value instruction (has a dest )\nA definition D reaches a point P (instruction) in the program if there is an execution path from D to P, and the variable in D is not overwritten on the path.\nAvailable: Definitions that reach a given point in the program are available at that point.\nif an instruction writes a variable it kills all prior definitions that write the same variable"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#reaching-definitions-problem-determine-which-definitions-reach-which-uses.",
    "href": "lectures/revealjs_04_data_flow.qmd.html#reaching-definitions-problem-determine-which-definitions-reach-which-uses.",
    "title": "Data Flow",
    "section": "Reaching definitions problem: determine which definitions reach which uses.",
    "text": "Reaching definitions problem: determine which definitions reach which uses.\nThe above program has 8 definitions, Which we could represent by a bit vector of size 8.\nWe could build a 2d matrix - definitions by uses, where a 1 bit indicates that this definition reaches this use. As a matrix this would be very sparse, later when we do ssa forms will see a very cool compression technique. Algorithms that use this kind of matrix are called bit-vector methods."
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#a-program-point-is-an-instruction",
    "href": "lectures/revealjs_04_data_flow.qmd.html#a-program-point-is-an-instruction",
    "title": "Data Flow",
    "section": "A program point is an instruction",
    "text": "A program point is an instruction\nA definition of a variable v reaches just after a program point p if and only if:\n\nthe definition reaches the point just before p\nthe variable v is not redefined at p\n\nor\n\nthe variable v is defined at p."
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#calculate-in-and-out",
    "href": "lectures/revealjs_04_data_flow.qmd.html#calculate-in-and-out",
    "title": "Data Flow",
    "section": "calculate in and out",
    "text": "calculate in and out\nFor a given block b, we can compute two sets (of definitions):\n\nkill(b) = all defs in the program that assign to y, and there is a def of y in b\n\ngen(b) = definitions in b that reach the bottom of b\n\nReaching defs will need iteration. but these sets do not change"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#and-now-globally",
    "href": "lectures/revealjs_04_data_flow.qmd.html#and-now-globally",
    "title": "Data Flow",
    "section": "And now globally:",
    "text": "And now globally:\n\n\\(OUT(b) = (in(b) - kill(b) ) \\cup gen(b)\\)\n\\(IN(b) = \\cup \\left( \\operatorname{OUT}(p) \\mid p \\in predecessors(b) \\right))\\)\n\nWe call the function for 1 the transfer function for the block, and the function for 2 the merge function"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#pseudo-code-we-can-solve-for-in-and-out-iteratively-using-a-worklist",
    "href": "lectures/revealjs_04_data_flow.qmd.html#pseudo-code-we-can-solve-for-in-and-out-iteratively-using-a-worklist",
    "title": "Data Flow",
    "section": "pseudo code : We can solve for IN and OUT iteratively using a worklist",
    "text": "pseudo code : We can solve for IN and OUT iteratively using a worklist\n// Initialize\nfor all CFG nodes n in N,\n    OUT[n] = emptyset; // can optimize by OUT[n] = GEN[n];\n\n// put all nodes into the changed set\n// N is all nodes in graph,\nChanged = N;\n\n// Iterate \nwhile (Changed != emptyset)\n{\n    choose a node n in Changed;\n    // remove it from the changed set\n    Changed = Changed -{ n };\n\n    // init IN[n] to be empty\n    IN[n] = emptyset;\n  \n    // calculate IN[n] from predecessors' OUT[p]\n    for all nodes p in predecessors(n)\n         IN[n] = IN[n] Union OUT[p];\n\n    oldout = OUT[n]; // save old OUT[n]\n    \n    // update OUT[n] using transfer function f_n ()\n    OUT[n] = GEN[n] Union (IN[n] -KILL[n]);\n\n    // any change to OUT[n] compared to previous value?\n    if (OUT[n] changed) // compare oldout vs. OUT[n]\n    {    \n        // if yes, put all successors of n into the changed set\n        for all nodes s in successors(n)\n             Changed = Changed U { s };\n    }\n}"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#questions",
    "href": "lectures/revealjs_04_data_flow.qmd.html#questions",
    "title": "Data Flow",
    "section": "questions",
    "text": "questions\nDoes this always converge?\nwhat order do we want to select nodes (basic blocks)?\n\nallways since the sets change in one direction\nvisit a node after visiting its preds. Reverse post order."
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#a-second-problem-liveness-",
    "href": "lectures/revealjs_04_data_flow.qmd.html#a-second-problem-liveness-",
    "title": "Data Flow",
    "section": "a second problem liveness-",
    "text": "a second problem liveness-\nA variable is live at some point if it holds a value that may be needed in the future, or equivalently if its value may be read before the next time the variable is written to.\n             live = {}\nb = 3        live = b\nc = 5        live = b c \na = f(b * c) live = a"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#global-liveness",
    "href": "lectures/revealjs_04_data_flow.qmd.html#global-liveness",
    "title": "Data Flow",
    "section": "global liveness",
    "text": "global liveness\n\nOUT(exit) = {}\nIN(b) = gen(b) union ( OUT(b) - KILL(b))\nOUT(b) = union IN(b)"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#an-example",
    "href": "lectures/revealjs_04_data_flow.qmd.html#an-example",
    "title": "Data Flow",
    "section": "An example",
    "text": "An example\n// in: {}; predecessor blocks: none\nb1: a = 3; \n    b = 5;\n    d = 4;\n    x = 100; //x is never being used later thus not in the out set {a,b,d}\n    t = a &gt; b\n    br t .t .f \n   // out: {a,b,d}    //union of all (in) successors of b1 =&gt; b2: {a,b}, and b3:{b,d}  \n\n\n\n.t   // in: {a,b}; predecessor blocks: b1\nb2: c = a + b;\n    d = 2;\n// out: {b,d}\n\n\n.f \nb3:  in: {b,d}; predecessor blocks: b1 and b2\n    c = 4;\n    return b * d + c;\n// out:{}\nThis can be solved using the same code as before, flip pred, successors because its backward, reverse in and out, set elements are variable names"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#data-flow-framework",
    "href": "lectures/revealjs_04_data_flow.qmd.html#data-flow-framework",
    "title": "Data Flow",
    "section": "data flow framework",
    "text": "data flow framework\nThe data flow framework. Here’s how you solve a global analysis problem by imbuing a local analysis with a dose of data-flow magic:\n\nFigure out the thing you want to know at the entry and exit of each block.\nWrite an equation for every block relating that thing at the entry to that thing at the exit. (In general, this is a local analysis for the block.), calculate GEN and KILL\nGenerate equalities according to the edges in the CFG.\nSolve the system of equations! (Using a general solver algorithm that you don’t need to adapt to every problem.)"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#loops",
    "href": "lectures/revealjs_04_data_flow.qmd.html#loops",
    "title": "Data Flow",
    "section": "loops",
    "text": "loops\nThis algorithm has no problems with loops!\nTheory – the requirements for a general data flow analysis. How do you know the worklist algorithm terminates and gives you the right answer?"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#partial-orders",
    "href": "lectures/revealjs_04_data_flow.qmd.html#partial-orders",
    "title": "Data Flow",
    "section": "partial orders",
    "text": "partial orders\nThe domain of values you’re trying compute needs to form a partial order with a unique lower bound. The rough idea is that the worklist algorithm should only “move” values monotonically in the order, so it’s guaranteed to eventually terminate.\nIn terms of a partial order ⊑, the merge function is the meet (greatest lower bound) operator ⊓; the initial value is the top value ⊤; and the transfer function must be a monotonic function, so x ⊑ y implies f(x) ⊑ f(y)."
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#other-data-flow-problems",
    "href": "lectures/revealjs_04_data_flow.qmd.html#other-data-flow-problems",
    "title": "Data Flow",
    "section": "other data flow problems",
    "text": "other data flow problems\nMore examples of things you can do with the data flow framework.\n\nReaching definitions.\nLive variables: which variables are both defined and going to be used at some point in the future?\nConstant propagation: which variables have statically knowable constant values?\nAvailable expressions: which expressions have already been computed in the past? (Useful in CSE.)\nInitialized variables: like in Java, which variables have had something written to them?\nInterval analysis: what is the numerical range of values that a given variable might hold?"
  },
  {
    "objectID": "lectures/revealjs_04_data_flow.qmd.html#ud-chains",
    "href": "lectures/revealjs_04_data_flow.qmd.html#ud-chains",
    "title": "Data Flow",
    "section": "ud chains",
    "text": "ud chains\nIn data flow we talked about a matrix definitions by uses which is very sparse and very slow to process.\nuse-def chains, for each use build a list of all defs that might reach that use.\ndef-use chains for each def calculate the set of all uses that the def might reach.\nBoth of these are good, but we are going use a much better data structure that is both smaller and faster to process. We also want ways to talk about loops in programs, since optimizations that move instructions inside loops to a place outside loops often speed up programs"
  },
  {
    "objectID": "lectures/04_data_flow.html",
    "href": "lectures/04_data_flow.html",
    "title": "Data Flow",
    "section": "",
    "text": "We will see a single algorithm that can do lots of different analysis. And it works no matter what kind of control flow.\nThere is some theory to look at for this. How do we know if the algorithm will converge for any possible cfg.\nand some naming for each kind of problem"
  },
  {
    "objectID": "lectures/04_data_flow.html#reasoning-about-data-flow-global-analysis",
    "href": "lectures/04_data_flow.html#reasoning-about-data-flow-global-analysis",
    "title": "Data Flow",
    "section": "",
    "text": "We will see a single algorithm that can do lots of different analysis. And it works no matter what kind of control flow.\nThere is some theory to look at for this. How do we know if the algorithm will converge for any possible cfg.\nand some naming for each kind of problem"
  },
  {
    "objectID": "lectures/04_data_flow.html#example",
    "href": "lectures/04_data_flow.html#example",
    "title": "Data Flow",
    "section": "example",
    "text": "example\n\n\n     main(cond)\n     a int = const 47\n     b :int = const 42\n     br cond .left .right\n    .left\n     b: int = const 1\n     c:int = const 5 \n    jmp .end\n   .right\n     a :int = const 2\n     c: int = const 10\n   jmp .end\n   .end\n    d: int sub  a b\n    print d\n    ret\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \n     A[\"1: main cond\\n2: a int = const 47\\n3: b :int = const 42\\n4:br cond left .right\"] \n   \n   B[\"5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A  -- true --&gt; B\n    A  --false --&gt; C\n    B --&gt; D\n    C --&gt; D\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \n     A[\"1: main cond\\n2: a int = const 47\\n3: b :int = const 42\\n4:br cond left .right\"] \n   \n   B[\"5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A  -- true --&gt; B\n    A  --false --&gt; C\n    B --&gt; D\n    C --&gt; D"
  },
  {
    "objectID": "lectures/04_data_flow.html#first-we-are-going-to-look-at-a-specific-problem-reaching-definitions",
    "href": "lectures/04_data_flow.html#first-we-are-going-to-look-at-a-specific-problem-reaching-definitions",
    "title": "Data Flow",
    "section": "first we are going to look at a specific problem “reaching definitions”",
    "text": "first we are going to look at a specific problem “reaching definitions”\nReaching definitions are an example of a global property that require you to look at an entire CFG."
  },
  {
    "objectID": "lectures/04_data_flow.html#definitions",
    "href": "lectures/04_data_flow.html#definitions",
    "title": "Data Flow",
    "section": "definitions",
    "text": "definitions\nA Use: An instruction uses all of its arguments. (So any instruction with arguments is a “use.”), a binary instruction is two uses.\nA definition is place in the program that assigns a value to an instruction. For Bril, a definition is a value instruction (has a dest )\nA definition D reaches a point P (instruction) in the program if there is an execution path from D to P, and the variable in D is not overwritten on the path.\nAvailable: Definitions that reach a given point in the program are available at that point.\nif an instruction writes a variable it kills all prior definitions that write the same variable"
  },
  {
    "objectID": "lectures/04_data_flow.html#reaching-definitions-problem-determine-which-definitions-reach-which-uses.",
    "href": "lectures/04_data_flow.html#reaching-definitions-problem-determine-which-definitions-reach-which-uses.",
    "title": "Data Flow",
    "section": "Reaching definitions problem: determine which definitions reach which uses.",
    "text": "Reaching definitions problem: determine which definitions reach which uses.\nThe above program has 8 definitions, Which we could represent by a bit vector of size 8.\nWe could build a 2d matrix - definitions by uses, where a 1 bit indicates that this definition reaches this use. As a matrix this would be very sparse, later when we do ssa forms will see a very cool compression technique. Algorithms that use this kind of matrix are called bit-vector methods."
  },
  {
    "objectID": "lectures/04_data_flow.html#a-program-point-is-an-instruction",
    "href": "lectures/04_data_flow.html#a-program-point-is-an-instruction",
    "title": "Data Flow",
    "section": "A program point is an instruction",
    "text": "A program point is an instruction\nA definition of a variable v reaches just after a program point p if and only if:\n\nthe definition reaches the point just before p\nthe variable v is not redefined at p\n\nor\n\nthe variable v is defined at p.\n\n\nWhat about multiple predecessors? p is the first instruction of a block with multiple preds.\nIf a definition reaches a point immediately after at least one pred of p then it reaches the point immediately before p.\nThis is a union operation.\nWe are moving information down from definition. This is called forward propagation\n\nDefine two sets IN and OUT that hold definitions\nIN is the set of definitions that reach a point immediately before p\nOUT is the set of definitions that reach a point immediately after p\n\nTo illustrate this, I”ll use pairs (variable, def) for each set, but the def already includes the variable so real implementations can just use the def\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \nA_IN[\"A_IN={}\"]\nA_OUT[\"A_OUT={(cond,1),(a,2),(b,3)}\"]\n\nB_IN[\"B_IN={(cond,1),(a,2),(b,3)}\"]\nB_OUT[\"B_OUT={(cond,1),(a,2),(b,5),(c,6)}\"]\n\nC_IN[\"IN={(cond,1),(a,2),(b,3)}\"]\nC_OUT[\"OUT={(cond,1),(a,8),(b,3,(c,9)}\"]\n\nD_IN[\"IN={(cond,1),(a,2),(a,8) (b,5), (b,3), (c,6), (c,9)}\"]\n \n  A[\"blk a\n    1: main cond\n   2: a int = const 47\n   3: b :int = const 42\n   4:br cond .left .right\"] \n   \n   B[\"blk b\n   5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"blk c\n     8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A_IN --&gt; A \n    A --&gt; A_OUT\n    A_OUT  -- true --&gt; B_IN\n    B_IN --&gt; B\n    B --&gt; B_OUT\n    A_OUT --false --&gt; C_IN\n    C_IN --&gt; C\n    C--&gt;   C_OUT\n    B_OUT--&gt; D_IN\n    C_OUT--&gt; D_IN\n    D_IN --&gt; D\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\nstyle A text-align: left\nstyle B  text-align: left\n%% nodes \nA_IN[\"A_IN={}\"]\nA_OUT[\"A_OUT={(cond,1),(a,2),(b,3)}\"]\n\nB_IN[\"B_IN={(cond,1),(a,2),(b,3)}\"]\nB_OUT[\"B_OUT={(cond,1),(a,2),(b,5),(c,6)}\"]\n\nC_IN[\"IN={(cond,1),(a,2),(b,3)}\"]\nC_OUT[\"OUT={(cond,1),(a,8),(b,3,(c,9)}\"]\n\nD_IN[\"IN={(cond,1),(a,2),(a,8) (b,5), (b,3), (c,6), (c,9)}\"]\n \n  A[\"blk a\n    1: main cond\n   2: a int = const 47\n   3: b :int = const 42\n   4:br cond .left .right\"] \n   \n   B[\"blk b\n   5: b: int = const 1\n   6 c:int = const 5 \n   7 jmp .end\"]\n  \n   C[\"blk c\n     8: a :int = const 2\n   9: c: int = const 10\n   10 jmp .end\"]\n    D[\"11: d: int sub  a b\n    12 print d\n    13 ret\"]\n%% edges\n    A_IN --&gt; A \n    A --&gt; A_OUT\n    A_OUT  -- true --&gt; B_IN\n    B_IN --&gt; B\n    B --&gt; B_OUT\n    A_OUT --false --&gt; C_IN\n    C_IN --&gt; C\n    C--&gt;   C_OUT\n    B_OUT--&gt; D_IN\n    C_OUT--&gt; D_IN\n    D_IN --&gt; D"
  },
  {
    "objectID": "lectures/04_data_flow.html#calculate-in-and-out",
    "href": "lectures/04_data_flow.html#calculate-in-and-out",
    "title": "Data Flow",
    "section": "calculate in and out",
    "text": "calculate in and out\nFor a given block b, we can compute two sets (of definitions):\n\nkill(b) = all defs in the program that assign to y, and there is a def of y in b\n\ngen(b) = definitions in b that reach the bottom of b\n\nReaching defs will need iteration. but these sets do not change"
  },
  {
    "objectID": "lectures/04_data_flow.html#and-now-globally",
    "href": "lectures/04_data_flow.html#and-now-globally",
    "title": "Data Flow",
    "section": "And now globally:",
    "text": "And now globally:\n\n\\(OUT(b) = (in(b) - kill(b) ) \\cup gen(b)\\)\n\\(IN(b) = \\cup \\left( \\operatorname{OUT}(p) \\mid p \\in predecessors(b) \\right))\\)\n\nWe call the function for 1 the transfer function for the block, and the function for 2 the merge function"
  },
  {
    "objectID": "lectures/04_data_flow.html#pseudo-code-we-can-solve-for-in-and-out-iteratively-using-a-worklist",
    "href": "lectures/04_data_flow.html#pseudo-code-we-can-solve-for-in-and-out-iteratively-using-a-worklist",
    "title": "Data Flow",
    "section": "pseudo code : We can solve for IN and OUT iteratively using a worklist",
    "text": "pseudo code : We can solve for IN and OUT iteratively using a worklist\n// Initialize\nfor all CFG nodes n in N,\n    OUT[n] = emptyset; // can optimize by OUT[n] = GEN[n];\n\n// put all nodes into the changed set\n// N is all nodes in graph,\nChanged = N;\n\n// Iterate \nwhile (Changed != emptyset)\n{\n    choose a node n in Changed;\n    // remove it from the changed set\n    Changed = Changed -{ n };\n\n    // init IN[n] to be empty\n    IN[n] = emptyset;\n  \n    // calculate IN[n] from predecessors' OUT[p]\n    for all nodes p in predecessors(n)\n         IN[n] = IN[n] Union OUT[p];\n\n    oldout = OUT[n]; // save old OUT[n]\n    \n    // update OUT[n] using transfer function f_n ()\n    OUT[n] = GEN[n] Union (IN[n] -KILL[n]);\n\n    // any change to OUT[n] compared to previous value?\n    if (OUT[n] changed) // compare oldout vs. OUT[n]\n    {    \n        // if yes, put all successors of n into the changed set\n        for all nodes s in successors(n)\n             Changed = Changed U { s };\n    }\n}"
  },
  {
    "objectID": "lectures/04_data_flow.html#questions",
    "href": "lectures/04_data_flow.html#questions",
    "title": "Data Flow",
    "section": "questions",
    "text": "questions\nDoes this always converge?\nwhat order do we want to select nodes (basic blocks)?\n. . .\nallways since the sets change in one direction\nvisit a node after visiting its preds. Reverse post order."
  },
  {
    "objectID": "lectures/04_data_flow.html#a-second-problem-liveness-",
    "href": "lectures/04_data_flow.html#a-second-problem-liveness-",
    "title": "Data Flow",
    "section": "a second problem liveness-",
    "text": "a second problem liveness-\nA variable is live at some point if it holds a value that may be needed in the future, or equivalently if its value may be read before the next time the variable is written to.\n             live = {}\nb = 3        live = b\nc = 5        live = b c \na = f(b * c) live = a\n\nWe had to consider flow starting at the bottom so this is a backwards analysis\nfor a basic block (b):\n\nGEN(s) the set of variables used in s before any assignment to s in the same block\nkill(s) the set of variables assigned in s"
  },
  {
    "objectID": "lectures/04_data_flow.html#global-liveness",
    "href": "lectures/04_data_flow.html#global-liveness",
    "title": "Data Flow",
    "section": "global liveness",
    "text": "global liveness\n\nOUT(exit) = {}\nIN(b) = gen(b) union ( OUT(b) - KILL(b))\nOUT(b) = union IN(b)"
  },
  {
    "objectID": "lectures/04_data_flow.html#an-example",
    "href": "lectures/04_data_flow.html#an-example",
    "title": "Data Flow",
    "section": "An example",
    "text": "An example\n// in: {}; predecessor blocks: none\nb1: a = 3; \n    b = 5;\n    d = 4;\n    x = 100; //x is never being used later thus not in the out set {a,b,d}\n    t = a &gt; b\n    br t .t .f \n   // out: {a,b,d}    //union of all (in) successors of b1 =&gt; b2: {a,b}, and b3:{b,d}  \n\n\n\n.t   // in: {a,b}; predecessor blocks: b1\nb2: c = a + b;\n    d = 2;\n// out: {b,d}\n\n\n.f \nb3:  in: {b,d}; predecessor blocks: b1 and b2\n    c = 4;\n    return b * d + c;\n// out:{}\nThis can be solved using the same code as before, flip pred, successors because its backward, reverse in and out, set elements are variable names"
  },
  {
    "objectID": "lectures/04_data_flow.html#data-flow-framework",
    "href": "lectures/04_data_flow.html#data-flow-framework",
    "title": "Data Flow",
    "section": "data flow framework",
    "text": "data flow framework\nThe data flow framework. Here’s how you solve a global analysis problem by imbuing a local analysis with a dose of data-flow magic:\n\nFigure out the thing you want to know at the entry and exit of each block.\nWrite an equation for every block relating that thing at the entry to that thing at the exit. (In general, this is a local analysis for the block.), calculate GEN and KILL\nGenerate equalities according to the edges in the CFG.\nSolve the system of equations! (Using a general solver algorithm that you don’t need to adapt to every problem.)\n\n\nstep 2 only looks at a single block, the iteration does not need to refigure out GEN and KILL"
  },
  {
    "objectID": "lectures/04_data_flow.html#loops",
    "href": "lectures/04_data_flow.html#loops",
    "title": "Data Flow",
    "section": "loops",
    "text": "loops\nThis algorithm has no problems with loops!\nTheory – the requirements for a general data flow analysis. How do you know the worklist algorithm terminates and gives you the right answer?"
  },
  {
    "objectID": "lectures/04_data_flow.html#partial-orders",
    "href": "lectures/04_data_flow.html#partial-orders",
    "title": "Data Flow",
    "section": "partial orders",
    "text": "partial orders\nThe domain of values you’re trying compute needs to form a partial order with a unique lower bound. The rough idea is that the worklist algorithm should only “move” values monotonically in the order, so it’s guaranteed to eventually terminate.\nIn terms of a partial order ⊑, the merge function is the meet (greatest lower bound) operator ⊓; the initial value is the top value ⊤; and the transfer function must be a monotonic function, so x ⊑ y implies f(x) ⊑ f(y).\n\nThe usual definition of a “correct” solution to a data-flow problem is the meet-over-all-paths solution: the meet of chained applications of the transfer functions for every path in the CFG from the entry block to any given block"
  },
  {
    "objectID": "lectures/04_data_flow.html#other-data-flow-problems",
    "href": "lectures/04_data_flow.html#other-data-flow-problems",
    "title": "Data Flow",
    "section": "other data flow problems",
    "text": "other data flow problems\nMore examples of things you can do with the data flow framework.\n\nReaching definitions.\nLive variables: which variables are both defined and going to be used at some point in the future?\nConstant propagation: which variables have statically knowable constant values?\nAvailable expressions: which expressions have already been computed in the past? (Useful in CSE.)\nInitialized variables: like in Java, which variables have had something written to them?\nInterval analysis: what is the numerical range of values that a given variable might hold?"
  },
  {
    "objectID": "lectures/04_data_flow.html#ud-chains",
    "href": "lectures/04_data_flow.html#ud-chains",
    "title": "Data Flow",
    "section": "ud chains",
    "text": "ud chains\nIn data flow we talked about a matrix definitions by uses which is very sparse and very slow to process.\nuse-def chains, for each use build a list of all defs that might reach that use.\ndef-use chains for each def calculate the set of all uses that the def might reach.\nBoth of these are good, but we are going use a much better data structure that is both smaller and faster to process. We also want ways to talk about loops in programs, since optimizations that move instructions inside loops to a place outside loops often speed up programs"
  },
  {
    "objectID": "lectures/revealjs_08_classic_loop_ops.qmd.html#induction-variable-elimination",
    "href": "lectures/revealjs_08_classic_loop_ops.qmd.html#induction-variable-elimination",
    "title": "8 classic loop optimizations",
    "section": "induction variable elimination",
    "text": "induction variable elimination\nfor (int i = 0; i &lt; 100; ++1){\n    f(a[i])\n}\ncalculate a[i] as: &a[0] + 4 * i in every loop iteration, but the values at each step only differ by 4\n\na_i = &a[0] before the loop\na_i = a_i + 4 (add the stride) in every iteration\nthe only remaining use of i is the test i &lt; 100, which could become a_i &lt; &a[0] + 4*100 (which is loop invariant)\n\nsteps\n1find basic induction variables i = i + e, where e is loop invariant\nwhat does this look like in ssa\nloop header:\n i1 = phi(i0, i2)\nloop body:\ni2 = i1 + e\nloop header:\n i1 = phi(i0, i2)\nloop body:\na0 = i1 + e\ni2 = a0 + e1\nfor each instruction d = c +- loop invariant see if there is a strongly connected graph in the ssa edges that only has adds and subtracts of loop invariant expressions\nStep 2 find auxiliary induction variables\nj = basic_ind * loop inv + loop invar\nfor (int i = 0; i &lt; n; i++) {\n     j = 2*i + 1;     // Y \n     k = -i;          // Y \n     l = 2*i*i + 1;   // N \n     c = c + 5;       // Y* \n}\nstep 3 replace auxiliary induction variables (derived ) by new variables without the multiply\nstep4 if the only remaining use of the induction variable is the termination test, change the test to use the new variable\nsum = 0\nfor (i = 1, i &lt; 100; i++) {\n  sum = sum + a[i -1]\n}\nin SSA form:\n   sum0 = 0\n   i0 = 1\nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t10 = i1 -1 \n   t20 = t10 * 4\n   t30 = t20 + &a\n   t40 = load t30\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   if (i2 &lt;= 100)go to l\n\ni is a basic induction variable\nt10 is a aux induction variable\nt20 is an aux induction variable\nt30 is an aux induction variable\n\nt3 has a use in the load\nt3 = t20 + &a ==&gt; t10 * 4 + &a ==&gt; (i1-1)* 4+ &a\nt3 = 4* i1 + &a - 4\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   t52 = t50 + 4\n   if (i2 &lt;= 100)go to l\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   // i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   //i2 = i1 + 1\n   t52 = t50 + 4\n   if (t52 &lt;= 396 + &a )go to l"
  },
  {
    "objectID": "lectures/revealjs_08_classic_loop_ops.qmd.html#loop-un-switching",
    "href": "lectures/revealjs_08_classic_loop_ops.qmd.html#loop-un-switching",
    "title": "8 classic loop optimizations",
    "section": "loop un-switching",
    "text": "loop un-switching\nfor (int i = 0 ; i &lt; 100; ++1){\n    if (c) {  // c is loop invariant \n        f(i)\n    } else {\n        g(i)\n    }\n}\nlook for special patterns and replace\nif (c) {  // c is loop invariant \n   for (int i = 0 ; i &lt; 100; ++1){\n        f(i)\n    } \n}else {\n    for (int i = 0 ; i &lt; 100; ++1){\n        g(i)\n    }\n}\nThis is often done before vectorization\nloop fusion\nfor (i = 0; i &lt; 100 ; ++){\n s0:   b[i] = f(a[i])\n}\nfor (i = 0; i &lt; 100 ; ++){\n s1:   c[i] = f(b[i])\n}\n\nwhen is it legal to do this?\nWhen can we get rid of the b array?\n\nThere is also an optimization that goes the other way split a loop so that each statement becomes a separate loop incase we could run as vectors\nThese sort of loop optimizations would make good projects"
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html",
    "href": "lectures/08_classic_loop_ops.html",
    "title": "8 classic loop optimizations",
    "section": "",
    "text": "Loops optimizations are important because\nWhat are classic loop optimizations?\nLess classic loop optimizations\nFirst recall natural loops\ndef of loop invariant for an instruction d = op a,b\nin SSA form if we find a loop invariant instruction we can always move it into the pre-header, because the value it writes is never rewritten, and the values that it depends on come from outside the loop\nconditions when moving an instruction d = a op b is ok\ncan move d\nL0: d = 0 preheader L1: if (i&gt;=N) goto L2 i = i + 1 d = a ⊕ b = d goto L1 L2: x = d ```\nno good d used after the loop, would not be changed if the loop executes zero times\nno good d reassigned in the loop, do invar would be changed\nwhile (e) { j = loopinv // may never execute S }\nj = loopinv // always executes while (e) { S }\nif (e) { j = loopinv // may never execute while (e) { S }\n} ````"
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "href": "lectures/08_classic_loop_ops.html#induction-variable-elimination",
    "title": "8 classic loop optimizations",
    "section": "induction variable elimination",
    "text": "induction variable elimination\nfor (int i = 0; i &lt; 100; ++1){\n    f(a[i])\n}\ncalculate a[i] as: &a[0] + 4 * i in every loop iteration, but the values at each step only differ by 4\n\na_i = &a[0] before the loop\na_i = a_i + 4 (add the stride) in every iteration\nthe only remaining use of i is the test i &lt; 100, which could become a_i &lt; &a[0] + 4*100 (which is loop invariant)\n\nsteps\n1find basic induction variables i = i + e, where e is loop invariant\nwhat does this look like in ssa\nloop header:\n i1 = phi(i0, i2)\nloop body:\ni2 = i1 + e\nloop header:\n i1 = phi(i0, i2)\nloop body:\na0 = i1 + e\ni2 = a0 + e1\nfor each instruction d = c +- loop invariant see if there is a strongly connected graph in the ssa edges that only has adds and subtracts of loop invariant expressions\nStep 2 find auxiliary induction variables\nj = basic_ind * loop inv + loop invar\nfor (int i = 0; i &lt; n; i++) {\n     j = 2*i + 1;     // Y \n     k = -i;          // Y \n     l = 2*i*i + 1;   // N \n     c = c + 5;       // Y* \n}\nstep 3 replace auxiliary induction variables (derived ) by new variables without the multiply\nstep4 if the only remaining use of the induction variable is the termination test, change the test to use the new variable\nsum = 0\nfor (i = 1, i &lt; 100; i++) {\n  sum = sum + a[i -1]\n}\nin SSA form:\n   sum0 = 0\n   i0 = 1\nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t10 = i1 -1 \n   t20 = t10 * 4\n   t30 = t20 + &a\n   t40 = load t30\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   if (i2 &lt;= 100)go to l\n\ni is a basic induction variable\nt10 is a aux induction variable\nt20 is an aux induction variable\nt30 is an aux induction variable\n\nt3 has a use in the load\nt3 = t20 + &a ==&gt; t10 * 4 + &a ==&gt; (i1-1)* 4+ &a\nt3 = 4* i1 + &a - 4\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   i2 = i1 + 1\n   t52 = t50 + 4\n   if (i2 &lt;= 100)go to l\n   sum0 = 0\n   i0 = 1\n   t50 = &a -4  // initial value \nL: sum1 = phi(sum0, sum2)\n   // i1 = phi(i0, i2)\n   t51 = phi(t50, t52)\n   //t10 = i1 -1 \n   //t20 = t10 * 4\n   //t30 = t20 + &a\n   t40 = load t50\n   sum2 = sum1 + t40\n   //i2 = i1 + 1\n   t52 = t50 + 4\n   if (t52 &lt;= 396 + &a )go to l"
  },
  {
    "objectID": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "href": "lectures/08_classic_loop_ops.html#loop-un-switching",
    "title": "8 classic loop optimizations",
    "section": "loop un-switching",
    "text": "loop un-switching\nfor (int i = 0 ; i &lt; 100; ++1){\n    if (c) {  // c is loop invariant \n        f(i)\n    } else {\n        g(i)\n    }\n}\nlook for special patterns and replace\nif (c) {  // c is loop invariant \n   for (int i = 0 ; i &lt; 100; ++1){\n        f(i)\n    } \n}else {\n    for (int i = 0 ; i &lt; 100; ++1){\n        g(i)\n    }\n}\nThis is often done before vectorization\nloop fusion\nfor (i = 0; i &lt; 100 ; ++){\n s0:   b[i] = f(a[i])\n}\nfor (i = 0; i &lt; 100 ; ++){\n s1:   c[i] = f(b[i])\n}\n\nwhen is it legal to do this?\nWhen can we get rid of the b array?\n\nThere is also an optimization that goes the other way split a loop so that each statement becomes a separate loop incase we could run as vectors\nThese sort of loop optimizations would make good projects"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "title": "local value numbering",
    "section": "local value numbering covers lot of optimizations that look different",
    "text": "local value numbering covers lot of optimizations that look different\ndead code elimination\n\nmain {\n    a: int = const 100;\n    a: int = const 42;\n    print a;\n\n}\n\ncopy propagation\n\nmain{\n    x: int = const 4;\n    copy1: int = id x;\n    copy2: int = id copy1;\n    print copy2;\n}\n\ncommon sub-expression elimination cse \n\nmain {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#variables-vis-values",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#variables-vis-values",
    "title": "local value numbering",
    "section": "variables vis values",
    "text": "variables vis values\nWe want to stop thinking about variables and think about values. Two instructions are redundant if they compute the same value."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#extension-3",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#extension-3",
    "title": "local value numbering",
    "section": "extension 3",
    "text": "extension 3\nconstant folding \n   a: int const 1;\n   b: int const 2;\n   c: add a b;\n\nif both value numbers are pointing to constants- actually do the add"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#problem-canonical-variables-might-be-overwritten",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#problem-canonical-variables-might-be-overwritten",
    "title": "local value numbering",
    "section": "problem: canonical variables might be overwritten",
    "text": "problem: canonical variables might be overwritten\nx = a+b       x =        = a+b\n\none option is to save the value, if x will be overwritten add a temp\nt = a+b\nx = t \nx = \n  = t"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#pseudo-code",
    "title": "local value numbering",
    "section": "pseudo code",
    "text": "pseudo code\n   table = mapping from value tuples to canonical variables,\n     with each row numbered\n   \n   var2num = mapping from variable names to their current\n     value numbers (i.e., rows in table)\n\n   for instr in block:\n       value = (instr.op, var2num[instr.args[0]], ...)\n\n       if value in table:\n           # The value has been computed before; reuse it.\n           num, var = table[value]\n           delete the instruction \n\n       else:\n           # A newly computed value.\n           num = fresh value number\n\n           dest = instr.dest\n           if instr.dest  will be overwritten later:\n                dest = fresh variable name\n                instr.dest = dest\n           else:\n                dest = instr.dest\n\n           table[value] = num, dest\n\n           for a in instr.args:\n               replace a with table[var2num[a]].var\n\n       var2num[instr.dest] = num"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering.",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#local-value-numbering.",
    "title": "local value numbering",
    "section": "Local value numbering.",
    "text": "Local value numbering.\nYou can see one implementation in lvn.py in the Bril repository. But seriously, don’t be tempted! You want to write your implementation without looking at mine!\nexamples"
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#testing-your-optimizations",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#testing-your-optimizations",
    "title": "local value numbering",
    "section": "Testing Your Optimizations",
    "text": "Testing Your Optimizations\nAs part of your tasks for this lesson, you will implement your first two optimizations. The two main things you want your optimizations to do are:\n\nNot break programs.\nMake programs faster, most of the time."
  },
  {
    "objectID": "lectures/revealjs_03b_local_value_numbering.qmd.html#think-carefully-about-how-to-make-a-convincing-case-for-each-of-those-criteria.",
    "href": "lectures/revealjs_03b_local_value_numbering.qmd.html#think-carefully-about-how-to-make-a-convincing-case-for-each-of-those-criteria.",
    "title": "local value numbering",
    "section": "Think carefully about how to make a convincing case for each of those criteria.",
    "text": "Think carefully about how to make a convincing case for each of those criteria.\nOne tempting methodology might be to hand write a few small test-case Bril programs (or, worse, borrow the woefully inadequate ones sitting around in the Bril git repository), run them through your optimizations, and look at them to check whether they look right. This does not amount to convincing evidence (maybe you can think of a few specific reasons why)."
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html",
    "href": "lectures/03b_local_value_numbering.html",
    "title": "local value numbering",
    "section": "",
    "text": "slides from Phil Gibbons at CMU lectures/L3-Local-Opts.pdf) for more details and context on LVN\nValue numbering is a very powerful technique that removes redunancies, An instruction x + y is redundant inside a block if it has already been computed in the block, and no intervening operation redefines x or y. If the compiler finds a redundant expression, it can save that value at the first computation and replace any subsequent evaluations with references to the saved value.\n\nThe idea is simple - The algorithm executes the block, Each time it sees a new variable it gives it a value (represented as a number)\nEach time it sees an instruction it forms a hash of the op code and the value numbers of its operands and gives tha a new value number.\nTwo instructions are redundant if they have same op code and operands, which means the same value number\n\n\\(e_i\\) and \\(e_j\\) have the same value number if and only if \\(e_i\\) and \\(e_j\\) are provably equal for all possible operands of the expressions."
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "href": "lectures/03b_local_value_numbering.html#local-value-numbering-covers-lot-of-optimizations-that-look-different",
    "title": "local value numbering",
    "section": "local value numbering covers lot of optimizations that look different",
    "text": "local value numbering covers lot of optimizations that look different\ndead code elimination\n\nmain {\n    a: int = const 100;\n    a: int = const 42;\n    print a;\n\n}\n\ncopy propagation\n\nmain{\n    x: int = const 4;\n    copy1: int = id x;\n    copy2: int = id copy1;\n    print copy2;\n}\n\ncommon sub-expression elimination cse \n\nmain {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mul sum1 sum2;\n    print prod;\n}"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#variables-vis-values",
    "href": "lectures/03b_local_value_numbering.html#variables-vis-values",
    "title": "local value numbering",
    "section": "variables vis values",
    "text": "variables vis values\nWe want to stop thinking about variables and think about values. Two instructions are redundant if they compute the same value.\n\nfor example in a JIT compiler we want computation to be fast so we can get rid of all the variables\nb: int const 1;\nc: int cont 2;\na:  int b c;  \nbecomes:\n[  int const 1\n   int const 2 \n   int 0 1\n]\nless storage, args are just pointers, instructions are smaller. faster because any use points to the corresponding def without any searching.\n\nPseudo code (similar to an interpreter)\n\nhash table constants and expressions of value numbers to value numbers and to a variable holding the value\nreverse map from variables to value numbers\n\n\n\n\n  main {\n    a: int = const 4;\n    b: int = const 2;\n    sum1: int = add a b;\n    sum2: int = add a b;\n    prod: int = mult sum1 sum2;\n    print prod\n\n  }\n\n\n\n\nkey\nvalue\ncanonical name\n\n\n\n\nconst 4\n1\na\n\n\nconst 2\n2\nb\n\n\nadd 1 2\n3\nsum1\n\n\nmul 3 3\n4\nprod\n\n\n\n\n\n\nname\nvalue\n\n\n\n\na\n1\n\n\nb\n2\n\n\nsum1\n3\n\n\nsum2\n3\n\n\nprod\n4"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#extension-3",
    "href": "lectures/03b_local_value_numbering.html#extension-3",
    "title": "local value numbering",
    "section": "extension 3",
    "text": "extension 3\nconstant folding \n   a: int const 1;\n   b: int const 2;\n   c: add a b;\n\nif both value numbers are pointing to constants- actually do the add"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#problem-canonical-variables-might-be-overwritten",
    "href": "lectures/03b_local_value_numbering.html#problem-canonical-variables-might-be-overwritten",
    "title": "local value numbering",
    "section": "problem: canonical variables might be overwritten",
    "text": "problem: canonical variables might be overwritten\nx = a+b       x =        = a+b\n. . .\none option is to save the value, if x will be overwritten add a temp\nt = a+b\nx = t \nx = \n  = t"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#pseudo-code",
    "href": "lectures/03b_local_value_numbering.html#pseudo-code",
    "title": "local value numbering",
    "section": "pseudo code",
    "text": "pseudo code\n   table = mapping from value tuples to canonical variables,\n     with each row numbered\n   \n   var2num = mapping from variable names to their current\n     value numbers (i.e., rows in table)\n\n   for instr in block:\n       value = (instr.op, var2num[instr.args[0]], ...)\n\n       if value in table:\n           # The value has been computed before; reuse it.\n           num, var = table[value]\n           delete the instruction \n\n       else:\n           # A newly computed value.\n           num = fresh value number\n\n           dest = instr.dest\n           if instr.dest  will be overwritten later:\n                dest = fresh variable name\n                instr.dest = dest\n           else:\n                dest = instr.dest\n\n           table[value] = num, dest\n\n           for a in instr.args:\n               replace a with table[var2num[a]].var\n\n       var2num[instr.dest] = num"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#local-value-numbering.",
    "href": "lectures/03b_local_value_numbering.html#local-value-numbering.",
    "title": "local value numbering",
    "section": "Local value numbering.",
    "text": "Local value numbering.\nYou can see one implementation in lvn.py in the Bril repository. But seriously, don’t be tempted! You want to write your implementation without looking at mine!\nexamples"
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#testing-your-optimizations",
    "href": "lectures/03b_local_value_numbering.html#testing-your-optimizations",
    "title": "local value numbering",
    "section": "Testing Your Optimizations",
    "text": "Testing Your Optimizations\nAs part of your tasks for this lesson, you will implement your first two optimizations. The two main things you want your optimizations to do are:\n\nNot break programs.\nMake programs faster, most of the time.\n\n\nAs with every task in this class, part of the work is checking that you have done what you set out to do — in this case, that your optimizations do those two things."
  },
  {
    "objectID": "lectures/03b_local_value_numbering.html#think-carefully-about-how-to-make-a-convincing-case-for-each-of-those-criteria.",
    "href": "lectures/03b_local_value_numbering.html#think-carefully-about-how-to-make-a-convincing-case-for-each-of-those-criteria.",
    "title": "local value numbering",
    "section": "Think carefully about how to make a convincing case for each of those criteria.",
    "text": "Think carefully about how to make a convincing case for each of those criteria.\nOne tempting methodology might be to hand write a few small test-case Bril programs (or, worse, borrow the woefully inadequate ones sitting around in the Bril git repository), run them through your optimizations, and look at them to check whether they look right. This does not amount to convincing evidence (maybe you can think of a few specific reasons why).\n\nWhile there are many ways to be convincing, a pretty good way might be to run your optimization on *every single available Bril benchmark, systematically check that it still produces the right output for at least one input, and collect aggregate statistics about some metric you’re interested in. This is a nice way to check for unexpected behavior in programs that you didn’t carefully write yourself to test the cases you’re thinking of.\n\nIf this is the route you choose, you can do it however you like, There is a simple tool that you can consider using, called Brench. Brench is not very fancy; it does three things:\n\nIt makes it easy to run a long list of inputs through several different commands. (For example, you can run a long list of Bril benchmarks through an “interpret” command and an “optimize-and-then-interpret” command.)\nIt checks that all the commands agree on their output. (So, in our use case, it checks that optimizing the benchmark doesn’t change its output when interpreted.)\nIt can collect a statistic from each command for comparison. (Like the number of dynamic instructions the interpreter executed, which is a pretty good metric for standard optimizations.)\n\nThose three things are probably what you want to do to make a convincing case for an optimization’s correctness and effectiveness, whether or not you use Brench. It’s there if you want it, but feel free to go your own way!\n:::"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#licm",
    "href": "lectures/revealjs_05b_licm.qmd.html#licm",
    "title": "loop invariant code motion",
    "section": "licm",
    "text": "licm\nLoop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop."
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#a-very-common-case-for-this-is-matrix-addressing",
    "href": "lectures/revealjs_05b_licm.qmd.html#a-very-common-case-for-this-is-matrix-addressing",
    "title": "loop invariant code motion",
    "section": "A very common case for this is matrix addressing",
    "text": "A very common case for this is matrix addressing\na[i,j] might expand to to \\(i*4*\\operatorname{stride_{a}} + j *4\\)\nfor j \n  a[i,j] = f(a[i,j+1])\nturns into\na = \nb = \nresult = 0\nfor (){\n    result += a*b\n}"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#pre-steps",
    "href": "lectures/revealjs_05b_licm.qmd.html#pre-steps",
    "title": "loop invariant code motion",
    "section": "pre steps",
    "text": "pre steps\n\nfind the natural loops\nadd pre-header\n\nif we are going to move code we often need to add a special basic block which is called a landing pad or a a pre-header create a new block b. change all the preds of the loop header to point to the pre-header, add an edge from b to the loop header\n\nneed reaching definitions"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#licm-steps",
    "href": "lectures/revealjs_05b_licm.qmd.html#licm-steps",
    "title": "loop invariant code motion",
    "section": "licm steps",
    "text": "licm steps\n\nfind loop invariant instructions,\nmove some of the loop invariant instructions to the pre-header"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#step-1",
    "href": "lectures/revealjs_05b_licm.qmd.html#step-1",
    "title": "loop invariant code motion",
    "section": "step 1",
    "text": "step 1\nAn instruction instr in a loop is loop invariant of:\nevery operand is:\n\nconstant or\nall reaching definitions of this operand are outside of the loop\nthere is exactly one def in loop reaching this operand and that def is loop invariant"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#naturally-iterative",
    "href": "lectures/revealjs_05b_licm.qmd.html#naturally-iterative",
    "title": "loop invariant code motion",
    "section": "naturally iterative",
    "text": "naturally iterative\niterate to convergence\n for each instr in  the loop\n  mark it as loop invar  iff \n     for all arguments x either\n         all reaching defs of x are outside of the loop (this covers constants)\n         or there is exactly one def of instr in the loop and that def is loop invar, and there are no uses of the dest before instr on any path in the loop"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#step-2",
    "href": "lectures/revealjs_05b_licm.qmd.html#step-2",
    "title": "loop invariant code motion",
    "section": "step 2",
    "text": "step 2\nwhen is ok to move an instr? We call this safe to move.\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\n   b1[\" n= 0\"]\n   p[\"preheader\"]\n   b3\n   b4[\"n = 2\"]\n   b5[\"m = n *2\"]\n   b6\n   b1--&gt;p\n   p--&gt; b3\n   b3--&gt; b4\n   b4--&gt; b5\n   b3--&gt; b5\n   b5--&gt; b3\n   b5--&gt; b6\n\n\n\n\n\n\ncan we move n = 2\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\n  b1[\" n= 0\"]\n   p[\"preheader\"]\n   b3\n   b4[\"n = 2\"]\n   b5\n   b6\n   b1--&gt;p\n   p--&gt; b3\n   b3--&gt; b4\n   b4--&gt; b5\n   b3--&gt; b5\n   b5--&gt; b3\n   b5--&gt; b6\n\n\n\n\n\n\n\nall uses of the variable dest in the loop, must come from this instr The basic block containing instr must execute every time around the loop\nmore formally\n\nthe def must dominate all the uses\nno other defs of the same variable\ndef dominates all the loop exits"
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#zero-trip-count-loops",
    "href": "lectures/revealjs_05b_licm.qmd.html#zero-trip-count-loops",
    "title": "loop invariant code motion",
    "section": "zero trip count loops",
    "text": "zero trip count loops\n   loop {\n     if cond goto exit\n     x = a*b \n       = x\n   }\nFor cond 3\nif the loop runs zero times, a*b is never executed\nWe can remove this condition if the dest variable is dead after the loop or the instruction can not cause a exception, this is called speculative exceptions."
  },
  {
    "objectID": "lectures/revealjs_05b_licm.qmd.html#how-about-an-example",
    "href": "lectures/revealjs_05b_licm.qmd.html#how-about-an-example",
    "title": "loop invariant code motion",
    "section": "How about an example:",
    "text": "How about an example:\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n    graph  LR;\nB1[\"B1:\n     1: b = 2\n     2: i = 1\"]\n\nB2[\"b2:\n   i lessthen 100\"]\nB3[\"B3:\n   3: a = b+1\n   4: c = 2\n   i mod 2 == 0\"]\nB4[\"b4: \n    5: d = a + d \n    6: e = 1 +d\"]\nB5[\"B5:\n    7: d= -c\n    8: f = 1+a\"]\nB6[\"B6:\n  9: i = i + 1\n     a lessthen 2\"]\nEntry --&gt; B1\nB1--&gt; B2\nB2 -- y --&gt;exit;\nB2 --n --&gt; B3\nB3 --y --&gt; B4\nB3 --n --&gt; B5\nB4--&gt; B6\nB5 --&gt; B6\nB6 --y --&gt; exit\nB6 --n --&gt; B2\n\n\n\n\n\n\nsteps\n\n\n\ncreate pre header\n\n\n\n\nb2.1 not loop invar (i &lt; 100) i reached by def outside of loop\n\n\n\n\nb3.3 loop inv ( a = b+1) b only def outside of the loop\n\n\n\n\nb3.4 loop inv (c =2) 2 is a constant\n\n\n\n\nb3.cond (i mod 2 ==0 ) not loop inv\n\n\n\n\nb4.5 (d = a +d ) not loop inv a is but not d\n\n\n\n\nb4.6 (e = 1 + d ) not loop inver\n\n\n\n\nb5.7 (d = -c ) not loop inv other def of d\n\n\n\n\nb5.8 (f = 1 +a) loop invar\n\n\n\n\nb6.9 not loop inv\n\n\n\n\nb6.cond loop inv\n\n\n\nchanged two instructions to loop invar\n\n\nrepeat"
  },
  {
    "objectID": "lectures/05b_licm.html",
    "href": "lectures/05b_licm.html",
    "title": "loop invariant code motion",
    "section": "",
    "text": "Loop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop."
  },
  {
    "objectID": "lectures/05b_licm.html#licm",
    "href": "lectures/05b_licm.html#licm",
    "title": "loop invariant code motion",
    "section": "",
    "text": "Loop invariant code motion recognizes computations in loop that produce the same value on each iteration and moves them out of the loop."
  },
  {
    "objectID": "lectures/05b_licm.html#a-very-common-case-for-this-is-matrix-addressing",
    "href": "lectures/05b_licm.html#a-very-common-case-for-this-is-matrix-addressing",
    "title": "loop invariant code motion",
    "section": "A very common case for this is matrix addressing",
    "text": "A very common case for this is matrix addressing\na[i,j] might expand to to \\(i*4*\\operatorname{stride_{a}} + j *4\\)\nfor j \n  a[i,j] = f(a[i,j+1])\nturns into\na = \nb = \nresult = 0\nfor (){\n    result += a*b\n}"
  },
  {
    "objectID": "lectures/05b_licm.html#pre-steps",
    "href": "lectures/05b_licm.html#pre-steps",
    "title": "loop invariant code motion",
    "section": "pre steps",
    "text": "pre steps\n\nfind the natural loops\nadd pre-header\n\nif we are going to move code we often need to add a special basic block which is called a landing pad or a a pre-header create a new block b. change all the preds of the loop header to point to the pre-header, add an edge from b to the loop header\n\nneed reaching definitions"
  },
  {
    "objectID": "lectures/05b_licm.html#licm-steps",
    "href": "lectures/05b_licm.html#licm-steps",
    "title": "loop invariant code motion",
    "section": "licm steps",
    "text": "licm steps\n\nfind loop invariant instructions,\nmove some of the loop invariant instructions to the pre-header"
  },
  {
    "objectID": "lectures/05b_licm.html#step-1",
    "href": "lectures/05b_licm.html#step-1",
    "title": "loop invariant code motion",
    "section": "step 1",
    "text": "step 1\nAn instruction instr in a loop is loop invariant of:\nevery operand is:\n\nconstant or\nall reaching definitions of this operand are outside of the loop\nthere is exactly one def in loop reaching this operand and that def is loop invariant"
  },
  {
    "objectID": "lectures/05b_licm.html#naturally-iterative",
    "href": "lectures/05b_licm.html#naturally-iterative",
    "title": "loop invariant code motion",
    "section": "naturally iterative",
    "text": "naturally iterative\niterate to convergence\n for each instr in  the loop\n  mark it as loop invar  iff \n     for all arguments x either\n         all reaching defs of x are outside of the loop (this covers constants)\n         or there is exactly one def of instr in the loop and that def is loop invar, and there are no uses of the dest before instr on any path in the loop"
  },
  {
    "objectID": "lectures/05b_licm.html#step-2",
    "href": "lectures/05b_licm.html#step-2",
    "title": "loop invariant code motion",
    "section": "step 2",
    "text": "step 2\nwhen is ok to move an instr? We call this safe to move.\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\n   b1[\" n= 0\"]\n   p[\"preheader\"]\n   b3\n   b4[\"n = 2\"]\n   b5[\"m = n *2\"]\n   b6\n   b1--&gt;p\n   p--&gt; b3\n   b3--&gt; b4\n   b4--&gt; b5\n   b3--&gt; b5\n   b5--&gt; b3\n   b5--&gt; b6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\n   b1[\" n= 0\"]\n   p[\"preheader\"]\n   b3\n   b4[\"n = 2\"]\n   b5[\"m = n *2\"]\n   b6\n   b1--&gt;p\n   p--&gt; b3\n   b3--&gt; b4\n   b4--&gt; b5\n   b3--&gt; b5\n   b5--&gt; b3\n   b5--&gt; b6\n\n\n\n\n\n\ncan we move n = 2\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\n  b1[\" n= 0\"]\n   p[\"preheader\"]\n   b3\n   b4[\"n = 2\"]\n   b5\n   b6\n   b1--&gt;p\n   p--&gt; b3\n   b3--&gt; b4\n   b4--&gt; b5\n   b3--&gt; b5\n   b5--&gt; b3\n   b5--&gt; b6\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n\ngraph TD\n  b1[\" n= 0\"]\n   p[\"preheader\"]\n   b3\n   b4[\"n = 2\"]\n   b5\n   b6\n   b1--&gt;p\n   p--&gt; b3\n   b3--&gt; b4\n   b4--&gt; b5\n   b3--&gt; b5\n   b5--&gt; b3\n   b5--&gt; b6\n\n\n\n\n\n\n\n\nall uses of the variable dest in the loop, must come from this instr The basic block containing instr must execute every time around the loop\nmore formally\n\nthe def must dominate all the uses\nno other defs of the same variable\ndef dominates all the loop exits"
  },
  {
    "objectID": "lectures/05b_licm.html#zero-trip-count-loops",
    "href": "lectures/05b_licm.html#zero-trip-count-loops",
    "title": "loop invariant code motion",
    "section": "zero trip count loops",
    "text": "zero trip count loops\n   loop {\n     if cond goto exit\n     x = a*b \n       = x\n   }\nFor cond 3\nif the loop runs zero times, a*b is never executed\nWe can remove this condition if the dest variable is dead after the loop or the instruction can not cause a exception, this is called speculative exceptions."
  },
  {
    "objectID": "lectures/05b_licm.html#how-about-an-example",
    "href": "lectures/05b_licm.html#how-about-an-example",
    "title": "loop invariant code motion",
    "section": "How about an example:",
    "text": "How about an example:\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n    graph  LR;\nB1[\"B1:\n     1: b = 2\n     2: i = 1\"]\n\nB2[\"b2:\n   i lessthen 100\"]\nB3[\"B3:\n   3: a = b+1\n   4: c = 2\n   i mod 2 == 0\"]\nB4[\"b4: \n    5: d = a + d \n    6: e = 1 +d\"]\nB5[\"B5:\n    7: d= -c\n    8: f = 1+a\"]\nB6[\"B6:\n  9: i = i + 1\n     a lessthen 2\"]\nEntry --&gt; B1\nB1--&gt; B2\nB2 -- y --&gt;exit;\nB2 --n --&gt; B3\nB3 --y --&gt; B4\nB3 --n --&gt; B5\nB4--&gt; B6\nB5 --&gt; B6\nB6 --y --&gt; exit\nB6 --n --&gt; B2\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\n    graph  LR;\nB1[\"B1:\n     1: b = 2\n     2: i = 1\"]\n\nB2[\"b2:\n   i lessthen 100\"]\nB3[\"B3:\n   3: a = b+1\n   4: c = 2\n   i mod 2 == 0\"]\nB4[\"b4: \n    5: d = a + d \n    6: e = 1 +d\"]\nB5[\"B5:\n    7: d= -c\n    8: f = 1+a\"]\nB6[\"B6:\n  9: i = i + 1\n     a lessthen 2\"]\nEntry --&gt; B1\nB1--&gt; B2\nB2 -- y --&gt;exit;\nB2 --n --&gt; B3\nB3 --y --&gt; B4\nB3 --n --&gt; B5\nB4--&gt; B6\nB5 --&gt; B6\nB6 --y --&gt; exit\nB6 --n --&gt; B2\n\n\n\n\n\n\nsteps\n\n\n\ncreate pre header\n\n\n\n\nb2.1 not loop invar (i &lt; 100) i reached by def outside of loop\n\n\n\n\nb3.3 loop inv ( a = b+1) b only def outside of the loop\n\n\n\n\nb3.4 loop inv (c =2) 2 is a constant\n\n\n\n\nb3.cond (i mod 2 ==0 ) not loop inv\n\n\n\n\nb4.5 (d = a +d ) not loop inv a is but not d\n\n\n\n\nb4.6 (e = 1 + d ) not loop inver\n\n\n\n\nb5.7 (d = -c ) not loop inv other def of d\n\n\n\n\nb5.8 (f = 1 +a) loop invar\n\n\n\n\nb6.9 not loop inv\n\n\n\n\nb6.cond loop inv\n\n\n\nchanged two instructions to loop invar\n\n\nrepeat"
  },
  {
    "objectID": "lectures/12_memory.html",
    "href": "lectures/12_memory.html",
    "title": "Dynamic Memory Management",
    "section": "",
    "text": "Warning\n\n\n\nnot done\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/07_llvm.html",
    "href": "lectures/07_llvm.html",
    "title": "7 LLVM",
    "section": "",
    "text": "intro to llvm\ndifference between bril and llvm\nlinks\nllvm page\nAdrians tutorial\nllvm doc\ngoogle or github pilot is very useful for this\n\n#as a first step I'm going to show how to install clang and cmake \n\n# step remove any old copies \n# the -S flag to sudo means - read from stdinput\n# the -y flag means always ans yes to apt \n# since sudo needs a password \n# -qq is the very quiet option \n!sudo -S apt purge -y -qq clang cmake &lt;  ~/pw\n!sudo -S apt install -y -qq clang cmake &lt; ~/pw\n\n\n[sudo] password for norm: The following packages were automatically installed and are no longer required:\n  cmake-data dh-elpa-helper emacsen-common libarchive13 libjsoncpp25 librhash0\nUse 'sudo apt autoremove' to remove them.\nThe following packages will be REMOVED:\n  clang* cmake*\n0 upgraded, 0 newly installed, 2 to remove and 48 not upgraded.\nAfter this operation, 21.3 MB disk space will be freed.\n\n(Reading database ... 40226 files and directories currently installed.)\nRemoving clang (1:14.0-55~exp2) ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Progress: [ 22%] [############..............................................] Progress: [ 33%] [###################.......................................] Progress: [ 44%] [#########################.................................] emoving cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] Progress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n[sudo] password for norm: Suggested packages:\n  cmake-doc ninja-build cmake-format\nThe following NEW packages will be installed:\n  clang cmake\n0 upgraded, 2 newly installed, 0 to remove and 48 not upgraded.\nNeed to get 0 B/5014 kB of archives.\nAfter this operation, 21.3 MB of additional disk space will be used.\n\nSelecting previously unselected package clang.\n(Reading database ... 40203 files and directories currently installed.)\nPreparing to unpack .../clang_1%3a14.0-55~exp2_amd64.deb ...\nProgress: [  0%] [..........................................................] Progress: [ 11%] [######....................................................] Unpacking clang (1:14.0-55~exp2) ...\nProgress: [ 22%] [############..............................................] electing previously unselected package cmake.\nPreparing to unpack .../cmake_3.22.1-1ubuntu1.22.04.2_amd64.deb ...\nProgress: [ 33%] [###################.......................................] Unpacking cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 44%] [#########################.................................] etting up clang (1:14.0-55~exp2) ...\nProgress: [ 56%] [################################..........................] Progress: [ 67%] [######################################....................] etting up cmake (3.22.1-1ubuntu1.22.04.2) ...\nProgress: [ 78%] [#############################################.............] Progress: [ 89%] [###################################################.......] rocessing triggers for man-db (2.10.2-1) ...\n\n\n\nlets take a look at llvm ir\n\n%%writefile temp.c\nint main(int argc, char** argv){\n    return argc;\n}\n\nOverwriting temp.c\n\n\n\n# call clang and dump the ir\n# # -emit-llvm  print the ir\n# -S print as text not as binary \n# 0 -  output to stdout \n# \n!clang -emit-llvm -S -o - temp.c\n\n\n; ModuleID = 'temp.c'\nsource_filename = \"temp.c\"\ntarget datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\ntarget triple = \"x86_64-pc-linux-gnu\"\n\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\n\nattributes #0 = { noinline nounwind optnone uwtable \"frame-pointer\"=\"all\" \"min-legal-vector-width\"=\"0\" \"no-trapping-math\"=\"true\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"x86-64\" \"target-features\"=\"+cx8,+fxsr,+mmx,+sse,+sse2,+x87\" \"tune-cpu\"=\"generic\" }\n\n!llvm.module.flags = !{!0, !1, !2, !3, !4}\n!llvm.ident = !{!5}\n\n!0 = !{i32 1, !\"wchar_size\", i32 4}\n!1 = !{i32 7, !\"PIC Level\", i32 2}\n!2 = !{i32 7, !\"PIE Level\", i32 2}\n!3 = !{i32 7, !\"uwtable\", i32 1}\n!4 = !{i32 7, !\"frame-pointer\", i32 2}\n!5 = !{!\"Ubuntu clang version 14.0.0-1ubuntu1.1\"}\n\n\nAn LLVM plugin is a shared library that can add additional functionality to the LLVM infrastructure. Plugins can be used to add new passes, analyses, targets, and more.\nPlugins are dynamically loaded into LLVM. Once loaded, a plugin can register new command-line options, passes, etc., that are then available for use in that invocation of the tool.\nThere is a cs6120 package that makes setting up the build process for plugins simple\nllvm ir, has two forms .bc files are bitcode, .ll forms are text versions that look like assembly.\nllvm is not written in C++ but it has a lot of features that look like C++.\n\nllvm does not use char* or std::string, it has something else called a StringRef.\nthere is no std::cout or std::cerr there are outs(), errs()\nlot of built in data structures\ncomplex class hierarchy\n\n\n\n\n\n\nflowchart TD;\nValue --&gt; Argument ;\nValue --&gt; other[\"...\"];\nValue --&gt; User;\nUser --&gt; Constant\nUser--&gt; Operator\nUser--&gt; Instruction\nConstant --&gt; ConstantExpr\nConstant--&gt; ConstantData\nOperator--&gt; ConcreteOperator\nInstruction--&gt; UnaryInst\nConstantData --&gt; ConstantInt\nConstantData --&gt; UndefValue\nInstruction --&gt; BinaryOperator\nInstruction--&gt; CallBase\n\n\n\n\n\n\n\nInstructions are a kind of Value, since everything is in SSA form, so in memory operands are pointers to instructions so if I is an instruction\nouts() &lt;&lt; *(I.getOperand(0)) ; prints an instruction\nGiven a Value* V, what kind of thing is V?\n\nisa(V) true of V is a agument\ncast(V) casts to Argument, assert falure of not Argument\ndyn_cast(V) casts to Argument returns NULL if not an argument\n\nStatic bool isLoopInvariant(const Value *V, const Loop *L) { \n    if (isa&lt;Constant&gt;(V) || isa&lt;Argument&gt;(V) || isa&lt;GlobalValue&lt;(V)) {\n         return true; } \n    //otherwise it must be an instruction…    \n    return !L-&gt;contains(cast&lt;Instruction&gt;(V)-&gt;getParent());\n     … \n}\nNavigating llvm IR - IT Containers\n\nModule - two way linked list of Functions\nFunction - two way linked list of Basic Blocks\nBasic Block - two way linked list of Instructions\n\n%5 = add i32 %4,2\nthis instruction adds two 32 bit ints, input is in register %4 and the constant 2, result goes into register %5\nblog post: Why would a grad student care about llvm\n\n%%bash \nrm -r llvm-pass-skeleton/\ngit clone   https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\n# look at  llvm-pass-skeleton/skeleton/Skeleton.cpp\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\nThe function returns PreservedAnalyses::all() to indicate that it didn’t modify M. Later, when we actually transform the program, we’ll need to return something like PreservedAnalyses::none().\nThe ModuleAnalysisManager is responsible for managing the analysis results for Module passes.\nWhen a pass requests an analysis, the ModuleAnalysisManager checks if the analysis result is already available. If it is, the ModuleAnalysisManager returns the cached result. If it’s not, the ModuleAnalysisManager runs the analysis pass, caches the result, and then returns it.\nThis allows LLVM to avoid recomputing analysis results unnecessarily, which can significantly improve the performance of the compiler.\nHere’s an example of how you might use it:\nPreservedAnalyses MyPass::run(Module &M, ModuleAnalysisManager &MAM) {\n    // Request an analysis result.\n    const auto &Result = MAM.getResult&lt;SomeAnalysis&gt;(M);\n\n    // Use the analysis result.\n    // ...\n\n    return PreservedAnalyses::all();\n}\nHere is a second example getting the dominator tree\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM) {\n        // Get the FunctionAnalysisManager.\n        FunctionAnalysisManager &FAM = MAM.getResult&lt;FunctionAnalysisManagerModuleProxy&gt;(M).getManager();\n\n        for (Function &F : M) {\n            // Skip external functions.\n            if (F.isDeclaration()) continue;\n\n            // Request the dominator tree of the function.\n            const DominatorTree &DT = FAM.getResult&lt;DominatorTreeAnalysis&gt;(F);\n\n            // Use the dominator tree.\n            // ...\n        }\n\n        return PreservedAnalyses::all();\n    }\nnow let look at the containers\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b containers  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\nError while terminating subprocess (pid=71626): \n[100%] Built target SkeletonPass\n\n\n\n# run the plugin \n# \n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp.c\n\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  ret i32 %6\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  ret i32 %6\nI saw a function called main!\n\n\n\n%%writefile temp1.c\nint main(int argc, char** argv){\n    if (argc &gt;2 )\n        return argc;\n    return 0;\n}\n\nOverwriting temp1.c\n\n\n\n!clang -fpass-plugin=`echo llvm-pass-skeleton/build/skeleton/SkeletonPass.*` temp1.c\n\nIn a function called main!\nFunction body:\n; Function Attrs: noinline nounwind optnone uwtable\ndefine dso_local i32 @main(i32 noundef %0, i8** noundef %1) #0 {\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\n}\nBasic block:\n\n  %3 = alloca i32, align 4\n  %4 = alloca i32, align 4\n  %5 = alloca i8**, align 8\n  store i32 0, i32* %3, align 4\n  store i32 %0, i32* %4, align 4\n  store i8** %1, i8*** %5, align 8\n  %6 = load i32, i32* %4, align 4\n  %7 = icmp sgt i32 %6, 2\n  br i1 %7, label %8, label %10\nInstruction: \n  %3 = alloca i32, align 4\nInstruction: \n  %4 = alloca i32, align 4\nInstruction: \n  %5 = alloca i8**, align 8\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  store i32 %0, i32* %4, align 4\nInstruction: \n  store i8** %1, i8*** %5, align 8\nInstruction: \n  %6 = load i32, i32* %4, align 4\nInstruction: \n  %7 = icmp sgt i32 %6, 2\nInstruction: \n  br i1 %7, label %8, label %10\nBasic block:\n\n8:                                                ; preds = %2\n  %9 = load i32, i32* %4, align 4\n  store i32 %9, i32* %3, align 4\n  br label %11\nInstruction: \n  %9 = load i32, i32* %4, align 4\nInstruction: \n  store i32 %9, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n10:                                               ; preds = %2\n  store i32 0, i32* %3, align 4\n  br label %11\nInstruction: \n  store i32 0, i32* %3, align 4\nInstruction: \n  br label %11\nBasic block:\n\n11:                                               ; preds = %10, %8\n  %12 = load i32, i32* %3, align 4\n  ret i32 %12\nInstruction: \n  %12 = load i32, i32* %3, align 4\nInstruction: \n  ret i32 %12\nI saw a function called main!\n\n\n\nusing IRBuilder is a mess, So I’m going to show a trick that makes it much simpler\n\n%%bash\nrm -r llvm-pass-skeleton/\ngit clone  -b rtlib  https://github.com/sampsyo/llvm-pass-skeleton.git\ncd llvm-pass-skeleton/\nmkdir -p build \ncd build \ncmake ..\nmake\n\nCloning into 'llvm-pass-skeleton'...\n\n\n-- The C compiler identification is GNU 11.4.0\n-- The CXX compiler identification is GNU 11.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /usr/bin/cc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test HAVE_FFI_CALL\n-- Performing Test HAVE_FFI_CALL - Success\n-- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so  \n-- Performing Test Terminfo_LINKABLE\n-- Performing Test Terminfo_LINKABLE - Success\n-- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so  \n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \"2.9.13\") \n-- Linker detection: GNU ld\n-- Registering SkeletonPass as a pass plugin (static build: OFF)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/norm/llvm/llvm-pass-skeleton/build\n[ 50%] Building CXX object skeleton/CMakeFiles/SkeletonPass.dir/Skeleton.cpp.o\n[100%] Linking CXX shared module SkeletonPass.so\n[100%] Built target SkeletonPass\n\n\n\n%%bash \ncat ls ~/llvm/llvm-pass-skeleton/skeleton/Skeleton.cpp \necho done\n\ncat: ls: No such file or directory\n\n\n#include \"llvm/Pass.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"llvm/Transforms/Utils/BasicBlockUtils.h\"\nusing namespace llvm;\n\nnamespace {\n\nstruct SkeletonPass : public PassInfoMixin&lt;SkeletonPass&gt; {\n    PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM) {\n        for (auto &F : M.functions()) {\n\n            // Get the function to call from our runtime library.\n            LLVMContext &Ctx = F.getContext();\n            std::vector&lt;Type*&gt; paramTypes = {Type::getInt32Ty(Ctx)};\n            Type *retType = Type::getVoidTy(Ctx);\n            FunctionType *logFuncType = FunctionType::get(retType, paramTypes, false);\n            FunctionCallee logFunc =\n                F.getParent()-&gt;getOrInsertFunction(\"logop\", logFuncType);\n\n            for (auto &B : F) {\n                for (auto &I : B) {\n                    if (auto *op = dyn_cast&lt;BinaryOperator&gt;(&I)) {\n                        // Insert *after* `op`.\n                        IRBuilder&lt;&gt; builder(op);\n                        builder.SetInsertPoint(&B, ++builder.GetInsertPoint());\n\n                        // Insert a call to our function.\n                        Value* args[] = {op};\n                        builder.CreateCall(logFunc, args);\n\n                        return PreservedAnalyses::none();\n                    }\n                }\n            }\n\n        }\n        return PreservedAnalyses::all();\n    }\n};\n\n}\n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        .APIVersion = LLVM_PLUGIN_API_VERSION,\n        .PluginName = \"Skeleton pass\",\n        .PluginVersion = \"v0.1\",\n        .RegisterPassBuilderCallbacks = [](PassBuilder &PB) {\n            PB.registerPipelineStartEPCallback(\n                [](ModulePassManager &MPM, OptimizationLevel Level) {\n                    MPM.addPass(SkeletonPass());\n                });\n        }\n    };\n}\ndone\n\n\n\n%%bash \ncat /home/norm/llvm/llvm-pass-skeleton/rtlib.c\necho\n\n#include &lt;stdio.h&gt;\nvoid logop(int i) {\n    printf(\"computed: %i\\n\", i);\n}\n\n\n\n\n%%writefile llvm-pass-skeleton/test_r.cpp\n#include &lt;stdio.h&gt;\nint main (int argc, char** argv) {\n    printf(\"%d %d\", argc, (argc + 2) * (argc +3));\n}\n\nOverwriting llvm-pass-skeleton/test_r.cpp\n\n\n\n%%bash \ncd llvm-pass-skeleton/\ncc -c rtlib.c\nclang  -fpass-plugin=build/skeleton/SkeletonPass.so -c test_r.cpp\ncc test_r.o rtlib.o\n./a.out 1 2 3 4\necho \n\ncomputed: 7\n5 56\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#partial-redundancy-elimination",
    "href": "lectures/revealjs_05c_pre.qmd.html#partial-redundancy-elimination",
    "title": "_ partial_redundancy elimination",
    "section": "partial redundancy elimination",
    "text": "partial redundancy elimination\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#simplifications",
    "href": "lectures/revealjs_05c_pre.qmd.html#simplifications",
    "title": "_ partial_redundancy elimination",
    "section": "simplifications",
    "text": "simplifications\n\nonly going to look at one expression \\(b + c\\)\ninitially all nodes in the cfg contain at most one assignment statement\nif there is a node that has multiple successors (a branch node) and one of the successors has multiple predecessors (a join) node we have added a extra node between them"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#down-safe",
    "href": "lectures/revealjs_05c_pre.qmd.html#down-safe",
    "title": "_ partial_redundancy elimination",
    "section": "down safe",
    "text": "down safe\nwe are moving computations earlier in the cfg\ndon’t move so far that it might not be used, or that an argument gets changed\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n\n\n\ncannot move b +c to top, because b changes"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#up-safe",
    "href": "lectures/revealjs_05c_pre.qmd.html#up-safe",
    "title": "_ partial_redundancy elimination",
    "section": "up-safe",
    "text": "up-safe\nWe can add a computation of \\(b+c\\) in any down-safe node. We want to pick a good one.\ndefine up-safe(block) (also called available) if \\(b+c\\) will be definitely used without being killed, computed on every path from entry to the block and not killed\nDo not add \\(b+c\\) to a block if the expression is available at that block\nup-safe is a second data flow problem\n\\[\nU_{\\text{safe}}(\\text{entry}) = \\text{false}\n\\]\n\\[\nU_{\\text{safe}}(n)=  \\text{trans}(n) \\cap_{p \\in \\text{preds}(n)} \\text{used}(p) \\cup \\text{U}_{\\text{safwe}}(p)\n\\]"
  },
  {
    "objectID": "lectures/revealjs_05c_pre.qmd.html#placement",
    "href": "lectures/revealjs_05c_pre.qmd.html#placement",
    "title": "_ partial_redundancy elimination",
    "section": "placement",
    "text": "placement\nwant a down-safe node, that is not up-safe\n\npick the closest to the entry (min number of computations)\npick a later node to lower register pressure\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\nWe could move b+c in nodes a,c or e, but e does not help"
  },
  {
    "objectID": "lectures/05c_pre.html",
    "href": "lectures/05c_pre.html",
    "title": "_ partial_redundancy elimination",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3"
  },
  {
    "objectID": "lectures/05c_pre.html#partial-redundancy-elimination",
    "href": "lectures/05c_pre.html#partial-redundancy-elimination",
    "title": "_ partial_redundancy elimination",
    "section": "",
    "text": "%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[a = b + c]\nb2[\" \"]\nb3[d = b + c]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\"t = b + c\n    a = t\"]\nb2[t = b + c]\nb3[d =t]\nb1--&gt; b3\nb2--&gt; b3"
  },
  {
    "objectID": "lectures/05c_pre.html#simplifications",
    "href": "lectures/05c_pre.html#simplifications",
    "title": "_ partial_redundancy elimination",
    "section": "simplifications",
    "text": "simplifications\n\nonly going to look at one expression \\(b + c\\)\ninitially all nodes in the cfg contain at most one assignment statement\nif there is a node that has multiple successors (a branch node) and one of the successors has multiple predecessors (a join) node we have added a extra node between them"
  },
  {
    "objectID": "lectures/05c_pre.html#down-safe",
    "href": "lectures/05c_pre.html#down-safe",
    "title": "_ partial_redundancy elimination",
    "section": "down safe",
    "text": "down safe\nwe are moving computations earlier in the cfg\ndon’t move so far that it might not be used, or that an argument gets changed\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nb1[\" \"]\nb2[\" \"]\nb3[b = d + e]\nb4[a = b + c]\nb5[\" \"]\nb6[d = b + c]\nb1 --&gt; b2\nb1 --&gt; b3\nb2 --&gt; b4\nb4 --&gt; b5\nb5 --&gt; b4\nb3 --&gt; b6\nb4 --&gt; exit\nb6 --&gt; exit\n\n\n\n\n\n\n\n\ncannot move b +c to top, because b changes"
  },
  {
    "objectID": "lectures/05c_pre.html#up-safe",
    "href": "lectures/05c_pre.html#up-safe",
    "title": "_ partial_redundancy elimination",
    "section": "up-safe",
    "text": "up-safe\nWe can add a computation of \\(b+c\\) in any down-safe node. We want to pick a good one.\ndefine up-safe(block) (also called available) if \\(b+c\\) will be definitely used without being killed, computed on every path from entry to the block and not killed\nDo not add \\(b+c\\) to a block if the expression is available at that block\nup-safe is a second data flow problem\n\\[\nU_{\\text{safe}}(\\text{entry}) = \\text{false}\n\\]\n\\[\nU_{\\text{safe}}(n)=  \\text{trans}(n) \\cap_{p \\in \\text{preds}(n)} \\text{used}(p) \\cup \\text{U}_{\\text{safwe}}(p)\n\\]"
  },
  {
    "objectID": "lectures/05c_pre.html#placement",
    "href": "lectures/05c_pre.html#placement",
    "title": "_ partial_redundancy elimination",
    "section": "placement",
    "text": "placement\nwant a down-safe node, that is not up-safe\n\npick the closest to the entry (min number of computations)\npick a later node to lower register pressure\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\ngraph TD\nA[a: Down-safe]\nB[b+c  :avail]\nC[c: Down-safe]\nD[:avail,Down-safe]\nE[e: Down-safe]\nF[b+c: Down-safe]\nA--&gt;C\nB--&gt;D\nC--&gt; E\nD--&gt; E\nE--&gt; F\n\n\n\n\n\n\nWe could move b+c in nodes a,c or e, but e does not help"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#formalizing-the-schedule-lexicographic-ordering",
    "href": "lectures/revealjs_09_poly.qmd.html#formalizing-the-schedule-lexicographic-ordering",
    "title": "9 polyhedral analysis",
    "section": "formalizing the schedule, Lexicographic ordering",
    "text": "formalizing the schedule, Lexicographic ordering\nschedule s(i,j) -&gt; (i,j) statements -&gt; vector (should be a time)\nHow do we interpret a vector as a time, e.g. hours, min, seconds.\nUsually written as $$ Generalization of alphabetical order\n\\[\n(i,j) \\gg (m,n) \\iff i &gt;  m \\lor (i=m \\land j&gt; n)\n\\]\nCompare left to right if terms are equal, go to next term, or different so compare the terms\nNotice the or we will need to call the ilp solver more than once\nChecking for loop interchange\nfor i in [1,2,3,4]                     for j in [1,2,3]\n  for j in [1,2,3]                       for i in [1,2,3,4]\ns:   a(i,j) = a(i-1,j+1)                   a(i,j) = a(i-1,j+1)  \n\n\ns(i, j) -&gt; (i,j)                          s(i,j)=(j,i)\ndata flow\n    read write\ns(1,1) a(0,2) a(1,1) s(1,2) a(0,3) a(1,2) s(1,3) a(0,4) a(1,3) s(1,4) a(0,5) a(1,4) s(2,1) a(1,2) a(2,1) s(1,2)-&gt; s(2,1) s(2,2) a(1,3) a(2,2) s(1,3)-&gt; s(2.2) …\ns(i,j) writes a value that is consumed in s(i+1, j-1)\n\\[\ns(i,j) \\rightarrow s(i+1, j-1)\n\\] constants:\nDoes there exist a statement s(i,j) and a statement \\(s(i',j')\\) where in the new schedule \\(s(i',j')\\) executes first and data flows backward in time \\[\n\\begin{align*}\n(i', j') \\gg (j,i)   &\\text{ $i',j'$ is first} \\\\\ni' = 1+ i            &\\text{ data\\  from \\ i+1 to $i'$}\\\\\nj' = -1 +j           &\\text{ data\\  from \\ j-1 to $j'$}\\\\\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 3  \\\\\n1 \\le i' le 4 \\\\\n1 \\le j' \\leftrightarrows 3\n\\end{align*}\n\\]\nbecause of the lexicographic order ( or) we have two ilp problems one where \\(i'\\) is greater then j, and one where \\(i'\\) = j, and the other where \\(j'\\) &gt; j\ni ran it through https://online-optimizer.appspot.com\nwhich gave me a solution\ns(4,2) reads s(3,3) but s(4,2) executes first"
  },
  {
    "objectID": "lectures/revealjs_09_poly.qmd.html#ir",
    "href": "lectures/revealjs_09_poly.qmd.html#ir",
    "title": "9 polyhedral analysis",
    "section": "ir",
    "text": "ir\nHow do we represent these sets in the ir?\nfor i in [0,1,2,3,4,5]\n  for j from  i to 7\n     a(i,j) = 0\n\nchange the equations around so that they are … \\(\\ge 0\\)\n\\[\n\\begin{align*}\ni \\ge 0  &\\rightarrow  i \\ge 0 \\\\\ni \\le 5 &\\rightarrow -i + 5 \\ge 0 \\\\\nj \\ge i &\\rightarrow -i + j \\ge 0 \\\\\nj \\le 7 &\\rightarrow =j+7 \\ge 0\n\\end{align*}\n\\]\nWe can split off the constraints: \\[\nconstraints  = \\left\\{ \\vec{x} \\mid B\\vec{x} + \\vec{b} &gt;= 0\\right\\}\n\\]\nWhere: \\[\n\\begin{equation*}\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n0 & -1\n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n0 \\\\\n5  \\\\\n0   \\\\\n7\n\\end{bmatrix}\n\\vec{x} =\n\\begin{bmatrix}\ni \\\\\nj\n\\end{bmatrix}\n\\end{equation*}\n\\]\nThis also works if the loop bounds are symbolic ~~~ for i in [L.. U] for j from i to 7 a(i,j) = 0\n$$\n\\begin{equation*}\nB = \n\\begin{bmatrix} \\begin{array}{rr}\n 1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n 0 & -1\n \\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n L \\\\\n U\\\\\n0\\\\\n7\n\\end{bmatrix}\n\\end{equation*}\n$$\n\n\n## suppose we have complex loop bounds?\n\n```\nfor i=0; i &lt; 7, i++\n  for j =i, j &lt; min(7, i+4), j++\n    a(i,j) = 0\n```\n![alt text](plot1-7.png)\n\nshaded area is the polygon\nwhat are the loop bounds if we interchange the loops?\n\nWhat are the upper and lower bounds if we interchange the loops?\n\ninequalities\n$$\n\\begin{align*}\ni \\ge 0   & \\rightarrow  i  \\ge 0 \\\\\ni \\le 6   & \\rightarrow  -i+6 \\ge 0 \\\\\nj \\ge i   & \\rightarrow j-i \\ge 0 \\\\\nj \\le 6    & \\rightarrow  6  -j  \\ge 0 \\\\\nj \\le i+3 & \\rightarrow -j+i+3 \\ge 0 \n\\end{align*}\n$$\n\n```\nfor j  (must be constants)\n  for j (constants and j )\n\n```\n\nwe can get the j bounds by projecting onto the j axis,  next we want to remove j from the inequalities \n\n\nir constrants\n\n$$\n\\begin{align*}\n\\begin{equation*}\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n 1 & 0 \\\\\n-1 & 0 \\\\\n-1 & 1 \\\\\n0 & -1 \\\\\n 1 & -1 \n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n 0\\\\\n 6 \\\\\n0\\\\\n6\\\\\n3\n\\end{bmatrix}\n\\end{equation*}\n\\end{align*}\n$$\n\nwritten for i\n$$\n\\begin{align}\n0  \\le  & i & \\\\\n        & i &\\le 6 \\\\\n        & i & \\le j \\\\\n        & &  6  -j  \\ge 0 \\\\\nj -3 \\le & i &\n\\end{align}\n$$\n\n$ i \\le max(0, j-3) \\land  i \\le min(6,j) $\n\nwritten for j\n$$\n\\begin{align}\n       & & i \\ge 0 \\\\\n       & & i \\le 6  \\\\\ni \\le  &j & \\\\\n    &  j  & \\le 6 \\\\\n&j& \\le i+3 \n\\end{align}\n$$\n\n\nbounds for j depend on i -  We need to remove i \n\n\nmath thing #2 fourier-motzkin method\n\nhttps://people.math.carleton.ca/~kcheung/math/notes/MATH5801/02/2_1_fourier_motzkin.html\n\nGiven a set of inequalities remove one variable, (for higher dim d, need to do this multiple times)\n\nin general \nSuppose we want to remove $x_m$ we find a pair $L \\le c_1 * x_m $  and  upper bound $x_2 * x_m \\ge U$ and both c's are &gt;= 0\n\nremove x_m and add $c_2* L \\ge c_1 *U $\n\nWe start with each pair of constants\n$$\nc_1 * i &lt; U \\land\nc_2 *i &gt; L\n$$\n\nthere are 4 pairs (1,2), (1,3) , (2,5),  (3,5) \nall the c's are 1 \nfrom the ir column 1 (i column) ignore zeros, pair up plus and minus values \n\n\nWe need to eliminate i (to get the bounds for the outer loop in j)\n\nwe have 4 inequalities where i is not multiplied by zero $ j \\le 6$ \n\nwe consider each pair\n\n$$\n\\begin{align*}\n(1,2) \\rightarrow  0 &\\le 6 \\ done \\\\\n(1,3) \\rightarrow  0 &\\le j\\\\\n(2,5) \\rightarrow j-3  &\\le 6\\\\\n(3,5) \\rightarrow j-3  &\\le j \\ done \n\\end{align*}\n$$\n\nbounds for j are 0 to 6\n\n\n```\nfor j =0 ; j &lt;= 6 , j++\n    for i = max(j-3,6), i &lt; j; i++&gt;  \n       a[i,j] = 0\n```\n\n\n## suppose we want to run the an example  in parallel\nfor i in [1,2,3,4] for j in [1,2,3, 4] s: a(i,j) = a(i-1, j+1) ~~~\nreorder to run in parallel get new bounds, we want to run diagonally \\(k= i-j\\), we know the transformation that we want We replace $i = k+j $\nfor k = ?? for j = ?? s: a(j-k,j) = a(j-k-1, j+1)\n\\[\n\\begin{align*}\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 4 \\\\\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n1 \\le & k+j &\\le 4 \\\\\n1 \\le & j &\\le 4 \\\\\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n1-k \\le j \\le 4-k \\\\\n1 \\le j &lt;= 4\n\\end{align*}\n\\]\nnow for mf \\[\n\\begin{align*}\n1-k \\le  4-k \\\\\n1-k  \\le 4\\\\\n1 \\le 4-k \\\\\n1 \\le 4\n\\end{align*}\n\\]\ngiving k bounds -3 to 3 j bound are max(1,1,k) yo min(4, 4-k)"
  },
  {
    "objectID": "lectures/09_poly.html",
    "href": "lectures/09_poly.html",
    "title": "9 polyhedral analysis",
    "section": "",
    "text": "We get a new flavor of IR - more math like\ntwo kinds of problems:\n\npolyhedral analysis - given a loop transform, does the behavior change- Is it valid\npolyhedral scheduling - find a transform that maximizes/minimizes some property\n\nThe base idea - A statement in a loop might execute a lot of times Each time it executes there is one instance of the statement\nWe want an ir that:\n\nlet us reason about each instance\nis finite (even in the number of instances is not)\nlets a compiler reason about what is going on\n\nNegative -\nOnly applies to loop nests, where everything, array indexs, bounds, statements etc are affine so not not loops hidden in recursion\n99% of hpc loops are affine C. Bastoul, A. Cohen, S. Girbal, S. Sharma, and O. Temam. Putting polyhedral loop transformations to work. In LCPC, 2003.\nover 95% of loops in deep learning are affine Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, RaminderBajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. 2017. In-datacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA). IEEE, 1–12.\nOver the course of this, I’ll use 3 pieces of math 1) ILP integer linear programming find a set of integers that satisfies a set of inequalities and maximize something 2) fourier-motzkin method 3) The affine form of Farkas Lemma"
  },
  {
    "objectID": "lectures/09_poly.html#formalizing-the-schedule-lexicographic-ordering",
    "href": "lectures/09_poly.html#formalizing-the-schedule-lexicographic-ordering",
    "title": "9 polyhedral analysis",
    "section": "formalizing the schedule, Lexicographic ordering",
    "text": "formalizing the schedule, Lexicographic ordering\nschedule s(i,j) -&gt; (i,j) statements -&gt; vector (should be a time)\nHow do we interpret a vector as a time, e.g. hours, min, seconds.\nUsually written as $$ Generalization of alphabetical order\n\\[\n(i,j) \\gg (m,n) \\iff i &gt;  m \\lor (i=m \\land j&gt; n)\n\\]\nCompare left to right if terms are equal, go to next term, or different so compare the terms\nNotice the or we will need to call the ilp solver more than once\nChecking for loop interchange\nfor i in [1,2,3,4]                     for j in [1,2,3]\n  for j in [1,2,3]                       for i in [1,2,3,4]\ns:   a(i,j) = a(i-1,j+1)                   a(i,j) = a(i-1,j+1)  \n\n\ns(i, j) -&gt; (i,j)                          s(i,j)=(j,i)\ndata flow\n    read write\ns(1,1) a(0,2) a(1,1) s(1,2) a(0,3) a(1,2) s(1,3) a(0,4) a(1,3) s(1,4) a(0,5) a(1,4) s(2,1) a(1,2) a(2,1) s(1,2)-&gt; s(2,1) s(2,2) a(1,3) a(2,2) s(1,3)-&gt; s(2.2) …\ns(i,j) writes a value that is consumed in s(i+1, j-1)\n\\[\ns(i,j) \\rightarrow s(i+1, j-1)\n\\] constants:\nDoes there exist a statement s(i,j) and a statement \\(s(i',j')\\) where in the new schedule \\(s(i',j')\\) executes first and data flows backward in time \\[\n\\begin{align*}\n(i', j') \\gg (j,i)   &\\text{ $i',j'$ is first} \\\\\ni' = 1+ i            &\\text{ data\\  from \\ i+1 to $i'$}\\\\\nj' = -1 +j           &\\text{ data\\  from \\ j-1 to $j'$}\\\\\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 3  \\\\\n1 \\le i' le 4 \\\\\n1 \\le j' \\leftrightarrows 3\n\\end{align*}\n\\]\nbecause of the lexicographic order ( or) we have two ilp problems one where \\(i'\\) is greater then j, and one where \\(i'\\) = j, and the other where \\(j'\\) &gt; j\ni ran it through https://online-optimizer.appspot.com\nwhich gave me a solution\ns(4,2) reads s(3,3) but s(4,2) executes first"
  },
  {
    "objectID": "lectures/09_poly.html#ir",
    "href": "lectures/09_poly.html#ir",
    "title": "9 polyhedral analysis",
    "section": "ir",
    "text": "ir\nHow do we represent these sets in the ir?\nfor i in [0,1,2,3,4,5]\n  for j from  i to 7\n     a(i,j) = 0\n\nchange the equations around so that they are … \\(\\ge 0\\)\n\\[\n\\begin{align*}\ni \\ge 0  &\\rightarrow  i \\ge 0 \\\\\ni \\le 5 &\\rightarrow -i + 5 \\ge 0 \\\\\nj \\ge i &\\rightarrow -i + j \\ge 0 \\\\\nj \\le 7 &\\rightarrow =j+7 \\ge 0\n\\end{align*}\n\\]\nWe can split off the constraints: \\[\nconstraints  = \\left\\{ \\vec{x} \\mid B\\vec{x} + \\vec{b} &gt;= 0\\right\\}\n\\]\nWhere: \\[\n\\begin{equation*}\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n0 & -1\n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n0 \\\\\n5  \\\\\n0   \\\\\n7\n\\end{bmatrix}\n\\vec{x} =\n\\begin{bmatrix}\ni \\\\\nj\n\\end{bmatrix}\n\\end{equation*}\n\\]\nThis also works if the loop bounds are symbolic ~~~ for i in [L.. U] for j from i to 7 a(i,j) = 0\n$$\n\\begin{equation*}\nB = \n\\begin{bmatrix} \\begin{array}{rr}\n 1 &  0 \\\\\n-1 &  0 \\\\\n-1 &  1 \\\\\n 0 & -1\n \\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n L \\\\\n U\\\\\n0\\\\\n7\n\\end{bmatrix}\n\\end{equation*}\n$$\n\n\n## suppose we have complex loop bounds?\n\n```\nfor i=0; i &lt; 7, i++\n  for j =i, j &lt; min(7, i+4), j++\n    a(i,j) = 0\n```\n![alt text](plot1-7.png)\n\nshaded area is the polygon\nwhat are the loop bounds if we interchange the loops?\n\nWhat are the upper and lower bounds if we interchange the loops?\n\ninequalities\n$$\n\\begin{align*}\ni \\ge 0   & \\rightarrow  i  \\ge 0 \\\\\ni \\le 6   & \\rightarrow  -i+6 \\ge 0 \\\\\nj \\ge i   & \\rightarrow j-i \\ge 0 \\\\\nj \\le 6    & \\rightarrow  6  -j  \\ge 0 \\\\\nj \\le i+3 & \\rightarrow -j+i+3 \\ge 0 \n\\end{align*}\n$$\n\n```\nfor j  (must be constants)\n  for j (constants and j )\n\n```\n\nwe can get the j bounds by projecting onto the j axis,  next we want to remove j from the inequalities \n\n\nir constrants\n\n$$\n\\begin{align*}\n\\begin{equation*}\nB =\n\\begin{bmatrix} \\begin{array}{rr}\n 1 & 0 \\\\\n-1 & 0 \\\\\n-1 & 1 \\\\\n0 & -1 \\\\\n 1 & -1 \n\\end{array} \\end{bmatrix}\n\\vec{b} =\n\\begin{bmatrix}\n 0\\\\\n 6 \\\\\n0\\\\\n6\\\\\n3\n\\end{bmatrix}\n\\end{equation*}\n\\end{align*}\n$$\n\nwritten for i\n$$\n\\begin{align}\n0  \\le  & i & \\\\\n        & i &\\le 6 \\\\\n        & i & \\le j \\\\\n        & &  6  -j  \\ge 0 \\\\\nj -3 \\le & i &\n\\end{align}\n$$\n\n$ i \\le max(0, j-3) \\land  i \\le min(6,j) $\n\nwritten for j\n$$\n\\begin{align}\n       & & i \\ge 0 \\\\\n       & & i \\le 6  \\\\\ni \\le  &j & \\\\\n    &  j  & \\le 6 \\\\\n&j& \\le i+3 \n\\end{align}\n$$\n\n\nbounds for j depend on i -  We need to remove i \n\n\nmath thing #2 fourier-motzkin method\n\nhttps://people.math.carleton.ca/~kcheung/math/notes/MATH5801/02/2_1_fourier_motzkin.html\n\nGiven a set of inequalities remove one variable, (for higher dim d, need to do this multiple times)\n\nin general \nSuppose we want to remove $x_m$ we find a pair $L \\le c_1 * x_m $  and  upper bound $x_2 * x_m \\ge U$ and both c's are &gt;= 0\n\nremove x_m and add $c_2* L \\ge c_1 *U $\n\nWe start with each pair of constants\n$$\nc_1 * i &lt; U \\land\nc_2 *i &gt; L\n$$\n\nthere are 4 pairs (1,2), (1,3) , (2,5),  (3,5) \nall the c's are 1 \nfrom the ir column 1 (i column) ignore zeros, pair up plus and minus values \n\n\nWe need to eliminate i (to get the bounds for the outer loop in j)\n\nwe have 4 inequalities where i is not multiplied by zero $ j \\le 6$ \n\nwe consider each pair\n\n$$\n\\begin{align*}\n(1,2) \\rightarrow  0 &\\le 6 \\ done \\\\\n(1,3) \\rightarrow  0 &\\le j\\\\\n(2,5) \\rightarrow j-3  &\\le 6\\\\\n(3,5) \\rightarrow j-3  &\\le j \\ done \n\\end{align*}\n$$\n\nbounds for j are 0 to 6\n\n\n```\nfor j =0 ; j &lt;= 6 , j++\n    for i = max(j-3,6), i &lt; j; i++&gt;  \n       a[i,j] = 0\n```\n\n\n## suppose we want to run the an example  in parallel\nfor i in [1,2,3,4] for j in [1,2,3, 4] s: a(i,j) = a(i-1, j+1) ~~~\nreorder to run in parallel get new bounds, we want to run diagonally \\(k= i-j\\), we know the transformation that we want We replace $i = k+j $\nfor k = ?? for j = ?? s: a(j-k,j) = a(j-k-1, j+1)\n\\[\n\\begin{align*}\n1 \\le i \\le 4 \\\\\n1 \\le j \\le 4 \\\\\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n1 \\le & k+j &\\le 4 \\\\\n1 \\le & j &\\le 4 \\\\\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n1-k \\le j \\le 4-k \\\\\n1 \\le j &lt;= 4\n\\end{align*}\n\\]\nnow for mf \\[\n\\begin{align*}\n1-k \\le  4-k \\\\\n1-k  \\le 4\\\\\n1 \\le 4-k \\\\\n1 \\le 4\n\\end{align*}\n\\]\ngiving k bounds -3 to 3 j bound are max(1,1,k) yo min(4, 4-k)"
  },
  {
    "objectID": "check_meta.html",
    "href": "check_meta.html",
    "title": "EECE7398 Fall 2024",
    "section": "",
    "text": "# gather all the meta info from all  the files -  check for errors \nimport yaml\nfrom pathlib import Path\n\n\ndef extract_meta_from_qmd(file_path):\n    \"\"\"\n    Extracts and returns the YAML front matter (meta information) from a QMD file.\n    \n    Parameters:\n    - file_path: Path to the QMD file.\n    \n    Returns:\n    - A dictionary containing the parsed YAML front matter, or None if not found.\n    \"\"\"\n    # Initialize an empty string to hold the YAML content\n    yaml_content = ''\n    # Flag to indicate if we are within the YAML front matter\n    in_yaml = False\n    \n    with open(file_path, 'r') as f:\n        for line in f:\n            # Check for the start/end of the YAML front matter\n            if line.strip() == '---':\n                if in_yaml:\n                    # We found the second ---, stop reading further\n                    break\n                else:\n                    # We found the first ---, start collecting lines\n                    in_yaml = True\n            elif in_yaml:\n                # Add the current line to the YAML content\n                yaml_content += line\n    \n    # Parse the YAML content if any was found\n    if yaml_content:\n        return yaml.safe_load(yaml_content)\n    else:\n        return None\n\n\n\nimport os\n\ndef list_all_files(root_dir):\n    \"\"\"List all files in a directory and its subdirectories.\"\"\"\n    all_files = []\n    for root, dirs, files in os.walk(root_dir):\n        for file in files:\n            all_files.append(os.path.join(root, file))\n    return all_files\n\n\nbase = Path(\"/home/norm/compiler_course_2024fa/\")\n\n\nfrom numpy import isin\n\n\nmeta_union = {}\nfor file in list_all_files(base):\n    file_path = Path(file)\n    if file_path.suffix in [\".pdf\", \".jpg\", \".png\", \".woff\", \".eot\", \".woff2\", \".ttf\", \".so\", \".pyc\"]:\n        continue\n    if file_path.parent.name == \"bin\":\n        continue \n    if any(parent.name == \".venv\" for parent in file_path.parents):\n        continue\n    if any(parent.name == \".git\" for parent in file_path.parents):\n        continue\n    meta_info = extract_meta_from_qmd(file)\n    if meta_info:\n        for key, value in meta_info.items():\n    \n            if isinstance(value, list):\n                value = ', '.join(map(str, value))\n            elif isinstance(value,dict):\n                for sub_key, sub_value in value.items():\n                    combined_key = f\"{key}.{sub_key}\"  # Combine the parent key and sub-key\n                    sub_value = str(sub_value)  # Convert sub-value to string\n                    if combined_key not in meta_union:\n                        meta_union[combined_key] = {sub_value}\n                    else:\n                        meta_union[combined_key].add(sub_value)\n                continue\n            \n            if key not in meta_union:\n                meta_union[key] = {value}\n            else:\n                meta_union[key].add(value)\n\nfor (k,v) in meta_union.items():\n    print (k, v )\n\n    \n\ntitle {'Representation of programs', 'Performance and Measurement', '14_gpu_compilers', '5_hw', 'project', 'EECE7398 Fall 2024', '10 MLIR', '3_hw ', 'Untitled', '_ loop invariant code motion', '9 polyhedral analysis', '11 Whole program', 'EECS7398 Weekly Schedule', 'How to do assignments', 'homework 0', '8 classic loop optimizations', 'Overview of Bril', '_ partial_redundancy elimination', '4_hw', 'EECS7398 Weekly Schedule fa 2024', '_ local value numbering', '4. Data Flow', 'About', 'Schedule', '3 Local Analysis & Optimization', '2.hw', '12_memory.qmd', 'Testing Register allocators', '6- extra credit hw ', '1 Compiler Overview', '1-Homework', 'Static Single Assignment', '13_dynamic_compielrs', '5 Global Analysis'}\nformat {'html'}\ntbl-colwidths {'10, 20, 20, 20, 15, 15'}\nformat.html {'default'}\nformat.revealjs {\"{'chalkboard': True, 'output-file': 'revealjs-licm', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-rep'}\", \"{'chalkboard': True, 'output-file': 'revealjs-partial-redun', 'scrollable': True}\", \"{'chalkboard': True, 'scrollable': True, 'output-location': 'slide', 'code-line-numbers': True, 'output-file': 'revealjs-bril'}\", \"{'chalkboard': True, 'output-file': 'revealjs-local', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-ssa', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-lvn', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-compiler_overview.html', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-data-flow', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-global-anal', 'scrollable': True}\", \"{'chalkboard': True, 'output-file': 'revealjs-performance.html', 'scrollable': True}\"}\nkeep-ipynb {True}\npython {'kaggle_comp'}\nsidebar {False}\nexecute.echo {'True'}\n\n\n\nimport os\nimport yaml\n\nbase = Path(\"/home/norm/compiler_course_2024fa/\")\n\n# Step 1: List all .qmd files\nqmd_files = []\nslide_qmd_files = []\n\nfor root, dirs, files in os.walk(base):  # Adjust '.' to your project directory if necessary\n    revealjs_\n    if \"_site\" in Path(root).parts:\n        continue\n    for file in files:\n        if file.endswith('.qmd'):\n            qmd_files.append(os.path.join(root, file))\n\n# Step 2: Read and parse each .qmd file\nfor qmd_file in qmd_files:\n\n    with open(qmd_file, 'r') as file:\n        content = file.read()\n        # Assuming the YAML metadata is at the top of the file, delimited by ---\n        if content.startswith('---'):\n            end_of_yaml = content.find('---', 3)\n            if end_of_yaml != -1:\n                yaml_content = content[3:end_of_yaml]\n                metadata = yaml.safe_load(yaml_content)  # Parse YAML\n\n                format_data = metadata.get('format')\n                if not format_data:\n                    print(qmd_file, \"no format field\")\n                    continue\n                try:\n                    html_meta_data = format_data.get(\"html\")\n                except Exception as e:\n                    print(qmd_file, e, 'format does not have html')\n                    continue\n\n                if html_meta_data != 'default':\n                    print(qmd_file, \"not html default\")\n                    continue \n                try:\n                    revealjs_meta_data = format_data.get('revealjs')\n                except:\n                    print(\"qmd_file\", \"no revealjs\")\n                    continue\n                if revealjs_meta_data:\n                    chalk = revealjs_meta_data.get(\"chalkboard'\")\n                    if chalk != 'true':\n                        print(qmd_file, \"missing chalkboard\")\n    \n                # get the format\n                # see if it has a subkey, revealjs\n                # if it does check for an deeper subkey of output-file\n\n                # Step 3: Check for format: reveljs\n                if metadata.get('format') == 'revealjs':\n                    # Step 4: Verify the output file name\n                    expected_output = 'reveljs-' + os.path.basename(qmd_file).replace('.qmd', '')\n                    if metadata.get('output-file') == expected_output:\n                        print(f\"{qmd_file}: Success, output file name is correct.\")\n                    else:\n                        print(f\"{qmd_file}: Failure, output file name does not match the expected '{expected_output}'.\")\n\n/home/norm/compiler_course_2024fa/lectures/02a_representation.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/010_compiler_overview.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/02b_bril.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/05_global.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/01a_performance_measurement.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/06_ssa.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/05b_licm.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/04_data_flow.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/03b_local_value_numbering.qmd missing chalkboard\n/home/norm/compiler_course_2024fa/lectures/03_local.qmd missing chalkboard\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/hw0.html",
    "href": "homework/hw0.html",
    "title": "0 homework",
    "section": "",
    "text": "Warning\n\n\n\nshould i make it easier to claim a paper?\nHow does a student submit something to canvas\n\n\nIntroduce yourself in the intro topic. Mention a compilers topic you’d like to learn about someday, either in this class or beyond.\nPick a paper from the weekly schedule whose discussion you will lead. Claim the paper by opening a pull request for the weekly.qmd file, fill in your name in the LEADER: line.\nAdd a text file to Canvas to indicate you have done the introduction and claimed a paper\n\nFor this task, submit an empty text file or whatever.\nFor others, include a link to your code. if you want, you can upload your code instead.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/5_hw.html",
    "href": "homework/5_hw.html",
    "title": "5_Homework",
    "section": "",
    "text": "Task5: Implement the into SSA and out of SSA transformations on Bril functions. Watch out for variables that are undefined on some paths. The script “is_ssa.py can check if a program is really in SSA and the Bril interpreter bili supports phi functions so you can execute code in the midpoint of your round trip. Measure the overhead (does the final program have more instructions (static or dynamic) the original, be sure to report the overhead in your writeup.\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/dynamic.html",
    "href": "homework/dynamic.html",
    "title": "homework dynamic compile",
    "section": "",
    "text": "This task is to implement a trace-based speculative optimizer for Bril. You’ll implement the same concept as in a tracing JIT, but in a profile-guided AOT setting: profiling, transformation, and execution will be distinct phases. The idea is to implement the “heavy lifting” for a trace-based JIT without needing all the scaffolding that a complete JIT requires, such as on-stack replacement.\nConcretely, there are three main phases:\n\nModify the reference interpreter to produce traces.\nBuild an optimizer that injects traces back into the original program using the speculation extension to provide a “fast path.”\nCheck that the whole process is correct and had some effect on performance (it needn’t actually be good!).\n\nStart by reading the documentation for the speculation extension (and watch the video!). That should give you an idea of what’s required to augment a program with a speculative execution of an extracted trace. Then make a plan for how you’ll hack the interpreter to produce one of those traces.\nHere’s a recipe:\n\nStart interpreting normally.\nAt some point during execution (at the very beginning of main, for example, or when reaching a backedge), start tracing.\nWhile tracing, record every instruction as it executes. Eliminate jumps; replace branches with guard instructions. Feel free to do the interprocedural version, and to bail out on any other instruction you don’t want to handle.\nStop tracing at some point (after a fixed number of instructions, for example, or at the next backedge) and save the trace to a file.\nFor bonus “points,” statically optimize the trace by eliminating instructions that depend on foregone conclusions enforced by guards.\nTransform the program to stitch the trace back into the program using speculate and commit instructions.\nFor these tasks, unlike some previous lessons, I recommend not attempting to support all the benchmarks. It’s more important that you understand a few programs well than you apply your transformation to a large body of code. (In other words, I recommend that you work depth-first instead of breadth-first.)\n\nIn particular, you do not need to support Bril’s memory extension, which makes things more complicated because it doesn’t get automatically rolled back on speculation aborts. If you are feeling very ambitious, you can try devising a scheme to manually roll back memory modifications on aborts (consider an “undo log” or “redo log,” which are concepts from databases).\nFinally, evaluate your work:\n\nCheck that you didn’t break programs. For at least one benchmark (and ideally a few), create multiple inputs to the program that result in different outputs. Use one input to generate the trace and optimize the program, and use other inputs to check correctness. This approach guards against cases where your tracing optimization “overfits” and you end up with code that only works on one input. Measure performance impact, i.e., the effect of your transformation on the dynamic instruction count.\nfor at least one benchmark, use at least two inputs to evaluate tracing’s impact on executions that are not identical to the traced execution. If you implemented optimizations on the traced code, consider comparing the optimized vs. un-optimized versions. (It’s OK if your tracing apparatus makes programs slower, especially on unseen inputs! We just want to measure the difference.)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "homework/2_hw.html",
    "href": "homework/2_hw.html",
    "title": "2 Homework",
    "section": "",
    "text": "Task2: Implement “trivial” dead code elimination in which you delete instructions that are never used before they are reassigned. Then implement local value numbering. Try pairing it with your dead code elimination code, in the write up be sure to include evidence that your implementation is correct and actually optimizes programs, you might want to use the Brench program, for extra points, extend your implementation to handle some of the tricker examples talked about in class.\n\n\n\n Back to top"
  }
]